{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dspy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "student_lm_name = \"fireworks_ai/accounts/fireworks/models/gpt-oss-120b\"\n",
        "teacher_lm_name = \"openai/gpt-5.1-2025-11-13\"\n",
        "\n",
        "if \"ollama_chat\" in student_lm_name:\n",
        "    student_lm = dspy.LM(student_lm_name, api_base='http://localhost:11434', api_key='')\n",
        "else:\n",
        "    student_lm = dspy.LM(student_lm_name)\n",
        "teacher_lm = dspy.LM(teacher_lm_name)\n",
        "\n",
        "dspy.configure(lm=student_lm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare DSPY Dataset (Subtask 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "trial_id = \"DSP0004S\"\n",
        "# Train val test split\n",
        "lang = \"eng\"\n",
        "# Load the training and validation data for subtask 3\n",
        "train_df = pd.read_csv(f'./dev_phase/subtask3/train/{lang}.csv')\n",
        "test_df = pd.read_csv(f'./dev_phase/subtask3/dev/{lang}.csv')\n",
        "# Split train into train and validation sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define label columns for multilabel classification (Subtask 3 - Polarization Techniques)\n",
        "LABEL_COLUMNS = [\"stereotype\", \"vilification\", \"dehumanization\", \"extreme_language\", \"lack_of_empathy\", \"invalidation\"]\n",
        "\n",
        "# Map for each label: 1 -> \"yes\", 0 -> \"no\"\n",
        "LABEL_MAP = {1: \"yes\", 0: \"no\"}\n",
        "LABEL_MAP_INV = {\"yes\": 1, \"no\": 0}\n",
        "\n",
        "def make_dspy_examples(df, include_label: bool = True):\n",
        "    examples = []\n",
        "    for _, row in df.iterrows():\n",
        "        kwargs = dict(\n",
        "            sentence=row[\"text\"],\n",
        "        )\n",
        "        if include_label:\n",
        "            for col in LABEL_COLUMNS:\n",
        "                if col in row:\n",
        "                    kwargs[col] = LABEL_MAP[row[col]]\n",
        "        example = dspy.Example(**kwargs).with_inputs(\"sentence\")\n",
        "        examples.append(example)\n",
        "    return examples\n",
        "\n",
        "# Create DSPY datasets\n",
        "raw_train = make_dspy_examples(train_df, include_label=True)\n",
        "raw_val = make_dspy_examples(val_df, include_label=True)\n",
        "raw_test = make_dspy_examples(test_df, include_label=False)\n",
        "\n",
        "\n",
        "# # For now take only 10% of each \n",
        "raw_train = raw_train[:int(len(raw_train) * 0.2)]\n",
        "raw_val = raw_val[:int(len(raw_val) * 0.3)]\n",
        "raw_test = raw_test[:int(len(raw_test) * 1)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define Signature (Subtask 3 - Polarization Techniques)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "class PolarizationTechniques(dspy.Signature):\n",
        "    \"\"\"\n",
        "    Polarization techniques are specific rhetorical strategies used to create division and intolerance.\n",
        "    \n",
        "    Given a sentence, classify it for the presence of the following polarization techniques:\n",
        "    - stereotype: Generalizing negative traits to an entire group\n",
        "    - vilification: Attacking the character or reputation of a group or individual\n",
        "    - dehumanization: Portraying people as less than human, using animalistic or objectifying language\n",
        "    - extreme_language: Using exaggerated, inflammatory, or hyperbolic language\n",
        "    - lack_of_empathy: Dismissing or ignoring the suffering or concerns of others\n",
        "    - invalidation: Denying the legitimacy of others' experiences, beliefs, or identities\n",
        "    \n",
        "    For each technique, output \"yes\" if the sentence uses that technique, \"no\" otherwise.\n",
        "    A sentence can use multiple techniques or none at all.\n",
        "    \"\"\"\n",
        "\n",
        "    sentence: str = dspy.InputField()\n",
        "    stereotype: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence contains stereotyping, \"no\" otherwise.',\n",
        "    )\n",
        "    vilification: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence contains vilification, \"no\" otherwise.',\n",
        "    )\n",
        "    dehumanization: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence contains dehumanization, \"no\" otherwise.',\n",
        "    )\n",
        "    extreme_language: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence contains extreme/inflammatory language, \"no\" otherwise.',\n",
        "    )\n",
        "    lack_of_empathy: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence shows lack of empathy, \"no\" otherwise.',\n",
        "    )\n",
        "    invalidation: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence contains invalidation, \"no\" otherwise.',\n",
        "    )\n",
        "\n",
        "classify = dspy.Predict(PolarizationTechniques)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Label fields (same as LABEL_COLUMNS for subtask 3)\n",
        "LABEL_FIELDS = [\"stereotype\", \"vilification\", \"dehumanization\", \"extreme_language\", \"lack_of_empathy\", \"invalidation\"]\n",
        "\n",
        "def label2id(label: str) -> int:\n",
        "    return LABEL_MAP_INV.get(label, 0)\n",
        "\n",
        "def id2label(i: int) -> str:\n",
        "    return LABEL_MAP[i]\n",
        "\n",
        "def accuracy_metric(example, pred, trace=None):\n",
        "    \"\"\"Compute accuracy as exact match across all labels\"\"\"\n",
        "    correct = 0\n",
        "    total = len(LABEL_FIELDS)\n",
        "    for field in LABEL_FIELDS:\n",
        "        gold = getattr(example, field, \"no\")\n",
        "        guess = getattr(pred, field, \"no\")\n",
        "        if guess is None:\n",
        "            guess = \"no\"\n",
        "        if gold == guess:\n",
        "            correct += 1\n",
        "    return correct / total  # Return fraction of correct labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 166.33 / 193 (86.2%): 100%|██████████| 193/193 [01:33<00:00,  2.07it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:21:09 INFO dspy.evaluate.evaluate: Average Metric: 166.33333333333334 / 193 (86.2%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>example_stereotype</th>\n",
              "      <th>example_vilification</th>\n",
              "      <th>example_dehumanization</th>\n",
              "      <th>example_extreme_language</th>\n",
              "      <th>example_lack_of_empathy</th>\n",
              "      <th>example_invalidation</th>\n",
              "      <th>pred_stereotype</th>\n",
              "      <th>pred_vilification</th>\n",
              "      <th>pred_dehumanization</th>\n",
              "      <th>pred_extreme_language</th>\n",
              "      <th>pred_lack_of_empathy</th>\n",
              "      <th>pred_invalidation</th>\n",
              "      <th>accuracy_metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump relies on First Amendment</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>House GOP in no rush to give more Ukraine aid after 6</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Israeli adviser to meet with US officials on war</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>so russia commits war crimes, how does that justify ukraine also c...</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [0.333]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cant wait to watch this episode of Border Security</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>Wow, thats awesome. It reminds me of the crazy things the Tamir in...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>How long will it be until human rights are stripped away? oligarch...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [0.500]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>There are no open borders here in Texas.</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>Ottawa to unveil economic update detailing deficit, new border sec...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>The White House or the asylum seekers?</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>193 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                  sentence  \\\n",
              "0                                   Donald Trump relies on First Amendment   \n",
              "1                    House GOP in no rush to give more Ukraine aid after 6   \n",
              "2                         Israeli adviser to meet with US officials on war   \n",
              "3    so russia commits war crimes, how does that justify ukraine also c...   \n",
              "4                       Cant wait to watch this episode of Border Security   \n",
              "..                                                                     ...   \n",
              "188  Wow, thats awesome. It reminds me of the crazy things the Tamir in...   \n",
              "189  How long will it be until human rights are stripped away? oligarch...   \n",
              "190                               There are no open borders here in Texas.   \n",
              "191  Ottawa to unveil economic update detailing deficit, new border sec...   \n",
              "192                                 The White House or the asylum seekers?   \n",
              "\n",
              "    example_stereotype example_vilification example_dehumanization  \\\n",
              "0                   no                   no                     no   \n",
              "1                   no                   no                     no   \n",
              "2                   no                   no                     no   \n",
              "3                   no                  yes                    yes   \n",
              "4                   no                   no                     no   \n",
              "..                 ...                  ...                    ...   \n",
              "188                 no                   no                     no   \n",
              "189                 no                   no                     no   \n",
              "190                 no                   no                     no   \n",
              "191                 no                   no                     no   \n",
              "192                 no                   no                     no   \n",
              "\n",
              "    example_extreme_language example_lack_of_empathy example_invalidation  \\\n",
              "0                         no                      no                   no   \n",
              "1                         no                      no                   no   \n",
              "2                         no                      no                   no   \n",
              "3                        yes                     yes                  yes   \n",
              "4                         no                      no                   no   \n",
              "..                       ...                     ...                  ...   \n",
              "188                       no                      no                   no   \n",
              "189                      yes                      no                   no   \n",
              "190                       no                      no                   no   \n",
              "191                       no                      no                   no   \n",
              "192                       no                      no                   no   \n",
              "\n",
              "    pred_stereotype pred_vilification pred_dehumanization  \\\n",
              "0                no                no                  no   \n",
              "1                no                no                  no   \n",
              "2                no                no                  no   \n",
              "3               yes               yes                  no   \n",
              "4                no                no                  no   \n",
              "..              ...               ...                 ...   \n",
              "188              no                no                  no   \n",
              "189             yes               yes                  no   \n",
              "190              no                no                  no   \n",
              "191              no                no                  no   \n",
              "192              no                no                  no   \n",
              "\n",
              "    pred_extreme_language pred_lack_of_empathy pred_invalidation  \\\n",
              "0                      no                   no                no   \n",
              "1                      no                   no                no   \n",
              "2                      no                   no                no   \n",
              "3                      no                  yes                no   \n",
              "4                      no                   no                no   \n",
              "..                    ...                  ...               ...   \n",
              "188                    no                   no                no   \n",
              "189                   yes                  yes                no   \n",
              "190                    no                   no                no   \n",
              "191                    no                   no                no   \n",
              "192                    no                   no                no   \n",
              "\n",
              "    accuracy_metric  \n",
              "0        ✔️ [1.000]  \n",
              "1        ✔️ [1.000]  \n",
              "2        ✔️ [1.000]  \n",
              "3        ✔️ [0.333]  \n",
              "4        ✔️ [1.000]  \n",
              "..              ...  \n",
              "188      ✔️ [1.000]  \n",
              "189      ✔️ [0.500]  \n",
              "190      ✔️ [1.000]  \n",
              "191      ✔️ [1.000]  \n",
              "192      ✔️ [1.000]  \n",
              "\n",
              "[193 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy average accuracy metric: 86.18\n"
          ]
        }
      ],
      "source": [
        "evaluate = dspy.Evaluate(\n",
        "    devset=raw_val,\n",
        "    metric=accuracy_metric,\n",
        "    display_progress=True,\n",
        "    display_table=True,   # nice overview\n",
        ")\n",
        "eval_result = evaluate(classify)\n",
        "print(\"DSPy average accuracy metric:\", eval_result.score)  # percentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation metrics: {'f1_macro': 0.46022704221867455, 'f1_micro': 0.5266272189349113, 'f1_samples': 0.14744820522022595, 'f1_weighted': 0.5194198759415818, 'precision_macro': 0.4387188178036705, 'recall_macro': 0.516920435885953, 'exact_match_ratio': np.float64(0.5906735751295337)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/0ssamaak0/miniconda3/envs/nlp/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "def eval_metrics_on_dataset(program, dataset):\n",
        "    \"\"\"Compute multilabel classification metrics\"\"\"\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for ex in dataset:\n",
        "        pred = program(sentence=ex.sentence)\n",
        "        \n",
        "        gold_labels = []\n",
        "        pred_labels = []\n",
        "        \n",
        "        for field in LABEL_FIELDS:\n",
        "            gold = getattr(ex, field, \"no\")\n",
        "            guess = getattr(pred, field, \"no\")\n",
        "            if guess is None:\n",
        "                guess = \"no\"\n",
        "            gold_labels.append(label2id(gold))\n",
        "            pred_labels.append(label2id(guess))\n",
        "        \n",
        "        y_true.append(gold_labels)\n",
        "        y_pred.append(pred_labels)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    return {\n",
        "        'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
        "        'f1_micro': f1_score(y_true, y_pred, average='micro'),\n",
        "        'f1_samples': f1_score(y_true, y_pred, average='samples'),\n",
        "        'f1_weighted': f1_score(y_true, y_pred, average='weighted'),\n",
        "        'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "        'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "        'exact_match_ratio': np.mean(np.all(y_true == y_pred, axis=1)),\n",
        "    }\n",
        "\n",
        "metrics_val = eval_metrics_on_dataset(classify, raw_val)\n",
        "print(\"Validation metrics:\", metrics_val)\n",
        "\n",
        "# metrics_test = eval_metrics_on_dataset(classify, raw_test)\n",
        "# print(\"Test metrics:\", metrics_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "student_f1_macro = metrics_val[\"f1_macro\"]\n",
        "import json\n",
        "\n",
        "# Build current language entry for subtask_3\n",
        "lang_entry = {\n",
        "    \"eval_results\": {\n",
        "        \"eval_f1_macro\": student_f1_macro\n",
        "    }\n",
        "}\n",
        "\n",
        "# Load previous trials from logs.json if it exists, else create new list\n",
        "log_path = \"logs.json\"\n",
        "try:\n",
        "    with open(log_path, \"r\") as f:\n",
        "        trials = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    trials = []\n",
        "\n",
        "# Look for existing trial by trial_id\n",
        "found = False\n",
        "for trial in trials:\n",
        "    if trial.get(\"trial_id\") == trial_id:\n",
        "        # Insert or update lang in subtask_3\n",
        "        if \"subtask_3\" not in trial:\n",
        "            trial[\"subtask_3\"] = {\"score\": None}\n",
        "        if \"score\" not in trial[\"subtask_3\"]:\n",
        "            trial[\"subtask_3\"][\"score\"] = None\n",
        "        trial[\"subtask_3\"][lang] = lang_entry\n",
        "        found = True\n",
        "        break\n",
        "\n",
        "if not found:\n",
        "    # Build new trial dict if trial_id not found\n",
        "    current_trial = {\n",
        "        \"trial_id\": trial_id,\n",
        "        \"metadata\": {\n",
        "            \"approach\": \"dspy basic\",\n",
        "            \"model\": student_lm_name\n",
        "        },\n",
        "        \"subtask_3\": {\n",
        "            \"score\": None,\n",
        "            lang: lang_entry\n",
        "        }\n",
        "    }\n",
        "    trials.append(current_trial)\n",
        "\n",
        "# Save back to logs.json\n",
        "with open(log_path, \"w\") as f:\n",
        "    json.dump(trials, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddb9038d640444d7a55ae2f0050f446d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                     id  stereotype  vilification  \\\n",
            "0  eng_f66ca14d60851371f9720aaf4ccd9b58           0             0   \n",
            "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb           0             0   \n",
            "2  eng_95770ff547ea5e48b0be00f385986483           0             0   \n",
            "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf           0             0   \n",
            "4  eng_07781aa88e61e7c0a996abd1e5ea3a20           0             0   \n",
            "\n",
            "   dehumanization  extreme_language  lack_of_empathy  invalidation  \n",
            "0               0                 0                0             0  \n",
            "1               0                 0                0             0  \n",
            "2               0                 0                0             0  \n",
            "3               0                 0                0             0  \n",
            "4               0                 0                0             0  \n"
          ]
        }
      ],
      "source": [
        "ids = test_df[\"id\"]\n",
        "\n",
        "def predict_dataset(program, dataset):\n",
        "    rows = []\n",
        "    for i, ex in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        out = program(sentence=ex.sentence)\n",
        "        row = {\"id\": test_df.iloc[i][\"id\"]}\n",
        "        for field in LABEL_FIELDS:\n",
        "            label = getattr(out, field, \"no\")\n",
        "            if label is None:\n",
        "                label = \"no\"\n",
        "            row[field] = label2id(label)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "\n",
        "# after you choose which model to use (classify, optimized_classify, etc.)\n",
        "test_preds_df = predict_dataset(classify, raw_test)\n",
        "\n",
        "print(test_preds_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# in results create dir with trial_id and create subtask_3 inside it, then save the csv as \"pred_lang.csv\" inside it\n",
        "import os\n",
        "os.makedirs(f\"results/{trial_id}/subtask_3\", exist_ok=True)\n",
        "test_preds_df.to_csv(f\"results/{trial_id}/subtask_3/pred_{lang}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using MIPROv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:31:02 WARNING dspy.teleprompt.mipro_optimizer_v2: 'requires_permission_to_run' is deprecated and will be removed in a future version.\n",
            "2025/12/09 10:31:02 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
            "num_trials: 10\n",
            "minibatch: True\n",
            "num_fewshot_candidates: 6\n",
            "num_instruct_candidates: 3\n",
            "valset size: 100\n",
            "\n",
            "2025/12/09 10:31:02 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "2025/12/09 10:31:02 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
            "\n",
            "2025/12/09 10:31:02 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapping set 1/6\n",
            "Bootstrapping set 2/6\n",
            "Bootstrapping set 3/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 4/515 [00:00<00:04, 109.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
            "Bootstrapping set 4/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/515 [00:00<00:04, 120.05it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 5/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/515 [00:00<00:04, 115.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 6/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 3/515 [00:00<00:04, 127.56it/s]\n",
            "2025/12/09 10:31:02 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "2025/12/09 10:31:02 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:32:56 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "Proposing N=3 instructions...\n",
            "\n",
            "2025/12/09 10:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
            "\n",
            "2025/12/09 10:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Polarization techniques are specific rhetorical strategies used to create division and intolerance.\n",
            "\n",
            "Given a sentence, classify it for the presence of the following polarization techniques:\n",
            "- stereotype: Generalizing negative traits to an entire group\n",
            "- vilification: Attacking the character or reputation of a group or individual\n",
            "- dehumanization: Portraying people as less than human, using animalistic or objectifying language\n",
            "- extreme_language: Using exaggerated, inflammatory, or hyperbolic language\n",
            "- lack_of_empathy: Dismissing or ignoring the suffering or concerns of others\n",
            "- invalidation: Denying the legitimacy of others' experiences, beliefs, or identities\n",
            "\n",
            "For each technique, output \"yes\" if the sentence uses that technique, \"no\" otherwise.\n",
            "A sentence can use multiple techniques or none at all.\n",
            "\n",
            "2025/12/09 10:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: 1: **Task**: For a given short, headline‑style sentence, decide whether each of the six polarization techniques below is used.\n",
            "\n",
            "**Techniques (in this order)**  \n",
            "1. **stereotype** – Generalizing negative traits to an entire group.  \n",
            "2. **vilification** – Attacking the character or reputation of a group or individual.  \n",
            "3. **dehumanization** – Describing people as animals, objects, or otherwise less than human.  \n",
            "4. **extreme_language** – Using exaggerated, inflammatory, or hyper‑bolic wording (e.g., profanity, all‑caps, intense punctuation).  \n",
            "5. **lack_of_empathy** – Dismissing or ignoring the suffering, concerns, or feelings of others.  \n",
            "6. **invalidation** – Denying the legitimacy of another’s experiences, beliefs, or identity.\n",
            "\n",
            "**Output format**: For each technique output a line exactly as `Technique: yes` or `Technique: no`, following the order above. Example:\n",
            "\n",
            "```\n",
            "stereotype: no\n",
            "vilification: yes\n",
            "dehumanization: no\n",
            "extreme_language: yes\n",
            "lack_of_empathy: no\n",
            "invalidation: no\n",
            "```\n",
            "\n",
            "If a technique is not present, answer “no”; otherwise answer “yes”. Use only “yes”/“no” (lower‑case) and keep the order intact.\n",
            "\n",
            "2025/12/09 10:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are given a single, headline‑style sentence.  \n",
            "Your task is to decide **independently for each of the six polarization techniques** whether the sentence employs that technique.  \n",
            "For each technique output **exactly** “yes” or “no”, one per line, in the order shown below. Do not add any extra wording, explanations, or formatting.\n",
            "\n",
            "**Techniques and definitions**\n",
            "\n",
            "1. **stereotype** – The sentence attributes a negative, overly‑generalized trait or belief to an entire social, ethnic, political, or cultural group.  \n",
            "2. **vilification** – The sentence attacks, condemns, or expresses contempt toward a target (person, group, ideology, or nation).  \n",
            "3. **dehumanization** – The sentence treats the target as less than human (e.g., likening them to animals, objects, diseases, or other non‑human entities).  \n",
            "4. **extreme_language** – The sentence uses strongly charged, inflammatory, or hyperbolic wording (e.g., profanity, slurs, threats, calls for violence, all‑caps, intensified punctuation).  \n",
            "5. **lack_of_empathy** – The sentence shows an absence of understanding, compassion, or concern for the target’s feelings, suffering, or perspective.  \n",
            "6. **invalidation** – The sentence dismisses, denies, or trivializes the experiences, identity, or beliefs of the target.\n",
            "\n",
            "**Guidelines for accurate labeling**\n",
            "\n",
            "- Focus on **lexical cues** (profanity, slurs, animal/object metaphors, exaggerated adjectives, rhetorical questions) and **stylistic cues** (ALL‑CAPS, excessive punctuation, “!!!”, “???”).  \n",
            "- Tokens such as “@URL”, hashtags, emojis, or intentional misspellings are usually **neutral** unless they are part of a hateful expression.  \n",
            "- The target of the sentence may be a specific group, a nation, a political ideology, or an individual; evaluate the technique with respect to that target.  \n",
            "- A sentence can contain **multiple** techniques; assign “yes” to every technique that applies.  \n",
            "- If a technique is **not clearly present**, answer “no”. Ambiguous or borderline cases should be treated as “no” to keep precision high.  \n",
            "- **Class imbalance**: Because positive examples are rare, be especially strict—only label “yes” when the cue matches the definition strongly.\n",
            "\n",
            "**Output format (exactly as shown):**\n",
            "\n",
            "```\n",
            "stereotype: <yes|no>\n",
            "vilification: <yes|no>\n",
            "dehumanization: <yes|no>\n",
            "extreme_language: <yes|no>\n",
            "lack_of_empthy: <yes|no>\n",
            "invalidation: <yes|no>\n",
            "```\n",
            "\n",
            "*Replace `<yes|no>` with the appropriate answer.*  \n",
            "\n",
            "**Example**\n",
            "\n",
            "Input: `Lazy woke excuse to justify sjw practices`\n",
            "\n",
            "Output:\n",
            "```\n",
            "stereotype: yes\n",
            "vilification: yes\n",
            "dehumanization: no\n",
            "extreme_language: yes\n",
            "lack_of_empathy: no\n",
            "invalidation: yes\n",
            "```\n",
            "\n",
            "Now process the given sentence and produce the six‑line answer following the exact format above.\n",
            "\n",
            "2025/12/09 10:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/12/09 10:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "2025/12/09 10:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
            "\n",
            "2025/12/09 10:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 13 - Full Evaluation of Default Program ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 87.50 / 100 (87.5%): 100%|██████████| 100/100 [00:00<00:00, 1412.55it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:33:33 INFO dspy.evaluate.evaluate: Average Metric: 87.5 / 100 (87.5%)\n",
            "2025/12/09 10:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 87.5\n",
            "\n",
            "/Users/0ssamaak0/miniconda3/envs/nlp/lib/python3.13/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "2025/12/09 10:33:33 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 31.17 / 35 (89.0%): 100%|██████████| 35/35 [00:20<00:00,  1.68it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:33:54 INFO dspy.evaluate.evaluate: Average Metric: 31.166666666666668 / 35 (89.0%)\n",
            "2025/12/09 10:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 89.05 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
            "2025/12/09 10:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [89.05]\n",
            "2025/12/09 10:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5]\n",
            "2025/12/09 10:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 10:33:54 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 28.50 / 35 (81.4%): 100%|██████████| 35/35 [00:28<00:00,  1.21it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:34:23 INFO dspy.evaluate.evaluate: Average Metric: 28.5 / 35 (81.4%)\n",
            "2025/12/09 10:34:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 81.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/12/09 10:34:23 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [89.05, 81.43]\n",
            "2025/12/09 10:34:23 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5]\n",
            "2025/12/09 10:34:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:34:23 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 10:34:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 29.33 / 35 (83.8%): 100%|██████████| 35/35 [00:22<00:00,  1.57it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:34:45 INFO dspy.evaluate.evaluate: Average Metric: 29.333333333333332 / 35 (83.8%)\n",
            "2025/12/09 10:34:45 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 83.81 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5'].\n",
            "2025/12/09 10:34:45 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [89.05, 81.43, 83.81]\n",
            "2025/12/09 10:34:45 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5]\n",
            "2025/12/09 10:34:45 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:34:45 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 10:34:45 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 27.17 / 35 (77.6%): 100%|██████████| 35/35 [00:23<00:00,  1.49it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:35:09 INFO dspy.evaluate.evaluate: Average Metric: 27.166666666666668 / 35 (77.6%)\n",
            "2025/12/09 10:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.62 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 2'].\n",
            "2025/12/09 10:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [89.05, 81.43, 83.81, 77.62]\n",
            "2025/12/09 10:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5]\n",
            "2025/12/09 10:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 10:35:09 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 31.33 / 35 (89.5%): 100%|██████████| 35/35 [00:16<00:00,  2.12it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:35:25 INFO dspy.evaluate.evaluate: Average Metric: 31.333333333333332 / 35 (89.5%)\n",
            "2025/12/09 10:35:25 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 89.52 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
            "2025/12/09 10:35:25 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [89.05, 81.43, 83.81, 77.62, 89.52]\n",
            "2025/12/09 10:35:25 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5]\n",
            "2025/12/09 10:35:25 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:35:25 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 10:35:25 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 13 - Full Evaluation =====\n",
            "2025/12/09 10:35:25 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 89.52) from minibatch trials...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 87.00 / 100 (87.0%): 100%|██████████| 100/100 [00:25<00:00,  3.90it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:35:51 INFO dspy.evaluate.evaluate: Average Metric: 87.0 / 100 (87.0%)\n",
            "2025/12/09 10:35:51 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5, 87.0]\n",
            "2025/12/09 10:35:51 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:35:51 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
            "2025/12/09 10:35:51 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/12/09 10:35:51 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 8 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 31.00 / 35 (88.6%): 100%|██████████| 35/35 [00:15<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:36:06 INFO dspy.evaluate.evaluate: Average Metric: 31.0 / 35 (88.6%)\n",
            "2025/12/09 10:36:06 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 88.57 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/12/09 10:36:06 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [89.05, 81.43, 83.81, 77.62, 89.52, 88.57]\n",
            "2025/12/09 10:36:06 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5, 87.0]\n",
            "2025/12/09 10:36:06 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:36:06 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 10:36:06 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 9 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 30.50 / 35 (87.1%): 100%|██████████| 35/35 [00:24<00:00,  1.40it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:36:31 INFO dspy.evaluate.evaluate: Average Metric: 30.5 / 35 (87.1%)\n",
            "2025/12/09 10:36:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 87.14 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
            "2025/12/09 10:36:31 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [89.05, 81.43, 83.81, 77.62, 89.52, 88.57, 87.14]\n",
            "2025/12/09 10:36:31 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5, 87.0]\n",
            "2025/12/09 10:36:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:36:31 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 10:36:31 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 10 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 29.00 / 35 (82.9%): 100%|██████████| 35/35 [00:21<00:00,  1.59it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:36:53 INFO dspy.evaluate.evaluate: Average Metric: 29.0 / 35 (82.9%)\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 82.86 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4'].\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [89.05, 81.43, 83.81, 77.62, 89.52, 88.57, 87.14, 82.86]\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5, 87.0]\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
            "\n",
            "\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 11 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 30.67 / 35 (87.6%): 100%|██████████| 35/35 [00:00<00:00, 4311.33it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:36:53 INFO dspy.evaluate.evaluate: Average Metric: 30.666666666666668 / 35 (87.6%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 87.62 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [89.05, 81.43, 83.81, 77.62, 89.52, 88.57, 87.14, 82.86, 87.62]\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5, 87.0]\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
            "\n",
            "\n",
            "2025/12/09 10:36:53 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 12 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 29.50 / 35 (84.3%): 100%|██████████| 35/35 [00:18<00:00,  1.94it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:37:11 INFO dspy.evaluate.evaluate: Average Metric: 29.5 / 35 (84.3%)\n",
            "2025/12/09 10:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 84.29 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
            "2025/12/09 10:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [89.05, 81.43, 83.81, 77.62, 89.52, 88.57, 87.14, 82.86, 87.62, 84.29]\n",
            "2025/12/09 10:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5, 87.0]\n",
            "2025/12/09 10:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
            "\n",
            "\n",
            "2025/12/09 10:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 13 - Full Evaluation =====\n",
            "2025/12/09 10:37:11 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 87.14) from minibatch trials...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 85.00 / 100 (85.0%): 100%|██████████| 100/100 [00:43<00:00,  2.30it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:37:55 INFO dspy.evaluate.evaluate: Average Metric: 85.0 / 100 (85.0%)\n",
            "2025/12/09 10:37:55 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [87.5, 87.0, 85.0]\n",
            "2025/12/09 10:37:55 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 87.5\n",
            "2025/12/09 10:37:55 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
            "2025/12/09 10:37:55 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/12/09 10:37:55 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 87.5!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from dspy.teleprompt import MIPROv2\n",
        "\n",
        "mipro = MIPROv2(\n",
        "    metric=accuracy_metric,\n",
        "    auto=\"light\",\n",
        "    teacher_settings=dict(lm=teacher_lm),\n",
        "    prompt_model=student_lm,\n",
        ")\n",
        "\n",
        "optimized_prog = mipro.compile(\n",
        "    student=dspy.Predict(PolarizationTechniques),\n",
        "    trainset=raw_train,\n",
        "    valset=raw_val,\n",
        "    requires_permission_to_run=False,\n",
        ")\n",
        "\n",
        "# # After optimization, compute your full metrics dict\n",
        "# metrics_val_opt = eval_metrics_on_dataset(optimized_prog, raw_val)\n",
        "\n",
        "# print(\"Optimized validation metrics:\", metrics_val_opt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 0.83 / 1 (83.3%):   0%|          | 0/193 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 166.33 / 193 (86.2%): 100%|██████████| 193/193 [00:00<00:00, 2805.64it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 10:37:55 INFO dspy.evaluate.evaluate: Average Metric: 166.33333333333334 / 193 (86.2%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>example_stereotype</th>\n",
              "      <th>example_vilification</th>\n",
              "      <th>example_dehumanization</th>\n",
              "      <th>example_extreme_language</th>\n",
              "      <th>example_lack_of_empathy</th>\n",
              "      <th>example_invalidation</th>\n",
              "      <th>pred_stereotype</th>\n",
              "      <th>pred_vilification</th>\n",
              "      <th>pred_dehumanization</th>\n",
              "      <th>pred_extreme_language</th>\n",
              "      <th>pred_lack_of_empathy</th>\n",
              "      <th>pred_invalidation</th>\n",
              "      <th>accuracy_metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump relies on First Amendment</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>House GOP in no rush to give more Ukraine aid after 6</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Israeli adviser to meet with US officials on war</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>so russia commits war crimes, how does that justify ukraine also c...</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [0.333]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cant wait to watch this episode of Border Security</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>Wow, thats awesome. It reminds me of the crazy things the Tamir in...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>How long will it be until human rights are stripped away? oligarch...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [0.500]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>There are no open borders here in Texas.</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>Ottawa to unveil economic update detailing deficit, new border sec...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>The White House or the asylum seekers?</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>193 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                  sentence  \\\n",
              "0                                   Donald Trump relies on First Amendment   \n",
              "1                    House GOP in no rush to give more Ukraine aid after 6   \n",
              "2                         Israeli adviser to meet with US officials on war   \n",
              "3    so russia commits war crimes, how does that justify ukraine also c...   \n",
              "4                       Cant wait to watch this episode of Border Security   \n",
              "..                                                                     ...   \n",
              "188  Wow, thats awesome. It reminds me of the crazy things the Tamir in...   \n",
              "189  How long will it be until human rights are stripped away? oligarch...   \n",
              "190                               There are no open borders here in Texas.   \n",
              "191  Ottawa to unveil economic update detailing deficit, new border sec...   \n",
              "192                                 The White House or the asylum seekers?   \n",
              "\n",
              "    example_stereotype example_vilification example_dehumanization  \\\n",
              "0                   no                   no                     no   \n",
              "1                   no                   no                     no   \n",
              "2                   no                   no                     no   \n",
              "3                   no                  yes                    yes   \n",
              "4                   no                   no                     no   \n",
              "..                 ...                  ...                    ...   \n",
              "188                 no                   no                     no   \n",
              "189                 no                   no                     no   \n",
              "190                 no                   no                     no   \n",
              "191                 no                   no                     no   \n",
              "192                 no                   no                     no   \n",
              "\n",
              "    example_extreme_language example_lack_of_empathy example_invalidation  \\\n",
              "0                         no                      no                   no   \n",
              "1                         no                      no                   no   \n",
              "2                         no                      no                   no   \n",
              "3                        yes                     yes                  yes   \n",
              "4                         no                      no                   no   \n",
              "..                       ...                     ...                  ...   \n",
              "188                       no                      no                   no   \n",
              "189                      yes                      no                   no   \n",
              "190                       no                      no                   no   \n",
              "191                       no                      no                   no   \n",
              "192                       no                      no                   no   \n",
              "\n",
              "    pred_stereotype pred_vilification pred_dehumanization  \\\n",
              "0                no                no                  no   \n",
              "1                no                no                  no   \n",
              "2                no                no                  no   \n",
              "3               yes               yes                  no   \n",
              "4                no                no                  no   \n",
              "..              ...               ...                 ...   \n",
              "188              no                no                  no   \n",
              "189             yes               yes                  no   \n",
              "190              no                no                  no   \n",
              "191              no                no                  no   \n",
              "192              no                no                  no   \n",
              "\n",
              "    pred_extreme_language pred_lack_of_empathy pred_invalidation  \\\n",
              "0                      no                   no                no   \n",
              "1                      no                   no                no   \n",
              "2                      no                   no                no   \n",
              "3                      no                  yes                no   \n",
              "4                      no                   no                no   \n",
              "..                    ...                  ...               ...   \n",
              "188                    no                   no                no   \n",
              "189                   yes                  yes                no   \n",
              "190                    no                   no                no   \n",
              "191                    no                   no                no   \n",
              "192                    no                   no                no   \n",
              "\n",
              "    accuracy_metric  \n",
              "0        ✔️ [1.000]  \n",
              "1        ✔️ [1.000]  \n",
              "2        ✔️ [1.000]  \n",
              "3        ✔️ [0.333]  \n",
              "4        ✔️ [1.000]  \n",
              "..              ...  \n",
              "188      ✔️ [1.000]  \n",
              "189      ✔️ [0.500]  \n",
              "190      ✔️ [1.000]  \n",
              "191      ✔️ [1.000]  \n",
              "192      ✔️ [1.000]  \n",
              "\n",
              "[193 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy average accuracy metric: 86.18\n"
          ]
        }
      ],
      "source": [
        "evaluate = dspy.Evaluate(\n",
        "    devset=raw_val,\n",
        "    metric=accuracy_metric,\n",
        "    display_progress=True,\n",
        "    display_table=True,   # nice overview\n",
        ")\n",
        "eval_result = evaluate(optimized_prog)\n",
        "print(\"DSPy average accuracy metric:\", eval_result.score)  # percentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation metrics: {'f1_macro': 0.46022704221867455, 'f1_micro': 0.5266272189349113, 'f1_samples': 0.14744820522022595, 'f1_weighted': 0.5194198759415818, 'precision_macro': 0.4387188178036705, 'recall_macro': 0.516920435885953, 'exact_match_ratio': np.float64(0.5906735751295337)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/0ssamaak0/miniconda3/envs/nlp/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "metrics_val = eval_metrics_on_dataset(optimized_prog, raw_val)\n",
        "print(\"Validation metrics:\", metrics_val)\n",
        "mipro_f1_macro = metrics_val[\"f1_macro\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87338638e19746efb4840590ac60e63c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ids = test_df[\"id\"]\n",
        "def predict_dataset(program, dataset):\n",
        "    rows = []\n",
        "    for i, ex in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        out = program(sentence=ex.sentence)\n",
        "        row = {\"id\": test_df.iloc[i][\"id\"]}\n",
        "        for field in LABEL_FIELDS:\n",
        "            label = getattr(out, field, \"no\")\n",
        "            if label is None:\n",
        "                label = \"no\"\n",
        "            row[field] = label2id(label)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# after you choose which model to use (classify, optimized_classify, etc.)\n",
        "test_preds_df = predict_dataset(optimized_prog, raw_test)\n",
        "\n",
        "trial_id = \"MIPRO\" + trial_id\n",
        "os.makedirs(f\"results/{trial_id}/subtask_3\", exist_ok=True)\n",
        "test_preds_df.to_csv(f\"results/{trial_id}/subtask_3/pred_{lang}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "log_path = \"logs.json\"\n",
        "\n",
        "# Load previous trials from logs.json if it exists, else create new list\n",
        "try:\n",
        "    with open(log_path, \"r\") as f:\n",
        "        trials = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    trials = []\n",
        "\n",
        "# Try to find an existing trial with the same trial_id\n",
        "found = False\n",
        "for trial in trials:\n",
        "    if trial.get(\"trial_id\") == trial_id:\n",
        "        # Add or update the language entry under subtask_3\n",
        "        if \"subtask_3\" not in trial:\n",
        "            trial[\"subtask_3\"] = {\"score\": None}\n",
        "        if \"score\" not in trial[\"subtask_3\"]:\n",
        "            trial[\"subtask_3\"][\"score\"] = None\n",
        "        # Insert/update this language result\n",
        "        trial[\"subtask_3\"][lang] = {\n",
        "            \"eval_results\": {\n",
        "                \"eval_f1_macro\": mipro_f1_macro\n",
        "            }\n",
        "        }\n",
        "        found = True\n",
        "        break\n",
        "\n",
        "if not found:\n",
        "    # Build current trial result dict and append if no matching trial_id found\n",
        "    current_trial = {\n",
        "        \"trial_id\": trial_id,\n",
        "        \"metadata\": {\n",
        "            \"approach\": \"dspy MIPROv2\",\n",
        "            \"student_model\": student_lm_name,\n",
        "            \"teacher_model\": teacher_lm_name\n",
        "        },\n",
        "        \"subtask_3\": {\n",
        "            \"score\": None,\n",
        "            lang: {\n",
        "                \"eval_results\": {\n",
        "                    \"eval_f1_macro\": mipro_f1_macro\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    trials.append(current_trial)\n",
        "\n",
        "# Save back to logs.json\n",
        "with open(log_path, \"w\") as f:\n",
        "    json.dump(trials, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the optimized program\n",
        "# Create dspy_cache dir if it doesn't exist\n",
        "os.makedirs(\"dspy_cache\", exist_ok=True)\n",
        "optimized_prog.save(f\"dspy_cache/optimized_subtask3_{lang}_dspy_miprov2_student{student_lm_name.split('/')[-1]}_teacher{teacher_lm_name.split('/')[-1]}_{trial_id}.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GEPA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from dspy import GEPA\n",
        "\n",
        "# def gepa_metric(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
        "#     \"\"\"GEPA metric for multilabel classification\"\"\"\n",
        "#     correct = 0\n",
        "#     total = len(LABEL_FIELDS)\n",
        "    \n",
        "#     mismatches = []\n",
        "#     for field in LABEL_FIELDS:\n",
        "#         gold_label = getattr(gold, field, \"no\")\n",
        "#         pred_label = getattr(pred, field, \"no\")\n",
        "#         if pred_label is None:\n",
        "#             pred_label = \"no\"\n",
        "#         if gold_label == pred_label:\n",
        "#             correct += 1\n",
        "#         else:\n",
        "#             mismatches.append((field, gold_label, pred_label))\n",
        "\n",
        "#     score = correct / total\n",
        "\n",
        "#     # When used just for Evaluate, we only need a scalar\n",
        "#     if trace is None and pred_name is None and pred_trace is None:\n",
        "#         return score\n",
        "\n",
        "#     if score == 1.0:\n",
        "#         feedback = (\n",
        "#             \"Correct. All polarization techniques were classified correctly. \"\n",
        "#             \"Keep enforcing the exact labels 'yes' or 'no' for each technique.\"\n",
        "#         )\n",
        "#     else:\n",
        "#         mismatch_details = \"; \".join([f\"{f}: gold='{g}', pred='{p}'\" for f, g, p in mismatches])\n",
        "#         feedback = (\n",
        "#             f\"Partially incorrect. Mismatches: {mismatch_details}. \"\n",
        "#             \"For each technique, output 'yes' if the sentence uses that polarization technique, \"\n",
        "#             \"otherwise output 'no'. Techniques are: stereotype, vilification, dehumanization, \"\n",
        "#             \"extreme_language, lack_of_empathy, invalidation.\"\n",
        "#         )\n",
        "\n",
        "#     return dspy.Prediction(score=score, feedback=feedback)\n",
        "\n",
        "# gepa = GEPA(\n",
        "#     metric=gepa_metric,\n",
        "#     auto=\"light\",\n",
        "#     reflection_lm=teacher_lm,  # strong LM for reflection\n",
        "#     # you can tweak these if you want more budget:\n",
        "#     # max_metric_calls=200,\n",
        "#     # max_full_evals=10,\n",
        "# )\n",
        "\n",
        "# gepa_prog = gepa.compile(\n",
        "#     student=optimized_prog,   # start from MIPRO-optimized program\n",
        "#     trainset=raw_train,\n",
        "#     valset=raw_val,\n",
        "# )\n",
        "\n",
        "# # Evaluate GEPA-optimized program\n",
        "# evaluate = dspy.Evaluate(\n",
        "#     devset=raw_val,\n",
        "#     metric=gepa_metric,\n",
        "#     display_progress=True,\n",
        "#     display_table=True,\n",
        "# )\n",
        "# eval_result = evaluate(gepa_prog)\n",
        "# print(\"GEPA DSPy average accuracy metric:\", eval_result.score)\n",
        "\n",
        "# metrics_val_gepa = eval_metrics_on_dataset(gepa_prog, raw_val)\n",
        "# print(\"GEPA validation metrics:\", metrics_val_gepa)\n",
        "# gepa_f1_macro = metrics_val_gepa[\"f1_macro\"]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
