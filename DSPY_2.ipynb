{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dspy\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "student_lm_name = \"fireworks_ai/accounts/fireworks/models/gpt-oss-20b\"\n",
        "teacher_lm_name = \"openai/gpt-5.1-2025-11-13\"\n",
        "\n",
        "if \"ollama_chat\" in student_lm_name:\n",
        "    student_lm = dspy.LM(student_lm_name, api_base='http://localhost:11434', api_key='')\n",
        "else:\n",
        "    student_lm = dspy.LM(student_lm_name)\n",
        "teacher_lm = dspy.LM(teacher_lm_name)\n",
        "\n",
        "dspy.configure(lm=student_lm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare DSPY Dataset (Subtask 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "trial_id = \"DSP0002SPRO\"\n",
        "# Train val test split\n",
        "lang = \"eng\"\n",
        "# Load the training and validation data for subtask 2\n",
        "train_df = pd.read_csv(f'./dev_phase/subtask2_pro/train/{lang}.csv')\n",
        "test_df = pd.read_csv(f'./dev_phase/subtask2_pro/dev/{lang}.csv')\n",
        "# Split train into train and validation sets\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define label columns for multilabel classification\n",
        "LABEL_COLUMNS = [\"political\", \"racial/ethnic\", \"religious\", \"gender/sexual\", \"other\"]\n",
        "\n",
        "# Map for each label: 1 -> \"yes\", 0 -> \"no\"\n",
        "LABEL_MAP = {1: \"yes\", 0: \"no\"}\n",
        "LABEL_MAP_INV = {\"yes\": 1, \"no\": 0}\n",
        "\n",
        "def make_dspy_examples(df, include_label: bool = True):\n",
        "    examples = []\n",
        "    for _, row in df.iterrows():\n",
        "        kwargs = dict(\n",
        "            sentence=row[\"text\"],\n",
        "        )\n",
        "        if include_label:\n",
        "            for col in LABEL_COLUMNS:\n",
        "                if col in row:\n",
        "                    kwargs[col.replace(\"/\", \"_\").replace(\"-\", \"_\")] = LABEL_MAP[row[col]]\n",
        "        example = dspy.Example(**kwargs).with_inputs(\"sentence\")\n",
        "        examples.append(example)\n",
        "    return examples\n",
        "\n",
        "# Create DSPY datasets\n",
        "raw_train = make_dspy_examples(train_df, include_label=True)\n",
        "raw_val = make_dspy_examples(val_df, include_label=True)\n",
        "raw_test = make_dspy_examples(test_df, include_label=False)\n",
        "\n",
        "\n",
        "# # For now take only 10% of each \n",
        "raw_train = raw_train[:int(len(raw_train) * 0.2)]\n",
        "raw_val = raw_val[:int(len(raw_val) * 0.3)]\n",
        "raw_test = raw_test[:int(len(raw_test) * 1)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define Signature (Subtask 2 - Multilabel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "\n",
        "class PolarizationMultilabel(dspy.Signature):\n",
        "    \"\"\"\n",
        "    Polarization denotes stereotyping, vilification, dehumanization, deindividuation, or intolerance of other people's views, beliefs, and identities.\n",
        "    \n",
        "    Given a sentence, classify it into one or more polarization categories:\n",
        "    - political: Political polarization targeting political groups, parties, ideologies, or political figures\n",
        "    - racial_ethnic: Racial or ethnic polarization targeting racial or ethnic groups\n",
        "    - religious: Religious polarization targeting religious groups or beliefs\n",
        "    - gender_sexual: Gender or sexual polarization targeting gender identities or sexual orientations\n",
        "    - other: Other forms of polarization not covered by the above categories\n",
        "    \n",
        "    For each category, output \"yes\" if the sentence contains that type of polarization, \"no\" otherwise.\n",
        "    A sentence can belong to multiple categories or none at all.\n",
        "    \"\"\"\n",
        "\n",
        "    sentence: str = dspy.InputField()\n",
        "    political: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence contains political polarization, \"no\" otherwise.',\n",
        "    )\n",
        "    racial_ethnic: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence contains racial/ethnic polarization, \"no\" otherwise.',\n",
        "    )\n",
        "    religious: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence contains religious polarization, \"no\" otherwise.',\n",
        "    )\n",
        "    gender_sexual: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence contains gender/sexual polarization, \"no\" otherwise.',\n",
        "    )\n",
        "    other: Literal[\"yes\", \"no\"] = dspy.OutputField(\n",
        "        desc='Return \"yes\" if the sentence contains other forms of polarization, \"no\" otherwise.',\n",
        "    )\n",
        "\n",
        "classify = dspy.Predict(PolarizationMultilabel)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "\n",
        "# Label columns with normalized names (matching dspy field names)\n",
        "LABEL_FIELDS = [\"political\", \"racial_ethnic\", \"religious\", \"gender_sexual\", \"other\"]\n",
        "\n",
        "def label2id(label: str) -> int:\n",
        "    return LABEL_MAP_INV.get(label, 0)\n",
        "\n",
        "def id2label(i: int) -> str:\n",
        "    return LABEL_MAP[i]\n",
        "\n",
        "def accuracy_metric(example, pred, trace=None):\n",
        "    \"\"\"Compute accuracy as exact match across all labels\"\"\"\n",
        "    correct = 0\n",
        "    total = len(LABEL_FIELDS)\n",
        "    for field in LABEL_FIELDS:\n",
        "        gold = getattr(example, field, \"no\")\n",
        "        guess = getattr(pred, field, \"no\")\n",
        "        if guess is None:\n",
        "            guess = \"no\"\n",
        "        if gold == guess:\n",
        "            correct += 1\n",
        "    return correct / total  # Return fraction of correct labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 176.00 / 193 (91.2%): 100%|██████████| 193/193 [00:34<00:00,  5.52it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:49:26 INFO dspy.evaluate.evaluate: Average Metric: 176.0 / 193 (91.2%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>example_political</th>\n",
              "      <th>example_racial_ethnic</th>\n",
              "      <th>example_religious</th>\n",
              "      <th>example_gender_sexual</th>\n",
              "      <th>example_other</th>\n",
              "      <th>pred_political</th>\n",
              "      <th>pred_racial_ethnic</th>\n",
              "      <th>pred_religious</th>\n",
              "      <th>pred_gender_sexual</th>\n",
              "      <th>pred_other</th>\n",
              "      <th>accuracy_metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump relies on First Amendment</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>House GOP in no rush to give more Ukraine aid after 6</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [0.800]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>country_xi adviser to meet with US officials on war</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>so russia commits war crimes, how does that justify ukraine also c...</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cant wait to watch this episode of Border Security</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>Wow, thats awesome. It reminds me of the crazy things the Tamir in...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>How long will it be until human rights are stripped away? oligarch...</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [0.800]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>There are no open borders here in Texas.</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>Ottawa to unveil economic update detailing deficit, new border sec...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>The White House or the asylum seekers?</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [0.800]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>193 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                  sentence  \\\n",
              "0                                   Donald Trump relies on First Amendment   \n",
              "1                    House GOP in no rush to give more Ukraine aid after 6   \n",
              "2                      country_xi adviser to meet with US officials on war   \n",
              "3    so russia commits war crimes, how does that justify ukraine also c...   \n",
              "4                       Cant wait to watch this episode of Border Security   \n",
              "..                                                                     ...   \n",
              "188  Wow, thats awesome. It reminds me of the crazy things the Tamir in...   \n",
              "189  How long will it be until human rights are stripped away? oligarch...   \n",
              "190                               There are no open borders here in Texas.   \n",
              "191  Ottawa to unveil economic update detailing deficit, new border sec...   \n",
              "192                                 The White House or the asylum seekers?   \n",
              "\n",
              "    example_political example_racial_ethnic example_religious  \\\n",
              "0                  no                    no                no   \n",
              "1                  no                    no                no   \n",
              "2                  no                    no                no   \n",
              "3                 yes                    no                no   \n",
              "4                  no                    no                no   \n",
              "..                ...                   ...               ...   \n",
              "188                no                    no                no   \n",
              "189               yes                    no                no   \n",
              "190                no                    no                no   \n",
              "191                no                    no                no   \n",
              "192                no                    no                no   \n",
              "\n",
              "    example_gender_sexual example_other pred_political pred_racial_ethnic  \\\n",
              "0                      no            no             no                 no   \n",
              "1                      no            no            yes                 no   \n",
              "2                      no            no             no                 no   \n",
              "3                      no            no            yes                 no   \n",
              "4                      no            no             no                 no   \n",
              "..                    ...           ...            ...                ...   \n",
              "188                    no            no             no                 no   \n",
              "189                    no            no             no                 no   \n",
              "190                    no            no             no                 no   \n",
              "191                    no            no             no                 no   \n",
              "192                    no            no            yes                 no   \n",
              "\n",
              "    pred_religious pred_gender_sexual pred_other accuracy_metric  \n",
              "0               no                 no         no      ✔️ [1.000]  \n",
              "1               no                 no         no      ✔️ [0.800]  \n",
              "2               no                 no         no      ✔️ [1.000]  \n",
              "3               no                 no         no      ✔️ [1.000]  \n",
              "4               no                 no         no      ✔️ [1.000]  \n",
              "..             ...                ...        ...             ...  \n",
              "188             no                 no         no      ✔️ [1.000]  \n",
              "189             no                 no         no      ✔️ [0.800]  \n",
              "190             no                 no         no      ✔️ [1.000]  \n",
              "191             no                 no         no      ✔️ [1.000]  \n",
              "192             no                 no         no      ✔️ [0.800]  \n",
              "\n",
              "[193 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy average accuracy metric: 91.19\n"
          ]
        }
      ],
      "source": [
        "evaluate = dspy.Evaluate(\n",
        "    devset=raw_val,\n",
        "    metric=accuracy_metric,\n",
        "    display_progress=True,\n",
        "    display_table=True,   # nice overview\n",
        ")\n",
        "eval_result = evaluate(classify)\n",
        "print(\"DSPy average accuracy metric:\", eval_result.score)  # percentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation metrics: {'f1_macro': 0.46280423280423283, 'f1_micro': 0.5728643216080402, 'f1_samples': 0.2023686158401184, 'f1_weighted': 0.5587832102537985, 'precision_macro': 0.5207142857142857, 'recall_macro': 0.44982905982905985, 'exact_match_ratio': np.float64(0.6476683937823834)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/0ssamaak0/miniconda3/envs/nlp/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "def eval_metrics_on_dataset(program, dataset):\n",
        "    \"\"\"Compute multilabel classification metrics\"\"\"\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for ex in dataset:\n",
        "        pred = program(sentence=ex.sentence)\n",
        "        \n",
        "        gold_labels = []\n",
        "        pred_labels = []\n",
        "        \n",
        "        for field in LABEL_FIELDS:\n",
        "            gold = getattr(ex, field, \"no\")\n",
        "            guess = getattr(pred, field, \"no\")\n",
        "            if guess is None:\n",
        "                guess = \"no\"\n",
        "            gold_labels.append(label2id(gold))\n",
        "            pred_labels.append(label2id(guess))\n",
        "        \n",
        "        y_true.append(gold_labels)\n",
        "        y_pred.append(pred_labels)\n",
        "\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    return {\n",
        "        'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
        "        'f1_micro': f1_score(y_true, y_pred, average='micro'),\n",
        "        'f1_samples': f1_score(y_true, y_pred, average='samples'),\n",
        "        'f1_weighted': f1_score(y_true, y_pred, average='weighted'),\n",
        "        'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "        'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "        'exact_match_ratio': np.mean(np.all(y_true == y_pred, axis=1)),\n",
        "    }\n",
        "\n",
        "metrics_val = eval_metrics_on_dataset(classify, raw_val)\n",
        "print(\"Validation metrics:\", metrics_val)\n",
        "\n",
        "# metrics_test = eval_metrics_on_dataset(classify, raw_test)\n",
        "# print(\"Test metrics:\", metrics_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "student_f1_macro = metrics_val[\"f1_macro\"]\n",
        "import json\n",
        "\n",
        "# Build current language entry for subtask_2\n",
        "lang_entry = {\n",
        "    \"eval_results\": {\n",
        "        \"eval_f1_macro\": student_f1_macro\n",
        "    }\n",
        "}\n",
        "\n",
        "# Load previous trials from logs.json if it exists, else create new list\n",
        "log_path = \"logs.json\"\n",
        "try:\n",
        "    with open(log_path, \"r\") as f:\n",
        "        trials = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    trials = []\n",
        "\n",
        "# Look for existing trial by trial_id\n",
        "found = False\n",
        "for trial in trials:\n",
        "    if trial.get(\"trial_id\") == trial_id:\n",
        "        # Insert or update lang in subtask_2\n",
        "        if \"subtask_2\" not in trial:\n",
        "            trial[\"subtask_2\"] = {\"score\": None}\n",
        "        if \"score\" not in trial[\"subtask_2\"]:\n",
        "            trial[\"subtask_2\"][\"score\"] = None\n",
        "        trial[\"subtask_2\"][lang] = lang_entry\n",
        "        found = True\n",
        "        break\n",
        "\n",
        "if not found:\n",
        "    # Build new trial dict if trial_id not found\n",
        "    current_trial = {\n",
        "        \"trial_id\": trial_id,\n",
        "        \"metadata\": {\n",
        "            \"approach\": \"dspy basic\",\n",
        "            \"model\": student_lm_name\n",
        "        },\n",
        "        \"subtask_2\": {\n",
        "            \"score\": None,\n",
        "            lang: lang_entry\n",
        "        }\n",
        "    }\n",
        "    trials.append(current_trial)\n",
        "\n",
        "# Save back to logs.json\n",
        "with open(log_path, \"w\") as f:\n",
        "    json.dump(trials, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d44872904d3e4731be239806155d8206",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                     id  political  racial/ethnic  religious  \\\n",
            "0  eng_f66ca14d60851371f9720aaf4ccd9b58          0              0          0   \n",
            "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb          0              0          0   \n",
            "2  eng_95770ff547ea5e48b0be00f385986483          0              0          0   \n",
            "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf          0              0          0   \n",
            "4  eng_07781aa88e61e7c0a996abd1e5ea3a20          0              0          0   \n",
            "\n",
            "   gender/sexual  other  \n",
            "0              0      0  \n",
            "1              0      0  \n",
            "2              0      0  \n",
            "3              0      0  \n",
            "4              0      0  \n"
          ]
        }
      ],
      "source": [
        "ids = test_df[\"id\"]\n",
        "\n",
        "# Map field names back to original CSV column names\n",
        "FIELD_TO_COL = {\n",
        "    \"political\": \"political\",\n",
        "    \"racial_ethnic\": \"racial/ethnic\",\n",
        "    \"religious\": \"religious\",\n",
        "    \"gender_sexual\": \"gender/sexual\",\n",
        "    \"other\": \"other\"\n",
        "}\n",
        "\n",
        "def predict_dataset(program, dataset):\n",
        "    rows = []\n",
        "    for i, ex in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        out = program(sentence=ex.sentence)\n",
        "        row = {\"id\": test_df.iloc[i][\"id\"]}\n",
        "        for field in LABEL_FIELDS:\n",
        "            label = getattr(out, field, \"no\")\n",
        "            if label is None:\n",
        "                label = \"no\"\n",
        "            col_name = FIELD_TO_COL[field]\n",
        "            row[col_name] = label2id(label)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "\n",
        "# after you choose which model to use (classify, optimized_classify, etc.)\n",
        "test_preds_df = predict_dataset(classify, raw_test)\n",
        "\n",
        "print(test_preds_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# in results create dir with trial_id and create subtask_2 inside it, then save the csv as \"pred_lang.csv\" inside it\n",
        "import os\n",
        "os.makedirs(f\"results/{trial_id}/subtask_2\", exist_ok=True)\n",
        "test_preds_df.to_csv(f\"results/{trial_id}/subtask_2/pred_{lang}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using MIPROv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:51:39 WARNING dspy.teleprompt.mipro_optimizer_v2: 'requires_permission_to_run' is deprecated and will be removed in a future version.\n",
            "2025/12/09 09:51:39 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
            "num_trials: 10\n",
            "minibatch: True\n",
            "num_fewshot_candidates: 6\n",
            "num_instruct_candidates: 3\n",
            "valset size: 100\n",
            "\n",
            "2025/12/09 09:51:39 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
            "2025/12/09 09:51:39 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
            "\n",
            "2025/12/09 09:51:39 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapping set 1/6\n",
            "Bootstrapping set 2/6\n",
            "Bootstrapping set 3/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 4/515 [00:07<15:11,  1.78s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
            "Bootstrapping set 4/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/515 [00:00<00:08, 59.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 5/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1/515 [00:01<11:08,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
            "Bootstrapping set 6/6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 3/515 [00:00<00:07, 65.13it/s]\n",
            "2025/12/09 09:51:47 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
            "2025/12/09 09:51:47 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:52:30 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=None. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently None)  if the reason for truncation is repetition.\n",
            "2025/12/09 09:52:34 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "Proposing N=3 instructions...\n",
            "\n",
            "2025/12/09 09:53:26 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
            "\n",
            "2025/12/09 09:53:26 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Polarization denotes stereotyping, vilification, dehumanization, deindividuation, or intolerance of other people's views, beliefs, and identities.\n",
            "\n",
            "Given a sentence, classify it into one or more polarization categories:\n",
            "- political: Political polarization targeting political groups, parties, ideologies, or political figures\n",
            "- racial_ethnic: Racial or ethnic polarization targeting racial or ethnic groups\n",
            "- religious: Religious polarization targeting religious groups or beliefs\n",
            "- gender_sexual: Gender or sexual polarization targeting gender identities or sexual orientations\n",
            "- other: Other forms of polarization not covered by the above categories\n",
            "\n",
            "For each category, output \"yes\" if the sentence contains that type of polarization, \"no\" otherwise.\n",
            "A sentence can belong to multiple categories or none at all.\n",
            "\n",
            "2025/12/09 09:53:26 INFO dspy.teleprompt.mipro_optimizer_v2: 1: You are a content moderation assistant.  \n",
            "Given a single sentence, decide whether it contains polarization toward one or more of the following five axes.  \n",
            "For each axis output **yes** if the sentence contains that type of polarization, otherwise output **no**.\n",
            "\n",
            "| Axis | Definition |\n",
            "|------|------------|\n",
            "| **political** | Criticism, support, or otherwise polarization toward a political group, party, ideology, or political figure. |\n",
            "| **racial_ethnic** | Polarization targeting a racial or ethnic group. |\n",
            "| **religious** | Polarization targeting a religious group or belief system. |\n",
            "| **gender_sexual** | Polarization targeting a gender identity or sexual orientation. |\n",
            "| **other** | Any other form of polarization not covered above (e.g., general harassment, profanity). |\n",
            "\n",
            "**Output format**: Exactly five lines, one per axis in the order above, each containing the word **yes** or **no**.  \n",
            "Do **not** provide any other text.\n",
            "\n",
            "**Example**  \n",
            "Input: *“Lazy woke excuse to justify sjw practices”*  \n",
            "\n",
            "Output:  \n",
            "```\n",
            "political: yes\n",
            "racial_ethnic: no\n",
            "religious: no\n",
            "gender_sexual: no\n",
            "other: no\n",
            "```\n",
            "\n",
            "2025/12/09 09:53:26 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You will receive a single English sentence. Decide whether the sentence contains polarization in any of five categories: political, racial_ethnic, religious, gender_sexual, and other. Produce a JSON object with the fields in this exact order—political, racial_ethnic, religious, gender_sexual, other. For each field, write \"yes\" if the sentence exhibits that type of polarization, otherwise write \"no\".\n",
            "\n",
            "Definitions:\n",
            "- **Political**: Critique, support, or dehumanization directed at political parties, leaders, ideologies, or governmental actions.\n",
            "- **Racial/Ethnic**: Targeting is based on race, ethnicity, or nationality.\n",
            "- **Religious**: Targeting is based on religious beliefs, affiliations, or institutions.\n",
            "- **Gender/Sexual**: Targeting is based on gender identity, sexual orientation, or related social stereotypes.\n",
            "- **Other**: Any form of polarization that does not fit the above categories (e.g., explicit hate or harassment toward any group).\n",
            "\n",
            "If the sentence contains no polarization, all fields should be \"no\". Include no additional text in the response. Example: \n",
            "Input: \"Lazy woke excuse to justify sjw practices\" \n",
            "Output: {\"political\":\"yes\",\"racial_ethnic\":\"no\",\"religious\":\"no\",\"gender_sexual\":\"no\",\"other\":\"no\"}\n",
            "\n",
            "Follow this format strictly for every input sentence.\n",
            "\n",
            "2025/12/09 09:53:26 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/12/09 09:53:26 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
            "2025/12/09 09:53:26 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
            "\n",
            "2025/12/09 09:53:26 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 13 - Full Evaluation of Default Program ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 92.00 / 100 (92.0%): 100%|██████████| 100/100 [00:00<00:00, 1808.52it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:53:26 INFO dspy.evaluate.evaluate: Average Metric: 92.0 / 100 (92.0%)\n",
            "2025/12/09 09:53:26 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 92.0\n",
            "\n",
            "/Users/0ssamaak0/miniconda3/envs/nlp/lib/python3.13/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "2025/12/09 09:53:26 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 30.60 / 35 (87.4%): 100%|██████████| 35/35 [00:23<00:00,  1.51it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:53:49 INFO dspy.evaluate.evaluate: Average Metric: 30.6 / 35 (87.4%)\n",
            "2025/12/09 09:53:49 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 87.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
            "2025/12/09 09:53:49 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [87.43]\n",
            "2025/12/09 09:53:49 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0]\n",
            "2025/12/09 09:53:49 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:53:49 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 09:53:49 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 30.80 / 35 (88.0%): 100%|██████████| 35/35 [00:30<00:00,  1.14it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:54:20 INFO dspy.evaluate.evaluate: Average Metric: 30.8 / 35 (88.0%)\n",
            "2025/12/09 09:54:20 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 88.0 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/12/09 09:54:20 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [87.43, 88.0]\n",
            "2025/12/09 09:54:20 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0]\n",
            "2025/12/09 09:54:20 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:54:20 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 09:54:20 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 30.80 / 35 (88.0%): 100%|██████████| 35/35 [00:33<00:00,  1.04it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:54:54 INFO dspy.evaluate.evaluate: Average Metric: 30.8 / 35 (88.0%)\n",
            "2025/12/09 09:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 88.0 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5'].\n",
            "2025/12/09 09:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [87.43, 88.0, 88.0]\n",
            "2025/12/09 09:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0]\n",
            "2025/12/09 09:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 09:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 29.60 / 35 (84.6%): 100%|██████████| 35/35 [00:23<00:00,  1.48it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:55:17 INFO dspy.evaluate.evaluate: Average Metric: 29.6 / 35 (84.6%)\n",
            "2025/12/09 09:55:17 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 84.57 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 2'].\n",
            "2025/12/09 09:55:17 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [87.43, 88.0, 88.0, 84.57]\n",
            "2025/12/09 09:55:17 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0]\n",
            "2025/12/09 09:55:17 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:55:17 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 09:55:17 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 33.00 / 35 (94.3%): 100%|██████████| 35/35 [00:05<00:00,  6.68it/s]  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:55:22 INFO dspy.evaluate.evaluate: Average Metric: 33.0 / 35 (94.3%)\n",
            "2025/12/09 09:55:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 94.29 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
            "2025/12/09 09:55:23 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [87.43, 88.0, 88.0, 84.57, 94.29]\n",
            "2025/12/09 09:55:23 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0]\n",
            "2025/12/09 09:55:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:55:23 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 09:55:23 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 13 - Full Evaluation =====\n",
            "2025/12/09 09:55:23 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 94.29) from minibatch trials...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 92.00 / 100 (92.0%): 100%|██████████| 100/100 [00:06<00:00, 16.22it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:55:29 INFO dspy.evaluate.evaluate: Average Metric: 92.0 / 100 (92.0%)\n",
            "2025/12/09 09:55:29 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0, 92.0]\n",
            "2025/12/09 09:55:29 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:55:29 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
            "2025/12/09 09:55:29 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/12/09 09:55:29 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 8 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 30.80 / 35 (88.0%): 100%|██████████| 35/35 [00:18<00:00,  1.94it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:55:47 INFO dspy.evaluate.evaluate: Average Metric: 30.8 / 35 (88.0%)\n",
            "2025/12/09 09:55:47 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 88.0 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
            "2025/12/09 09:55:47 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [87.43, 88.0, 88.0, 84.57, 94.29, 88.0]\n",
            "2025/12/09 09:55:47 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0, 92.0]\n",
            "2025/12/09 09:55:47 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:55:47 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 09:55:47 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 9 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 31.40 / 35 (89.7%): 100%|██████████| 35/35 [00:22<00:00,  1.52it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:56:10 INFO dspy.evaluate.evaluate: Average Metric: 31.400000000000002 / 35 (89.7%)\n",
            "2025/12/09 09:56:10 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 89.71 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
            "2025/12/09 09:56:10 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [87.43, 88.0, 88.0, 84.57, 94.29, 88.0, 89.71]\n",
            "2025/12/09 09:56:10 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0, 92.0]\n",
            "2025/12/09 09:56:10 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:56:10 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
            "\n",
            "\n",
            "2025/12/09 09:56:10 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 10 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 30.60 / 35 (87.4%): 100%|██████████| 35/35 [00:25<00:00,  1.37it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:56:35 INFO dspy.evaluate.evaluate: Average Metric: 30.6 / 35 (87.4%)\n",
            "2025/12/09 09:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 87.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4'].\n",
            "2025/12/09 09:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [87.43, 88.0, 88.0, 84.57, 94.29, 88.0, 89.71, 87.43]\n",
            "2025/12/09 09:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0, 92.0]\n",
            "2025/12/09 09:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
            "\n",
            "\n",
            "2025/12/09 09:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 11 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 33.00 / 35 (94.3%): 100%|██████████| 35/35 [00:00<00:00, 1284.41it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:56:36 INFO dspy.evaluate.evaluate: Average Metric: 33.0 / 35 (94.3%)\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 94.29 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [87.43, 88.0, 88.0, 84.57, 94.29, 88.0, 89.71, 87.43, 94.29]\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0, 92.0]\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
            "\n",
            "\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 12 / 13 - Minibatch ==\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 31.20 / 35 (89.1%): 100%|██████████| 35/35 [00:00<00:00, 4072.14it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:56:36 INFO dspy.evaluate.evaluate: Average Metric: 31.2 / 35 (89.1%)\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 89.14 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [87.43, 88.0, 88.0, 84.57, 94.29, 88.0, 89.71, 87.43, 94.29, 89.14]\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0, 92.0]\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
            "\n",
            "\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 13 - Full Evaluation =====\n",
            "2025/12/09 09:56:36 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 89.71) from minibatch trials...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Average Metric: 90.60 / 100 (90.6%): 100%|██████████| 100/100 [00:36<00:00,  2.76it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:57:12 INFO dspy.evaluate.evaluate: Average Metric: 90.60000000000001 / 100 (90.6%)\n",
            "2025/12/09 09:57:12 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [92.0, 92.0, 90.6]\n",
            "2025/12/09 09:57:12 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 92.0\n",
            "2025/12/09 09:57:12 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
            "2025/12/09 09:57:12 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
            "\n",
            "2025/12/09 09:57:12 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 92.0!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from dspy.teleprompt import MIPROv2\n",
        "\n",
        "mipro = MIPROv2(\n",
        "    metric=accuracy_metric,\n",
        "    auto=\"light\",\n",
        "    teacher_settings=dict(lm=teacher_lm),\n",
        "    prompt_model=student_lm,\n",
        ")\n",
        "\n",
        "optimized_prog = mipro.compile(\n",
        "    student=dspy.Predict(PolarizationMultilabel),\n",
        "    trainset=raw_train,\n",
        "    valset=raw_val,\n",
        "    requires_permission_to_run=False,\n",
        ")\n",
        "\n",
        "# # After optimization, compute your full metrics dict\n",
        "# metrics_val_opt = eval_metrics_on_dataset(optimized_prog, raw_val)\n",
        "\n",
        "# print(\"Optimized validation metrics:\", metrics_val_opt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Metric: 176.00 / 193 (91.2%): 100%|██████████| 193/193 [00:00<00:00, 4541.48it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/09 09:57:12 INFO dspy.evaluate.evaluate: Average Metric: 176.0 / 193 (91.2%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>example_political</th>\n",
              "      <th>example_racial_ethnic</th>\n",
              "      <th>example_religious</th>\n",
              "      <th>example_gender_sexual</th>\n",
              "      <th>example_other</th>\n",
              "      <th>pred_political</th>\n",
              "      <th>pred_racial_ethnic</th>\n",
              "      <th>pred_religious</th>\n",
              "      <th>pred_gender_sexual</th>\n",
              "      <th>pred_other</th>\n",
              "      <th>accuracy_metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump relies on First Amendment</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>House GOP in no rush to give more Ukraine aid after 6</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [0.800]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>country_xi adviser to meet with US officials on war</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>so russia commits war crimes, how does that justify ukraine also c...</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cant wait to watch this episode of Border Security</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>Wow, thats awesome. It reminds me of the crazy things the Tamir in...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>How long will it be until human rights are stripped away? oligarch...</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [0.800]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>There are no open borders here in Texas.</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>Ottawa to unveil economic update detailing deficit, new border sec...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [1.000]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>The White House or the asylum seekers?</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>✔️ [0.800]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>193 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                  sentence  \\\n",
              "0                                   Donald Trump relies on First Amendment   \n",
              "1                    House GOP in no rush to give more Ukraine aid after 6   \n",
              "2                      country_xi adviser to meet with US officials on war   \n",
              "3    so russia commits war crimes, how does that justify ukraine also c...   \n",
              "4                       Cant wait to watch this episode of Border Security   \n",
              "..                                                                     ...   \n",
              "188  Wow, thats awesome. It reminds me of the crazy things the Tamir in...   \n",
              "189  How long will it be until human rights are stripped away? oligarch...   \n",
              "190                               There are no open borders here in Texas.   \n",
              "191  Ottawa to unveil economic update detailing deficit, new border sec...   \n",
              "192                                 The White House or the asylum seekers?   \n",
              "\n",
              "    example_political example_racial_ethnic example_religious  \\\n",
              "0                  no                    no                no   \n",
              "1                  no                    no                no   \n",
              "2                  no                    no                no   \n",
              "3                 yes                    no                no   \n",
              "4                  no                    no                no   \n",
              "..                ...                   ...               ...   \n",
              "188                no                    no                no   \n",
              "189               yes                    no                no   \n",
              "190                no                    no                no   \n",
              "191                no                    no                no   \n",
              "192                no                    no                no   \n",
              "\n",
              "    example_gender_sexual example_other pred_political pred_racial_ethnic  \\\n",
              "0                      no            no             no                 no   \n",
              "1                      no            no            yes                 no   \n",
              "2                      no            no             no                 no   \n",
              "3                      no            no            yes                 no   \n",
              "4                      no            no             no                 no   \n",
              "..                    ...           ...            ...                ...   \n",
              "188                    no            no             no                 no   \n",
              "189                    no            no             no                 no   \n",
              "190                    no            no             no                 no   \n",
              "191                    no            no             no                 no   \n",
              "192                    no            no            yes                 no   \n",
              "\n",
              "    pred_religious pred_gender_sexual pred_other accuracy_metric  \n",
              "0               no                 no         no      ✔️ [1.000]  \n",
              "1               no                 no         no      ✔️ [0.800]  \n",
              "2               no                 no         no      ✔️ [1.000]  \n",
              "3               no                 no         no      ✔️ [1.000]  \n",
              "4               no                 no         no      ✔️ [1.000]  \n",
              "..             ...                ...        ...             ...  \n",
              "188             no                 no         no      ✔️ [1.000]  \n",
              "189             no                 no         no      ✔️ [0.800]  \n",
              "190             no                 no         no      ✔️ [1.000]  \n",
              "191             no                 no         no      ✔️ [1.000]  \n",
              "192             no                 no         no      ✔️ [0.800]  \n",
              "\n",
              "[193 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DSPy average accuracy metric: 91.19\n"
          ]
        }
      ],
      "source": [
        "evaluate = dspy.Evaluate(\n",
        "    devset=raw_val,\n",
        "    metric=accuracy_metric,\n",
        "    display_progress=True,\n",
        "    display_table=True,   # nice overview\n",
        ")\n",
        "eval_result = evaluate(optimized_prog)\n",
        "print(\"DSPy average accuracy metric:\", eval_result.score)  # percentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation metrics: {'f1_macro': 0.46280423280423283, 'f1_micro': 0.5728643216080402, 'f1_samples': 0.2023686158401184, 'f1_weighted': 0.5587832102537985, 'precision_macro': 0.5207142857142857, 'recall_macro': 0.44982905982905985, 'exact_match_ratio': np.float64(0.6476683937823834)}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/0ssamaak0/miniconda3/envs/nlp/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
          ]
        }
      ],
      "source": [
        "metrics_val = eval_metrics_on_dataset(optimized_prog, raw_val)\n",
        "print(\"Validation metrics:\", metrics_val)\n",
        "mipro_f1_macro = metrics_val[\"f1_macro\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73c637403ac847ee80921544bb755dea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/160 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ids = test_df[\"id\"]\n",
        "def predict_dataset(program, dataset):\n",
        "    rows = []\n",
        "    for i, ex in tqdm(enumerate(dataset), total=len(dataset)):\n",
        "        out = program(sentence=ex.sentence)\n",
        "        row = {\"id\": test_df.iloc[i][\"id\"]}\n",
        "        for field in LABEL_FIELDS:\n",
        "            label = getattr(out, field, \"no\")\n",
        "            if label is None:\n",
        "                label = \"no\"\n",
        "            col_name = FIELD_TO_COL[field]\n",
        "            row[col_name] = label2id(label)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "\n",
        "# after you choose which model to use (classify, optimized_classify, etc.)\n",
        "test_preds_df = predict_dataset(optimized_prog, raw_test)\n",
        "\n",
        "trial_id = \"MIPRO\" + trial_id\n",
        "os.makedirs(f\"results/{trial_id}/subtask_2\", exist_ok=True)\n",
        "test_preds_df.to_csv(f\"results/{trial_id}/subtask_2/pred_{lang}.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "log_path = \"logs.json\"\n",
        "\n",
        "# Load previous trials from logs.json if it exists, else create new list\n",
        "try:\n",
        "    with open(log_path, \"r\") as f:\n",
        "        trials = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    trials = []\n",
        "\n",
        "# Try to find an existing trial with the same trial_id\n",
        "found = False\n",
        "for trial in trials:\n",
        "    if trial.get(\"trial_id\") == trial_id:\n",
        "        # Add or update the language entry under subtask_2\n",
        "        if \"subtask_2\" not in trial:\n",
        "            trial[\"subtask_2\"] = {\"score\": None}\n",
        "        if \"score\" not in trial[\"subtask_2\"]:\n",
        "            trial[\"subtask_2\"][\"score\"] = None\n",
        "        # Insert/update this language result\n",
        "        trial[\"subtask_2\"][lang] = {\n",
        "            \"eval_results\": {\n",
        "                \"eval_f1_macro\": mipro_f1_macro\n",
        "            }\n",
        "        }\n",
        "        found = True\n",
        "        break\n",
        "\n",
        "if not found:\n",
        "    # Build current trial result dict and append if no matching trial_id found\n",
        "    current_trial = {\n",
        "        \"trial_id\": trial_id,\n",
        "        \"metadata\": {\n",
        "            \"approach\": \"dspy MIPROv2\",\n",
        "            \"student_model\": student_lm_name,\n",
        "            \"teacher_model\": teacher_lm_name\n",
        "        },\n",
        "        \"subtask_2\": {\n",
        "            \"score\": None,\n",
        "            lang: {\n",
        "                \"eval_results\": {\n",
        "                    \"eval_f1_macro\": mipro_f1_macro\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    trials.append(current_trial)\n",
        "\n",
        "# Save back to logs.json\n",
        "with open(log_path, \"w\") as f:\n",
        "    json.dump(trials, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the optimized program\n",
        "# Create dspy_cache dir if it doesn't exist\n",
        "os.makedirs(\"dspy_cache\", exist_ok=True)\n",
        "optimized_prog.save(f\"dspy_cache/optimized_subtask2_{lang}_dspy_miprov2_student{student_lm_name.split('/')[-1]}_teacher{teacher_lm_name.split('/')[-1]}_{trial_id}.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GEPA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from dspy import GEPA\n",
        "\n",
        "# def gepa_metric(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
        "#     \"\"\"GEPA metric for multilabel classification\"\"\"\n",
        "#     correct = 0\n",
        "#     total = len(LABEL_FIELDS)\n",
        "    \n",
        "#     mismatches = []\n",
        "#     for field in LABEL_FIELDS:\n",
        "#         gold_label = getattr(gold, field, \"no\")\n",
        "#         pred_label = getattr(pred, field, \"no\")\n",
        "#         if pred_label is None:\n",
        "#             pred_label = \"no\"\n",
        "#         if gold_label == pred_label:\n",
        "#             correct += 1\n",
        "#         else:\n",
        "#             mismatches.append((field, gold_label, pred_label))\n",
        "\n",
        "#     score = correct / total\n",
        "\n",
        "#     # When used just for Evaluate, we only need a scalar\n",
        "#     if trace is None and pred_name is None and pred_trace is None:\n",
        "#         return score\n",
        "\n",
        "#     if score == 1.0:\n",
        "#         feedback = (\n",
        "#             \"Correct. All polarization categories were classified correctly. \"\n",
        "#             \"Keep enforcing the exact labels 'yes' or 'no' for each category.\"\n",
        "#         )\n",
        "#     else:\n",
        "#         mismatch_details = \"; \".join([f\"{f}: gold='{g}', pred='{p}'\" for f, g, p in mismatches])\n",
        "#         feedback = (\n",
        "#             f\"Partially incorrect. Mismatches: {mismatch_details}. \"\n",
        "#             \"For each category, output 'yes' if the sentence contains that type of \"\n",
        "#             \"polarization (stereotyping, vilification, dehumanization, intolerance), \"\n",
        "#             \"otherwise output 'no'. Categories are: political, racial/ethnic, \"\n",
        "#             \"religious, gender/sexual, other.\"\n",
        "#         )\n",
        "\n",
        "#     return dspy.Prediction(score=score, feedback=feedback)\n",
        "\n",
        "# gepa = GEPA(\n",
        "#     metric=gepa_metric,\n",
        "#     auto=\"light\",\n",
        "#     reflection_lm=teacher_lm,  # strong LM for reflection\n",
        "#     # you can tweak these if you want more budget:\n",
        "#     # max_metric_calls=200,\n",
        "#     # max_full_evals=10,\n",
        "# )\n",
        "\n",
        "# gepa_prog = gepa.compile(\n",
        "#     student=optimized_prog,   # start from MIPRO-optimized program\n",
        "#     trainset=raw_train,\n",
        "#     valset=raw_val,\n",
        "# )\n",
        "\n",
        "# # Evaluate GEPA-optimized program\n",
        "# evaluate = dspy.Evaluate(\n",
        "#     devset=raw_val,\n",
        "#     metric=gepa_metric,\n",
        "#     display_progress=True,\n",
        "#     display_table=True,\n",
        "# )\n",
        "# eval_result = evaluate(gepa_prog)\n",
        "# print(\"GEPA DSPy average accuracy metric:\", eval_result.score)\n",
        "\n",
        "# metrics_val_gepa = eval_metrics_on_dataset(gepa_prog, raw_val)\n",
        "# print(\"GEPA validation metrics:\", metrics_val_gepa)\n",
        "# gepa_f1_macro = metrics_val_gepa[\"f1_macro\"]\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
