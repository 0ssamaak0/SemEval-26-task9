{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "78d203c2-4edd-41ed-a45d-dc1fc92fa697",
      "metadata": {
        "id": "78d203c2-4edd-41ed-a45d-dc1fc92fa697"
      },
      "source": [
        "# Bert baseline for POLAR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea01ed9f-399e-4b8a-b46f-49369a33ee31",
      "metadata": {
        "id": "ea01ed9f-399e-4b8a-b46f-49369a33ee31"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this part of the starter notebook, we will take you through the process of all three Subtasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aIt64l96d4TR",
      "metadata": {
        "id": "aIt64l96d4TR"
      },
      "source": [
        "## Subtask 1 - Polarization detection\n",
        "\n",
        "This is a binary classification to determine whether a post contains polarized content (Polarized or Not Polarized)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "285b408f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Cvdkk_AZQzM5rJYhV4Nq-8bXvJrF8t4z\n",
            "To: /content/dev_phase.zip\n",
            "100% 10.1M/10.1M [00:00<00:00, 25.8MB/s]\n",
            "Archive:  dev_phase.zip\n",
            "   creating: dev_phase/\n",
            "  inflating: __MACOSX/._dev_phase    \n",
            "   creating: dev_phase/subtask2/\n",
            "  inflating: __MACOSX/dev_phase/._subtask2  \n",
            "   creating: dev_phase/subtask3/\n",
            "  inflating: __MACOSX/dev_phase/._subtask3  \n",
            "  inflating: dev_phase/.DS_Store     \n",
            "  inflating: __MACOSX/dev_phase/._.DS_Store  \n",
            "   creating: dev_phase/subtask1/\n",
            "  inflating: __MACOSX/dev_phase/._subtask1  \n",
            "  inflating: dev_phase/subtask2/.DS_Store  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/._.DS_Store  \n",
            "   creating: dev_phase/subtask2/train/\n",
            "  inflating: __MACOSX/dev_phase/subtask2/._train  \n",
            "   creating: dev_phase/subtask2/dev/\n",
            "  inflating: __MACOSX/dev_phase/subtask2/._dev  \n",
            "  inflating: dev_phase/subtask3/.DS_Store  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/._.DS_Store  \n",
            "   creating: dev_phase/subtask3/train/\n",
            "  inflating: __MACOSX/dev_phase/subtask3/._train  \n",
            "   creating: dev_phase/subtask3/dev/\n",
            "  inflating: __MACOSX/dev_phase/subtask3/._dev  \n",
            "  inflating: dev_phase/subtask1/.DS_Store  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/._.DS_Store  \n",
            "   creating: dev_phase/subtask1/train/\n",
            "  inflating: __MACOSX/dev_phase/subtask1/._train  \n",
            "   creating: dev_phase/subtask1/dev/\n",
            "  inflating: __MACOSX/dev_phase/subtask1/._dev  \n",
            "  inflating: dev_phase/subtask2/train/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._arb.csv  \n",
            "  inflating: dev_phase/subtask2/train/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._fas.csv  \n",
            "  inflating: dev_phase/subtask2/train/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._zho.csv  \n",
            "  inflating: dev_phase/subtask2/train/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._nep.csv  \n",
            "  inflating: dev_phase/subtask2/train/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._spa.csv  \n",
            "  inflating: dev_phase/subtask2/train/ita.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._ita.csv  \n",
            "  inflating: dev_phase/subtask2/train/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._urd.csv  \n",
            "  inflating: dev_phase/subtask2/train/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._amh.csv  \n",
            "  inflating: dev_phase/subtask2/train/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._tur.csv  \n",
            "  inflating: dev_phase/subtask2/train/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._deu.csv  \n",
            "  inflating: dev_phase/subtask2/train/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._eng.csv  \n",
            "  inflating: dev_phase/subtask2/train/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._hin.csv  \n",
            "  inflating: dev_phase/subtask2/train/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._hau.csv  \n",
            "  inflating: dev_phase/subtask2/dev/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._arb.csv  \n",
            "  inflating: dev_phase/subtask2/dev/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._fas.csv  \n",
            "  inflating: dev_phase/subtask2/dev/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._zho.csv  \n",
            "  inflating: dev_phase/subtask2/dev/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._nep.csv  \n",
            "  inflating: dev_phase/subtask2/dev/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._spa.csv  \n",
            "  inflating: dev_phase/subtask2/dev/ita.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._ita.csv  \n",
            "  inflating: dev_phase/subtask2/dev/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._urd.csv  \n",
            "  inflating: dev_phase/subtask2/dev/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._amh.csv  \n",
            "  inflating: dev_phase/subtask2/dev/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._tur.csv  \n",
            "  inflating: dev_phase/subtask2/dev/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._deu.csv  \n",
            "  inflating: dev_phase/subtask2/dev/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._eng.csv  \n",
            "  inflating: dev_phase/subtask2/dev/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._hin.csv  \n",
            "  inflating: dev_phase/subtask2/dev/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._hau.csv  \n",
            "  inflating: dev_phase/subtask3/train/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._arb.csv  \n",
            "  inflating: dev_phase/subtask3/train/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._fas.csv  \n",
            "  inflating: dev_phase/subtask3/train/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._zho.csv  \n",
            "  inflating: dev_phase/subtask3/train/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._nep.csv  \n",
            "  inflating: dev_phase/subtask3/train/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._spa.csv  \n",
            "  inflating: dev_phase/subtask3/train/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._urd.csv  \n",
            "  inflating: dev_phase/subtask3/train/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._amh.csv  \n",
            "  inflating: dev_phase/subtask3/train/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._tur.csv  \n",
            "  inflating: dev_phase/subtask3/train/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._deu.csv  \n",
            "  inflating: dev_phase/subtask3/train/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._eng.csv  \n",
            "  inflating: dev_phase/subtask3/train/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._hin.csv  \n",
            "  inflating: dev_phase/subtask3/train/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._hau.csv  \n",
            "  inflating: dev_phase/subtask3/dev/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._arb.csv  \n",
            "  inflating: dev_phase/subtask3/dev/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._fas.csv  \n",
            "  inflating: dev_phase/subtask3/dev/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._zho.csv  \n",
            "  inflating: dev_phase/subtask3/dev/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._nep.csv  \n",
            "  inflating: dev_phase/subtask3/dev/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._spa.csv  \n",
            "  inflating: dev_phase/subtask3/dev/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._urd.csv  \n",
            "  inflating: dev_phase/subtask3/dev/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._amh.csv  \n",
            "  inflating: dev_phase/subtask3/dev/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._tur.csv  \n",
            "  inflating: dev_phase/subtask3/dev/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._deu.csv  \n",
            "  inflating: dev_phase/subtask3/dev/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._eng.csv  \n",
            "  inflating: dev_phase/subtask3/dev/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._hin.csv  \n",
            "  inflating: dev_phase/subtask3/dev/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._hau.csv  \n",
            "  inflating: dev_phase/subtask1/train/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._arb.csv  \n",
            "  inflating: dev_phase/subtask1/train/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._fas.csv  \n",
            "  inflating: dev_phase/subtask1/train/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._zho.csv  \n",
            "  inflating: dev_phase/subtask1/train/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._nep.csv  \n",
            "  inflating: dev_phase/subtask1/train/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._spa.csv  \n",
            "  inflating: dev_phase/subtask1/train/ita.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._ita.csv  \n",
            "  inflating: dev_phase/subtask1/train/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._urd.csv  \n",
            "  inflating: dev_phase/subtask1/train/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._amh.csv  \n",
            "  inflating: dev_phase/subtask1/train/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._tur.csv  \n",
            "  inflating: dev_phase/subtask1/train/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._deu.csv  \n",
            "  inflating: dev_phase/subtask1/train/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._eng.csv  \n",
            "  inflating: dev_phase/subtask1/train/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._hin.csv  \n",
            "  inflating: dev_phase/subtask1/train/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._hau.csv  \n",
            "  inflating: dev_phase/subtask1/dev/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._arb.csv  \n",
            "  inflating: dev_phase/subtask1/dev/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._fas.csv  \n",
            "  inflating: dev_phase/subtask1/dev/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._zho.csv  \n",
            "  inflating: dev_phase/subtask1/dev/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._nep.csv  \n",
            "  inflating: dev_phase/subtask1/dev/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._spa.csv  \n",
            "  inflating: dev_phase/subtask1/dev/ita.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._ita.csv  \n",
            "  inflating: dev_phase/subtask1/dev/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._urd.csv  \n",
            "  inflating: dev_phase/subtask1/dev/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._amh.csv  \n",
            "  inflating: dev_phase/subtask1/dev/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._tur.csv  \n",
            "  inflating: dev_phase/subtask1/dev/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._deu.csv  \n",
            "  inflating: dev_phase/subtask1/dev/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._eng.csv  \n",
            "  inflating: dev_phase/subtask1/dev/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._hin.csv  \n",
            "  inflating: dev_phase/subtask1/dev/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._hau.csv  \n"
          ]
        }
      ],
      "source": [
        "# Install gdown if needed\n",
        "# Replace the ID below with your actual file ID from the Drive link\n",
        "# (The ID is the long string of random characters in the URL)\n",
        "file_id = '1Cvdkk_AZQzM5rJYhV4Nq-8bXvJrF8t4z'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "output = 'dev_phase.zip'\n",
        "\n",
        "!gdown {url} -O {output}\n",
        "\n",
        "!unzip {output}\n",
        "\n",
        "# Delete __MACOSX directory (if exists) and the dev_phase.zip file (cleanup)\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if os.path.exists(\"__MACOSX\"):\n",
        "    shutil.rmtree(\"__MACOSX\")\n",
        "\n",
        "if os.path.exists(\"dev_phase.zip\"):\n",
        "    os.remove(\"dev_phase.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "843cbd77-1b7f-41df-aec8-1d53fe1199c2",
      "metadata": {
        "id": "843cbd77-1b7f-41df-aec8-1d53fe1199c2"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5b8e9d6e-9342-43fd-9a0a-1330caf4e23a",
      "metadata": {
        "id": "5b8e9d6e-9342-43fd-9a0a-1330caf4e23a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "UkC2r47nManC",
      "metadata": {
        "id": "UkC2r47nManC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/d3byzf6h?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x797e9ffa1b50>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# Disable wandb logging for this script\n",
        "wandb.init(mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dac92ad-3fac-4aa1-aae6-1fe3ad14b1c0",
      "metadata": {
        "id": "4dac92ad-3fac-4aa1-aae6-1fe3ad14b1c0"
      },
      "source": [
        "## Data Import\n",
        "\n",
        "The training data consists of a short text and binary labels\n",
        "\n",
        "The data is structured as a CSV file with the following fields:\n",
        "- id: a unique identifier for the sample\n",
        "- text: a sentence or short text\n",
        "- polarization:  1 text is polarized, 0 text is not polarized\n",
        "\n",
        "The data is in all three subtask folders the same but only containing the labels for the specific task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e4fe8cc2-ba47-4240-bdd2-b1d3ea323134",
      "metadata": {
        "id": "e4fe8cc2-ba47-4240-bdd2-b1d3ea323134"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-45e604f5-d928-467c-b437-78f9e09bf701\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>polarization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>arb_a2a60c8b4af3389e842d8ec31afb0eea</td>\n",
              "      <td>ÿßÿ≠ŸÑÿßŸÖ ÿßŸÜÿ™Ÿä ŸàŸÜÿπÿßŸÑŸä ŸàŸÖŸÜŸà ÿßŸÜÿ™Ÿä ÿ≠ÿ™Ÿâ ÿ™ŸÇŸäŸÖŸäŸÜ ÿßŸÑŸÅŸÜÿßŸÜŸä...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>arb_6723e56a672674a6c1d9b28b213c4a05</td>\n",
              "      <td>Ÿàÿ±Ÿá ÿßŸÑŸÉŸàÿßŸÑŸäÿ≥ ÿ™ŸÜŸäÿ¨ÿ¨ ŸÖŸÜ Ÿàÿ±Ÿá ÿ®ÿπŸäÿ± ÿµÿ∑ŸÜÿßÿπŸä ÿπŸÑŸâ ŸÅŸÉÿ±ÿ©...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>arb_b0365d606edeee38ae6c025b1ca33e96</td>\n",
              "      <td>.ÿÆÿÆÿÆÿÆ ÿßŸÑŸÖŸÑŸÉŸá ÿßÿ≠ŸÑÿßŸÖ ŸÅŸäŸáÿß ÿ¥ÿ∞Ÿàÿ∞ ÿ¥ŸÜŸà ŸáŸÑ ÿ®Ÿàÿ≥ ŸàÿßŸÑÿØŸÑÿπ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>arb_858c0ee684049ba6f416a6cecb0b0761</td>\n",
              "      <td>ÿßŸÑŸÑŸá ŸäÿÆÿ≤Ÿä ÿßÿ≠ŸÑÿßŸÖ ŸáŸä ŸàÿßŸÑÿ®ÿ±ŸÜÿßŸÖÿ¨ ÿßŸÑÿÆÿßŸäÿ≥ ÿßŸÑŸä ŸÉŸÑŸá ŸÖÿµÿÆÿ±Ÿá</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>arb_bdafc73afd0bc2cd2badae2a089446b9</td>\n",
              "      <td>ŸÉÿ≥ ÿßŸÖ ÿßÿ≠ŸÑÿßŸÖ ÿßŸÑŸä ŸÖÿßÿ±ÿ®ÿ™Ÿáÿß Ÿàÿ¥ ŸÖŸÑŸÉŸá ŸáŸáŸáŸá ŸÖÿ™ÿ≥ÿ™ÿßŸáŸÑ ŸÖ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45e604f5-d928-467c-b437-78f9e09bf701')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45e604f5-d928-467c-b437-78f9e09bf701 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45e604f5-d928-467c-b437-78f9e09bf701');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                     id  \\\n",
              "0  arb_a2a60c8b4af3389e842d8ec31afb0eea   \n",
              "1  arb_6723e56a672674a6c1d9b28b213c4a05   \n",
              "2  arb_b0365d606edeee38ae6c025b1ca33e96   \n",
              "3  arb_858c0ee684049ba6f416a6cecb0b0761   \n",
              "4  arb_bdafc73afd0bc2cd2badae2a089446b9   \n",
              "\n",
              "                                                text  polarization  \n",
              "0  ÿßÿ≠ŸÑÿßŸÖ ÿßŸÜÿ™Ÿä ŸàŸÜÿπÿßŸÑŸä ŸàŸÖŸÜŸà ÿßŸÜÿ™Ÿä ÿ≠ÿ™Ÿâ ÿ™ŸÇŸäŸÖŸäŸÜ ÿßŸÑŸÅŸÜÿßŸÜŸä...             1  \n",
              "1  Ÿàÿ±Ÿá ÿßŸÑŸÉŸàÿßŸÑŸäÿ≥ ÿ™ŸÜŸäÿ¨ÿ¨ ŸÖŸÜ Ÿàÿ±Ÿá ÿ®ÿπŸäÿ± ÿµÿ∑ŸÜÿßÿπŸä ÿπŸÑŸâ ŸÅŸÉÿ±ÿ©...             1  \n",
              "2  .ÿÆÿÆÿÆÿÆ ÿßŸÑŸÖŸÑŸÉŸá ÿßÿ≠ŸÑÿßŸÖ ŸÅŸäŸáÿß ÿ¥ÿ∞Ÿàÿ∞ ÿ¥ŸÜŸà ŸáŸÑ ÿ®Ÿàÿ≥ ŸàÿßŸÑÿØŸÑÿπ...             1  \n",
              "3  ÿßŸÑŸÑŸá ŸäÿÆÿ≤Ÿä ÿßÿ≠ŸÑÿßŸÖ ŸáŸä ŸàÿßŸÑÿ®ÿ±ŸÜÿßŸÖÿ¨ ÿßŸÑÿÆÿßŸäÿ≥ ÿßŸÑŸä ŸÉŸÑŸá ŸÖÿµÿÆÿ±Ÿá             1  \n",
              "4  ŸÉÿ≥ ÿßŸÖ ÿßÿ≠ŸÑÿßŸÖ ÿßŸÑŸä ŸÖÿßÿ±ÿ®ÿ™Ÿáÿß Ÿàÿ¥ ŸÖŸÑŸÉŸá ŸáŸáŸáŸá ŸÖÿ™ÿ≥ÿ™ÿßŸáŸÑ ŸÖ...             1  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the training and validation data for subtask 1\n",
        "\n",
        "train = pd.read_csv('./dev_phase/subtask1/train/arb.csv')\n",
        "val = pd.read_csv('./dev_phase/subtask1/dev/arb.csv')\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eQWDFio83z9g",
      "metadata": {
        "id": "eQWDFio83z9g"
      },
      "source": [
        "# Dataset\n",
        "-  Create a pytorch class for handling data\n",
        "-  Wrapping the raw texts and labels into a format that Huggingface‚Äôs Trainer can use for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8e749d08",
      "metadata": {
        "id": "8e749d08"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,texts,labels,tokenizer,max_length =128):\n",
        "    self.texts=texts\n",
        "    self.labels=labels\n",
        "    self.tokenizer= tokenizer\n",
        "    self.max_length = max_length # Store max_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    text=self.texts[idx]\n",
        "    label=self.labels[idx]\n",
        "    encoding=self.tokenizer(text,truncation=True,padding=False,max_length=self.max_length,return_tensors='pt')\n",
        "\n",
        "    # Ensure consistent tensor conversion for all items\n",
        "    item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "    item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "    return item"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adfb74a3",
      "metadata": {
        "id": "adfb74a3"
      },
      "source": [
        "Now, we'll tokenize the text data and create the datasets using `bert-base-uncased` as the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c2e6215b",
      "metadata": {
        "id": "c2e6215b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Load the tokenizer\n",
        "model_name = ['bert-base-uncased', \"UBC-NLP/MARBERTv2\"]\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name[0])\n",
        "\n",
        "texts_train, texts_val, labels_train, labels_val = train_test_split(\n",
        "    train['text'].tolist(),\n",
        "    train['polarization'].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train['polarization'].tolist(),  # if labels are imbalanced\n",
        ")\n",
        "\n",
        "train_dataset = PolarizationDataset(texts_train, labels_train, tokenizer)\n",
        "val_dataset = PolarizationDataset(texts_val, labels_val, tokenizer)\n",
        "test_dataset = PolarizationDataset(val['text'].tolist(), val['polarization'].tolist(), tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b13caa5c",
      "metadata": {
        "id": "b13caa5c"
      },
      "source": [
        "Next, we'll load the pre-trained `bert-base-uncased` model for sequence classification. Since this is a binary classification task (Polarized/Not Polarized), we set `num_labels=2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7cd0411f",
      "metadata": {
        "id": "7cd0411f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91375f682038427fb54a0289e83bb765",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name[0], num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b250d61e",
      "metadata": {
        "id": "b250d61e"
      },
      "source": [
        "Now, we'll define the training arguments and the evaluation metric. We'll use macro F1 score for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "21c97269",
      "metadata": {
        "id": "21c97269"
      },
      "outputs": [],
      "source": [
        "# Define metrics function\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "        output_dir=f\"./\",\n",
        "        num_train_epochs=3,\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=64,\n",
        "        per_device_eval_batch_size=8,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_steps=100,\n",
        "        disable_tqdm=False\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20167a2b",
      "metadata": {
        "id": "20167a2b"
      },
      "source": [
        "Finally, we'll initialize the `Trainer` and start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ecd9f444",
      "metadata": {
        "id": "ecd9f444"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='129' max='129' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [129/129 03:24, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.628892</td>\n",
              "      <td>0.627409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.534294</td>\n",
              "      <td>0.730066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.607800</td>\n",
              "      <td>0.518725</td>\n",
              "      <td>0.738102</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='338' max='338' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [338/338 00:17]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1 score on validation set: 0.738102495098396\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ü§ó Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=train_dataset,            # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        "    data_collator=DataCollatorWithPadding(tokenizer) # Data collator for dynamic padding\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set: {eval_results['eval_f1_macro']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bbcee2f",
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Run predictions on the test set and fill the labels array with predicted testues\n",
        "test_texts = test['text'].tolist()\n",
        "labels = []\n",
        "\n",
        "# Tokenize and predict in batches to avoid memory issues\n",
        "for i in range(0, len(test_texts), 64):\n",
        "    batch_texts = test_texts[i:i+64]\n",
        "    inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        preds = outputs.logits.argmax(dim=1).cpu().numpy()\n",
        "        labels.extend(preds.tolist())\n",
        "\n",
        "# save it into CSV format\n",
        "test_results = pd.DataFrame({\n",
        "    'id': test['id'].tolist(),\n",
        "    'polarization': labels\n",
        "})\n",
        "test_results.to_csv('ar_bert_based_uncased.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "7b370d71",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arb_67be47e5216d7bee41e17484e619f4e6,1\n",
            "arb_272322e5b265e177613d685e5619e402,1\n",
            "arb_d1ec38dd0ec5d7a4fe28ef8317fc96c1,1\n",
            "arb_fad75310b17c124d98ebc514189ec033,1\n",
            "arb_95caf70cec5bf00c94c35cf7af2a0ab5,0\n",
            "arb_ac108c1ecf5071892c61abd253847b15,1\n",
            "arb_adaaa6d482119e65ce337ee224674e70,1\n",
            "arb_2794b08cac6cc9394a68c51cfc436243,1\n",
            "arb_19dd96c989323c9e950a2c3ab9c285be,1\n",
            "arb_f2bd638d9d9fc7a617130ff2b198b562,1\n",
            "arb_f992bf7776b854d4f7f8475aebf80f49,1\n",
            "arb_0b5ac70e86926f5e84cad94028864a37,0\n",
            "arb_8ababf95f952e2425c2df1033192dac0,1\n",
            "arb_06cd19aac6cc52e394a22d7d1dd58efc,1\n",
            "arb_12eeeb8d2fa2d04be2ed9830d5f36ce9,1\n",
            "arb_5bc23bacf9a161cd0f99719c70681a81,1\n",
            "arb_9ee7c931ab1ecd655533042d8301f6bb,1\n",
            "arb_bb7c40559f3a7ca1ecdd7dd7c136198f,1\n",
            "arb_5d394c0cce56675e2fc36a0590b47ed7,1\n",
            "arb_0704305e8313650e672563a2d073384f,1\n",
            "arb_e56b759d14fd70506e01cf971315453d,1\n",
            "arb_d286a2aac63432acef285a4799041f55,1\n",
            "arb_5a9f322a530e85cd640f21af5c6bae42,1\n",
            "arb_133c4737c4e04a8991fc7c219106b4e4,0\n",
            "arb_f03fd416ab63cbb8f9f92a020fdd46be,1\n",
            "arb_b8fbf2253ba4b8a83829b964012d1a9b,1\n",
            "arb_4188caa3678846451bb812d7a7902459,1\n",
            "arb_c0224b694b38805f15fae4137121302e,1\n",
            "arb_3991e487126513829ec24ab5c1f1e325,0\n",
            "arb_9861662780205d38780ea04feed598dd,1\n",
            "arb_2b14abe9527a935117ae771612afca21,1\n",
            "arb_925eb03f72f22102e242a475f1f54530,1\n",
            "arb_c531bdc9a777137d8aa23a3bf529f87e,1\n",
            "arb_51a6eb82ab53edd30fdd18b6940dc275,1\n",
            "arb_6aa01210c44d11393ea419d6781b89a9,1\n",
            "arb_0c8c4d1e368fa6081c8840c3924b3711,1\n",
            "arb_f15fdbdb119f76f430f7cf7c773c3590,1\n",
            "arb_9b66d2e70ea93d6d37d0b656c1b1e880,1\n",
            "arb_773241d9837d36ed8962eacefa5143ef,1\n",
            "arb_b8f51143c06fbaed500ee2e7e7f5ac14,1\n",
            "arb_99dc675d6e1f9acdc7714fa066b4242b,1\n",
            "arb_3bcca38054a14240945f770aebe23355,1\n",
            "arb_730fba0ced42edd151f49218959abcdc,1\n",
            "arb_1a960ef19b8ebbeba5d8a48f2da3baf7,0\n",
            "arb_60a8455969e0277c96a31b2ab8f57bb6,1\n",
            "arb_8e46849f4110205740552b9b3d8afcc8,1\n",
            "arb_6535199985cd1f867d14c01e1780ed45,0\n",
            "arb_90448d504fbf1cdf02fe55dd474078fe,1\n",
            "arb_650c8d322f6c2ea8be78385ac29ad57d,0\n",
            "arb_8e08d6c50f1bc16d8aa16c4fcc461702,0\n",
            "arb_aafb2df7e4108d4d09ffefa74811ea2e,0\n",
            "arb_3a9070f93fa0aed9b4c7d7974d6134fe,0\n",
            "arb_a25e888067bd682f8712cc254a94450d,1\n",
            "arb_69b3fac31a9776e98df1f2ed3a37f743,0\n",
            "arb_70d64fdc7707ba7b23590bc3987a22bc,1\n",
            "arb_3561147626932826873155b2cb70e11e,1\n",
            "arb_757e07f4b35078992f4e9656cb4ea948,0\n",
            "arb_954a7a38de550d4b5252483bb9b748ea,1\n",
            "arb_a9847cdfa1abb179e11c85955a5f49bf,0\n",
            "arb_46b4284e3ace41c2806a041162aa1a39,0\n",
            "arb_8e5e356a5c81496169940989d545c6ac,0\n",
            "arb_c30e1b90992cee20688833ca1e382de0,0\n",
            "arb_0340513e0b537d1db0934fc235651218,0\n",
            "arb_726332fa6d54c653d55f5c7b42deb977,0\n",
            "arb_88c88e64e71c1e1b9222a49458d448ee,0\n",
            "arb_031d376aa7923c4268ac73dc2b9334a9,0\n",
            "arb_1cbab69c6f39bfd5484bd5832ece0ac0,0\n",
            "arb_ce785dd8c5b8140363e2e057dae241ce,0\n",
            "arb_60d2f094428bbcbde294086a7f75d5d9,0\n",
            "arb_28552d3893a580bf74bb1e4711c30e29,0\n",
            "arb_7e021fb631c018eb7a1dc96bb3b7d3f5,0\n",
            "arb_1429c399c30de8d7188cdd239c91aaa6,0\n",
            "arb_1a1c75b0f7b1b571c157dd83243f81c6,0\n",
            "arb_143932e3ea47fd0d8d45ff79c8e9a529,0\n",
            "arb_c0a60d5d5cb40fbd604c9c3e0b3098bf,0\n",
            "arb_13636b23e853783423f760db617520a9,0\n",
            "arb_6c8048c166f7ee2e8a94ca3650335345,0\n",
            "arb_8530294a4c91bae6bcbc9d7888b8d183,1\n",
            "arb_c4c60186c0b797433e86f3f08cd77e7b,0\n",
            "arb_2de8255707465f99180bf1c58204816b,0\n",
            "arb_52f0037e1b1196f8462aba17ce30b0bd,1\n",
            "arb_05a11d7f973c5b33f51a53a92a08c9f7,0\n",
            "arb_cfdb8f2486dbb02404f69c104509e956,0\n",
            "arb_119473be95ebd1ff087a086a8cdf67f0,0\n",
            "arb_06aa7b6d64858e1ea54c8d5c093a1385,0\n",
            "arb_58683c41f6320b304993fbc9ce8e559c,0\n",
            "arb_ae60c3911c8290e556ffdfa0e73ea408,0\n",
            "arb_c6624ecf4359e15fe5298b8878a53630,0\n",
            "arb_2228fe1e68bf10ac10d74c8f24ed672f,0\n",
            "arb_0d027dd29b767b3cb54141a67da833a8,0\n",
            "arb_f5345aeade0452ce211afa3b91a2a98a,0\n",
            "arb_fb4217f3ac08ddbbe93b87607d9e7eea,0\n",
            "arb_6eaa4e896b8b2056308fba14b04d1323,0\n",
            "arb_0c49ebfdc0e82c39fb952a55a2eec2a6,1\n",
            "arb_d380557a1e7c162fbf0bf8bb8cb7c374,0\n",
            "arb_445262028526e3ac19d4a7617b89312f,0\n",
            "arb_5078361bd8c9205ae1abd0f554b413a8,1\n",
            "arb_d8fc83089c56da4eaa4ea5dc1c8385cd,1\n",
            "arb_e203ea25f0d5899540684c600c27e313,0\n",
            "arb_8af35c96dd0ab3abdd243488210d41fb,1\n",
            "arb_80e0c1d020bb3e68c57092a5da055789,1\n",
            "arb_e9afce419a9fd57fd8fde9130084d86f,1\n",
            "arb_4208815a310227400e1d9b718aa3201b,1\n",
            "arb_f78e2ee76eaf751e219c0a6c24f17477,1\n",
            "arb_9444af3fa26415a2e1a1215b618b77fc,1\n",
            "arb_8ca54749e8a4cb192d605e8d0fed5077,1\n",
            "arb_985e458b817a04e5b4b856bdd66baad1,1\n",
            "arb_2ae6d2826d3f741c81074893b7368e8f,0\n",
            "arb_752cbd7c5fa526b02871ee2174b75260,1\n",
            "arb_d4e513d177a18cd0361907f0abcee264,1\n",
            "arb_3fd0b4dcbfd27d815c7c1600ed523acc,1\n",
            "arb_a5714ea7faf17fb64bce39550b8f66a0,1\n",
            "arb_dbb306bb98f778a984aa4e89a2a0c69c,1\n",
            "arb_8fe3d20ecd2bffca8608ad581e1d450d,1\n",
            "arb_4d3ed82d7641e459b2143327303141ca,1\n",
            "arb_2fe0dd13d24583051d76f1efe2a6b221,0\n",
            "arb_328246a090fa79fae208734fb506356a,1\n",
            "arb_fa9bfd0d2544a6a0da7e9fdf67dcb61a,1\n",
            "arb_eca8c2a903579f5bc09bbae9a914192b,0\n",
            "arb_ae665012d4d85ec2b7f67036e8e7ef91,0\n",
            "arb_7b2074b411c5991657d956f2e868d0d6,1\n",
            "arb_a2d10460956f12da3bfad87d75c17b85,1\n",
            "arb_68d1cbebcef21c8b7e157d3deb68c96a,1\n",
            "arb_2320e4a90c9a3e16ad43013187628bf0,1\n",
            "arb_03c025ab5aac30fb1b817698060f88e9,1\n",
            "arb_28a4a6fa8a0d9478a678ead7d87141aa,1\n",
            "arb_26bf97302d3bbf29dc55628a7cdce3b2,1\n",
            "arb_6c9c12fd45b04bafdda96d36b4abf654,1\n",
            "arb_717eb9eb752dde1f2ba0b1f75431ecb9,1\n",
            "arb_22ad0f62586145ee322627cc04737aed,1\n",
            "arb_9965f78f084c4b52eba5ad3eaf00c383,0\n",
            "arb_230ff60adcb94e26bb447d4d2d2d4d87,1\n",
            "arb_de5e97574cb90756816e4acad906cbcb,1\n",
            "arb_b930858672f01ab4e30913d1a42b2fdd,1\n",
            "arb_9e735136b6578cfa2e617c9686b060c6,1\n",
            "arb_2f940f44c8882b16eedd16ceb9a22f3a,1\n",
            "arb_63bba78965d711655b703211386a1d66,1\n",
            "arb_796f4f5016b6b057af6e4d9a931be707,1\n",
            "arb_35b4ec4ee73ff5865897b530f86a0df2,1\n",
            "arb_54d246af610d9df0efc222e9f5f568ee,0\n",
            "arb_c03c23fb168af6d9974173940301a49e,1\n",
            "arb_04c10b142c039bea31abc347a05e901e,1\n",
            "arb_fc3a3dada9c28b31f4501b1aff617009,1\n",
            "arb_db683247365c64679c4cc519af44f581,1\n",
            "arb_aecc5b9082fe643e2b8d6f0ac0dcdfce,1\n",
            "arb_f17c38194db34a072fb9ffa06a3c1a36,1\n",
            "arb_00ba726a4ccda40d3aa9970b605643d0,1\n",
            "arb_466691d07d329912a743f07951be4b63,1\n",
            "arb_32df687e0801943c203047322024a082,1\n",
            "arb_5956bff1d7e2d783e032bbb840bc0b0c,1\n",
            "arb_8d9f1d3fdd08dccf0fe640b32ee3c75d,1\n",
            "arb_2f9508e688439711aadf9ffe4c7dc43c,1\n",
            "arb_ea84b8ff4b701131207666ad68d9b4e6,1\n",
            "arb_c3baa08c705605f300bacbfd7b32cdb5,1\n",
            "arb_968554a6b5723334ac89acd80d35f5f3,1\n",
            "arb_63849e6cf2a4b209a3a7c88cf689c09f,1\n",
            "arb_7c14ba01ef8cdc91ee907afe06c6d57b,1\n",
            "arb_d90e03b791ee0a44e1ff732b3502cff2,1\n",
            "arb_a614e47120a6cc5ab2c22d062f799d1d,1\n",
            "arb_d0bec4c3e835773e91bade24082405dc,0\n",
            "arb_54d3d10c58ab60fe3bc8135cec8a7745,1\n",
            "arb_3a6d9f8b7468345e5fe80353682ea2b6,0\n",
            "arb_a74cb5b1ac1b5e1e3297ec29040104f7,1\n",
            "arb_902c5ae816b9323758ed8e33424c5427,1\n",
            "arb_7d86f321f6d638c75df7ed4645bdabbc,1\n",
            "arb_452c08a3d812c6786509a33f13bdca7a,1\n",
            "arb_fee827860874f8bf04cfdaca1a0bff7a,0\n",
            "arb_d072529aace0ca637b85d8bb968577c0,0\n",
            "arb_e564370d0a844c67763dafdd2ede0411,1\n"
          ]
        }
      ],
      "source": [
        "# print the results row by row in csv format\n",
        "for index, row in val_results.iterrows():\n",
        "    print(f\"{row['id']},{row['polarization']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Qi53eheGIbu",
      "metadata": {
        "id": "5Qi53eheGIbu"
      },
      "source": [
        "# Subtask 2: Polarization Type Classification\n",
        "Multi-label classification to identify the target of polarization as one of the following categories: Gender/Sexual, Political, Religious, Racial/Ethnic, or Other.\n",
        "For this task we will load the data for subtask 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "YaWIvnYv0rV2",
      "metadata": {
        "id": "YaWIvnYv0rV2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>political</th>\n",
              "      <th>racial/ethnic</th>\n",
              "      <th>religious</th>\n",
              "      <th>gender/sexual</th>\n",
              "      <th>other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>eng_973938b90b0ff5d87d35a582f83f5c89</td>\n",
              "      <td>is defending imperialism in the dnd chat</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eng_07dfd4600426caca6e2c5883fcbea9ea</td>\n",
              "      <td>Still playing with this. I am now following Ra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eng_f14519ff2302b6cd47712073f13bc461</td>\n",
              "      <td>.senate.gov Theres 3 groups out there Republic...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>eng_e48b7e7542faafa544ac57b64bc80daf</td>\n",
              "      <td>\"ABC MD, David Anderson, said the additional f...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eng_7c581fb77bce8033aeba3d6dbd6273eb</td>\n",
              "      <td>\"bad people\" I have some conservative values s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     id  \\\n",
              "0  eng_973938b90b0ff5d87d35a582f83f5c89   \n",
              "1  eng_07dfd4600426caca6e2c5883fcbea9ea   \n",
              "2  eng_f14519ff2302b6cd47712073f13bc461   \n",
              "3  eng_e48b7e7542faafa544ac57b64bc80daf   \n",
              "4  eng_7c581fb77bce8033aeba3d6dbd6273eb   \n",
              "\n",
              "                                                text  political  \\\n",
              "0           is defending imperialism in the dnd chat          0   \n",
              "1  Still playing with this. I am now following Ra...          0   \n",
              "2  .senate.gov Theres 3 groups out there Republic...          0   \n",
              "3  \"ABC MD, David Anderson, said the additional f...          0   \n",
              "4  \"bad people\" I have some conservative values s...          0   \n",
              "\n",
              "   racial/ethnic  religious  gender/sexual  other  \n",
              "0              0          0              0      0  \n",
              "1              0          0              0      0  \n",
              "2              0          0              0      0  \n",
              "3              0          0              0      0  \n",
              "4              0          0              0      0  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv('./dev_phase/subtask2/train/eng.csv')\n",
        "val = pd.read_csv('./dev_phase/subtask2/train/eng.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "I6S2S6QBDKzw",
      "metadata": {
        "id": "I6S2S6QBDKzw"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length # Store max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, truncation=True, padding=False, max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        # Ensure consistent tensor conversion for all items\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        # CHANGE THIS LINE: Use torch.float instead of torch.long for multi-label classification\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "u1_KYsG68nxI",
      "metadata": {
        "id": "u1_KYsG68nxI"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Create train and Test dataset for multilabel\n",
        "train_dataset = PolarizationDataset(train['text'].tolist(), train[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n",
        "val_dataset = PolarizationDataset(val['text'].tolist(), val[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n",
        "dev_dataset = PolarizationDataset(val['text'].tolist(), val[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "cdiYJyr08bw2",
      "metadata": {
        "id": "cdiYJyr08bw2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5, problem_type=\"multi_label_classification\") # 5 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ArVWKwze2mtS",
      "metadata": {
        "id": "ArVWKwze2mtS"
      },
      "outputs": [],
      "source": [
        "# Define metrics function for multi-label classification\n",
        "def compute_metrics_multilabel(p):\n",
        "    # Sigmoid the predictions to get probabilities\n",
        "    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n",
        "    # Convert probabilities to predicted labels (0 or 1)\n",
        "    preds = (probs > 0.5).int().numpy()\n",
        "    # Compute macro F1 score\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./\",\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100,\n",
        "    disable_tqdm=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qd3QPyfc2RKE",
      "metadata": {
        "id": "Qd3QPyfc2RKE"
      },
      "outputs": [],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics_multilabel,  # Use the new metrics function\n",
        "    data_collator=DataCollatorWithPadding(tokenizer)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set for Subtask 2: {eval_results['eval_f1_macro']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UL1uE8llIgTQ",
      "metadata": {
        "id": "UL1uE8llIgTQ"
      },
      "source": [
        "# Subtask 3: Manifestation Identification\n",
        "Multi-label classification to classify how polarization is expressed, with multiple possible labels including Vilification, Extreme Language, Stereotype, Invalidation, Lack of Empathy, and Dehumanization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nCz20cgl-K3t",
      "metadata": {
        "id": "nCz20cgl-K3t"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('subtask3/train/eng.csv')\n",
        "val = pd.read_csv('subtask3/train/eng.csv')\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qs-UjVYsInpD",
      "metadata": {
        "id": "Qs-UjVYsInpD"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length # Store max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, truncation=True, padding=False, max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        # Ensure consistent tensor conversion for all items\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        # CHANGE THIS LINE: Use torch.float instead of torch.long for multi-label classification\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-yxSaDCA9IMi",
      "metadata": {
        "id": "-yxSaDCA9IMi"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Create train and Test dataset for multilabel\n",
        "train_dataset = PolarizationDataset(train['text'].tolist(), train[['vilification','extreme_language','stereotype','invalidation','lack_of_empathy','dehumanization']].values.tolist(), tokenizer)\n",
        "val_dataset = PolarizationDataset(val['text'].tolist(), val[['vilification','extreme_language','stereotype','invalidation','lack_of_empathy','dehumanization']].values.tolist(), tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0VXqqqIH9A3M",
      "metadata": {
        "id": "0VXqqqIH9A3M"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6, problem_type=\"multi_label_classification\") # use 6 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QLubGtx988hm",
      "metadata": {
        "id": "QLubGtx988hm"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./\",\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100,\n",
        "    disable_tqdm=False\n",
        ")\n",
        "\n",
        "# Define metrics function for multi-label classification\n",
        "def compute_metrics_multilabel(p):\n",
        "    # Sigmoid the predictions to get probabilities\n",
        "    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n",
        "    # Convert probabilities to predicted labels (0 or 1)\n",
        "    preds = (probs > 0.5).int().numpy()\n",
        "    # Compute macro F1 score\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qEhm1TEv82mP",
      "metadata": {
        "id": "qEhm1TEv82mP"
      },
      "outputs": [],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics_multilabel,  # Use the new metrics function\n",
        "    data_collator=DataCollatorWithPadding(tokenizer)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set for Subtask 3: {eval_results['eval_f1_macro']}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
