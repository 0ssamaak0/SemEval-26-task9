{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "78d203c2-4edd-41ed-a45d-dc1fc92fa697",
      "metadata": {
        "id": "78d203c2-4edd-41ed-a45d-dc1fc92fa697"
      },
      "source": [
        "# Bert baseline for POLAR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea01ed9f-399e-4b8a-b46f-49369a33ee31",
      "metadata": {
        "id": "ea01ed9f-399e-4b8a-b46f-49369a33ee31"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this part of the starter notebook, we will take you through the process of all three Subtasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aIt64l96d4TR",
      "metadata": {
        "id": "aIt64l96d4TR"
      },
      "source": [
        "## Subtask 1 - Polarization detection\n",
        "\n",
        "This is a binary classification to determine whether a post contains polarized content (Polarized or Not Polarized)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "285b408f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Cvdkk_AZQzM5rJYhV4Nq-8bXvJrF8t4z\n",
            "To: /content/dev_phase.zip\n",
            "100% 10.1M/10.1M [00:00<00:00, 20.8MB/s]\n",
            "Archive:  dev_phase.zip\n",
            "   creating: dev_phase/\n",
            "  inflating: __MACOSX/._dev_phase    \n",
            "   creating: dev_phase/subtask2/\n",
            "  inflating: __MACOSX/dev_phase/._subtask2  \n",
            "   creating: dev_phase/subtask3/\n",
            "  inflating: __MACOSX/dev_phase/._subtask3  \n",
            "  inflating: dev_phase/.DS_Store     \n",
            "  inflating: __MACOSX/dev_phase/._.DS_Store  \n",
            "   creating: dev_phase/subtask1/\n",
            "  inflating: __MACOSX/dev_phase/._subtask1  \n",
            "  inflating: dev_phase/subtask2/.DS_Store  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/._.DS_Store  \n",
            "   creating: dev_phase/subtask2/train/\n",
            "  inflating: __MACOSX/dev_phase/subtask2/._train  \n",
            "   creating: dev_phase/subtask2/dev/\n",
            "  inflating: __MACOSX/dev_phase/subtask2/._dev  \n",
            "  inflating: dev_phase/subtask3/.DS_Store  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/._.DS_Store  \n",
            "   creating: dev_phase/subtask3/train/\n",
            "  inflating: __MACOSX/dev_phase/subtask3/._train  \n",
            "   creating: dev_phase/subtask3/dev/\n",
            "  inflating: __MACOSX/dev_phase/subtask3/._dev  \n",
            "  inflating: dev_phase/subtask1/.DS_Store  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/._.DS_Store  \n",
            "   creating: dev_phase/subtask1/train/\n",
            "  inflating: __MACOSX/dev_phase/subtask1/._train  \n",
            "   creating: dev_phase/subtask1/dev/\n",
            "  inflating: __MACOSX/dev_phase/subtask1/._dev  \n",
            "  inflating: dev_phase/subtask2/train/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._arb.csv  \n",
            "  inflating: dev_phase/subtask2/train/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._fas.csv  \n",
            "  inflating: dev_phase/subtask2/train/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._zho.csv  \n",
            "  inflating: dev_phase/subtask2/train/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._nep.csv  \n",
            "  inflating: dev_phase/subtask2/train/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._spa.csv  \n",
            "  inflating: dev_phase/subtask2/train/ita.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._ita.csv  \n",
            "  inflating: dev_phase/subtask2/train/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._urd.csv  \n",
            "  inflating: dev_phase/subtask2/train/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._amh.csv  \n",
            "  inflating: dev_phase/subtask2/train/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._tur.csv  \n",
            "  inflating: dev_phase/subtask2/train/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._deu.csv  \n",
            "  inflating: dev_phase/subtask2/train/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._eng.csv  \n",
            "  inflating: dev_phase/subtask2/train/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._hin.csv  \n",
            "  inflating: dev_phase/subtask2/train/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/train/._hau.csv  \n",
            "  inflating: dev_phase/subtask2/dev/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._arb.csv  \n",
            "  inflating: dev_phase/subtask2/dev/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._fas.csv  \n",
            "  inflating: dev_phase/subtask2/dev/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._zho.csv  \n",
            "  inflating: dev_phase/subtask2/dev/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._nep.csv  \n",
            "  inflating: dev_phase/subtask2/dev/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._spa.csv  \n",
            "  inflating: dev_phase/subtask2/dev/ita.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._ita.csv  \n",
            "  inflating: dev_phase/subtask2/dev/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._urd.csv  \n",
            "  inflating: dev_phase/subtask2/dev/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._amh.csv  \n",
            "  inflating: dev_phase/subtask2/dev/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._tur.csv  \n",
            "  inflating: dev_phase/subtask2/dev/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._deu.csv  \n",
            "  inflating: dev_phase/subtask2/dev/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._eng.csv  \n",
            "  inflating: dev_phase/subtask2/dev/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._hin.csv  \n",
            "  inflating: dev_phase/subtask2/dev/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask2/dev/._hau.csv  \n",
            "  inflating: dev_phase/subtask3/train/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._arb.csv  \n",
            "  inflating: dev_phase/subtask3/train/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._fas.csv  \n",
            "  inflating: dev_phase/subtask3/train/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._zho.csv  \n",
            "  inflating: dev_phase/subtask3/train/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._nep.csv  \n",
            "  inflating: dev_phase/subtask3/train/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._spa.csv  \n",
            "  inflating: dev_phase/subtask3/train/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._urd.csv  \n",
            "  inflating: dev_phase/subtask3/train/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._amh.csv  \n",
            "  inflating: dev_phase/subtask3/train/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._tur.csv  \n",
            "  inflating: dev_phase/subtask3/train/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._deu.csv  \n",
            "  inflating: dev_phase/subtask3/train/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._eng.csv  \n",
            "  inflating: dev_phase/subtask3/train/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._hin.csv  \n",
            "  inflating: dev_phase/subtask3/train/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/train/._hau.csv  \n",
            "  inflating: dev_phase/subtask3/dev/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._arb.csv  \n",
            "  inflating: dev_phase/subtask3/dev/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._fas.csv  \n",
            "  inflating: dev_phase/subtask3/dev/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._zho.csv  \n",
            "  inflating: dev_phase/subtask3/dev/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._nep.csv  \n",
            "  inflating: dev_phase/subtask3/dev/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._spa.csv  \n",
            "  inflating: dev_phase/subtask3/dev/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._urd.csv  \n",
            "  inflating: dev_phase/subtask3/dev/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._amh.csv  \n",
            "  inflating: dev_phase/subtask3/dev/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._tur.csv  \n",
            "  inflating: dev_phase/subtask3/dev/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._deu.csv  \n",
            "  inflating: dev_phase/subtask3/dev/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._eng.csv  \n",
            "  inflating: dev_phase/subtask3/dev/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._hin.csv  \n",
            "  inflating: dev_phase/subtask3/dev/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask3/dev/._hau.csv  \n",
            "  inflating: dev_phase/subtask1/train/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._arb.csv  \n",
            "  inflating: dev_phase/subtask1/train/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._fas.csv  \n",
            "  inflating: dev_phase/subtask1/train/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._zho.csv  \n",
            "  inflating: dev_phase/subtask1/train/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._nep.csv  \n",
            "  inflating: dev_phase/subtask1/train/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._spa.csv  \n",
            "  inflating: dev_phase/subtask1/train/ita.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._ita.csv  \n",
            "  inflating: dev_phase/subtask1/train/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._urd.csv  \n",
            "  inflating: dev_phase/subtask1/train/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._amh.csv  \n",
            "  inflating: dev_phase/subtask1/train/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._tur.csv  \n",
            "  inflating: dev_phase/subtask1/train/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._deu.csv  \n",
            "  inflating: dev_phase/subtask1/train/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._eng.csv  \n",
            "  inflating: dev_phase/subtask1/train/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._hin.csv  \n",
            "  inflating: dev_phase/subtask1/train/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/train/._hau.csv  \n",
            "  inflating: dev_phase/subtask1/dev/arb.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._arb.csv  \n",
            "  inflating: dev_phase/subtask1/dev/fas.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._fas.csv  \n",
            "  inflating: dev_phase/subtask1/dev/zho.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._zho.csv  \n",
            "  inflating: dev_phase/subtask1/dev/nep.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._nep.csv  \n",
            "  inflating: dev_phase/subtask1/dev/spa.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._spa.csv  \n",
            "  inflating: dev_phase/subtask1/dev/ita.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._ita.csv  \n",
            "  inflating: dev_phase/subtask1/dev/urd.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._urd.csv  \n",
            "  inflating: dev_phase/subtask1/dev/amh.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._amh.csv  \n",
            "  inflating: dev_phase/subtask1/dev/tur.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._tur.csv  \n",
            "  inflating: dev_phase/subtask1/dev/deu.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._deu.csv  \n",
            "  inflating: dev_phase/subtask1/dev/eng.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._eng.csv  \n",
            "  inflating: dev_phase/subtask1/dev/hin.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._hin.csv  \n",
            "  inflating: dev_phase/subtask1/dev/hau.csv  \n",
            "  inflating: __MACOSX/dev_phase/subtask1/dev/._hau.csv  \n"
          ]
        }
      ],
      "source": [
        "# Install gdown if needed\n",
        "# Replace the ID below with your actual file ID from the Drive link\n",
        "# (The ID is the long string of random characters in the URL)\n",
        "file_id = '1Cvdkk_AZQzM5rJYhV4Nq-8bXvJrF8t4z'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "output = 'dev_phase.zip'\n",
        "\n",
        "!gdown {url} -O {output}\n",
        "\n",
        "!unzip {output}\n",
        "\n",
        "# Delete __MACOSX directory (if exists) and the dev_phase.zip file (cleanup)\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "if os.path.exists(\"__MACOSX\"):\n",
        "    shutil.rmtree(\"__MACOSX\")\n",
        "\n",
        "if os.path.exists(\"dev_phase.zip\"):\n",
        "    os.remove(\"dev_phase.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "843cbd77-1b7f-41df-aec8-1d53fe1199c2",
      "metadata": {
        "id": "843cbd77-1b7f-41df-aec8-1d53fe1199c2"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b8e9d6e-9342-43fd-9a0a-1330caf4e23a",
      "metadata": {
        "id": "5b8e9d6e-9342-43fd-9a0a-1330caf4e23a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "UkC2r47nManC",
      "metadata": {
        "id": "UkC2r47nManC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/00as2e01?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f65de092060>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# Disable wandb logging for this script\n",
        "wandb.init(mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7ac2064b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, random, numpy as np\n",
        "import torch\n",
        "\n",
        "seed = 42\n",
        "\n",
        "# python\n",
        "random.seed(seed)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "# numpy\n",
        "np.random.seed(seed)\n",
        "\n",
        "# pytorch\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# deterministic behavior\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dac92ad-3fac-4aa1-aae6-1fe3ad14b1c0",
      "metadata": {
        "id": "4dac92ad-3fac-4aa1-aae6-1fe3ad14b1c0"
      },
      "source": [
        "## Data Import\n",
        "\n",
        "The training data consists of a short text and binary labels\n",
        "\n",
        "The data is structured as a CSV file with the following fields:\n",
        "- id: a unique identifier for the sample\n",
        "- text: a sentence or short text\n",
        "- polarization:  1 text is polarized, 0 text is not polarized\n",
        "\n",
        "The data is in all three subtask folders the same but only containing the labels for the specific task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e4fe8cc2-ba47-4240-bdd2-b1d3ea323134",
      "metadata": {
        "id": "e4fe8cc2-ba47-4240-bdd2-b1d3ea323134"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c1242588-f157-4ba5-80e3-3c7658edc99b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>polarization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>eng_973938b90b0ff5d87d35a582f83f5c89</td>\n",
              "      <td>is defending imperialism in the dnd chat</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eng_07dfd4600426caca6e2c5883fcbea9ea</td>\n",
              "      <td>Still playing with this. I am now following Ra...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eng_f14519ff2302b6cd47712073f13bc461</td>\n",
              "      <td>.senate.gov Theres 3 groups out there Republic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>eng_e48b7e7542faafa544ac57b64bc80daf</td>\n",
              "      <td>\"ABC MD, David Anderson, said the additional f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eng_7c581fb77bce8033aeba3d6dbd6273eb</td>\n",
              "      <td>\"bad people\" I have some conservative values s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1242588-f157-4ba5-80e3-3c7658edc99b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c1242588-f157-4ba5-80e3-3c7658edc99b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c1242588-f157-4ba5-80e3-3c7658edc99b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                     id  \\\n",
              "0  eng_973938b90b0ff5d87d35a582f83f5c89   \n",
              "1  eng_07dfd4600426caca6e2c5883fcbea9ea   \n",
              "2  eng_f14519ff2302b6cd47712073f13bc461   \n",
              "3  eng_e48b7e7542faafa544ac57b64bc80daf   \n",
              "4  eng_7c581fb77bce8033aeba3d6dbd6273eb   \n",
              "\n",
              "                                                text  polarization  \n",
              "0           is defending imperialism in the dnd chat             0  \n",
              "1  Still playing with this. I am now following Ra...             0  \n",
              "2  .senate.gov Theres 3 groups out there Republic...             0  \n",
              "3  \"ABC MD, David Anderson, said the additional f...             0  \n",
              "4  \"bad people\" I have some conservative values s...             0  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the training and validation data for subtask 1\n",
        "\n",
        "train = pd.read_csv('./dev_phase/subtask1/train/eng.csv')\n",
        "test = pd.read_csv('./dev_phase/subtask1/dev/eng.csv')\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eQWDFio83z9g",
      "metadata": {
        "id": "eQWDFio83z9g"
      },
      "source": [
        "# Dataset\n",
        "-  Create a pytorch class for handling data\n",
        "-  Wrapping the raw texts and labels into a format that Huggingfaceâ€™s Trainer can use for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "8e749d08",
      "metadata": {
        "id": "8e749d08"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,texts,labels,tokenizer,max_length =128):\n",
        "    self.texts=texts\n",
        "    self.labels=labels\n",
        "    self.tokenizer= tokenizer\n",
        "    self.max_length = max_length # Store max_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    text=self.texts[idx]\n",
        "    label=self.labels[idx]\n",
        "    encoding=self.tokenizer(text,truncation=True,padding=False,max_length=self.max_length,return_tensors='pt')\n",
        "\n",
        "    # Ensure consistent tensor conversion for all items\n",
        "    item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "    item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "    return item"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adfb74a3",
      "metadata": {
        "id": "adfb74a3"
      },
      "source": [
        "Now, we'll tokenize the text data and create the datasets using `bert-base-uncased` as the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c2e6215b",
      "metadata": {
        "id": "c2e6215b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Load the tokenizer\n",
        "model_names = ['bert-base-uncased', \"UBC-NLP/MARBERTv2\"]\n",
        "model_name = model_names[0]\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "texts_train, texts_val, labels_train, labels_val = train_test_split(\n",
        "    train['text'].tolist(),\n",
        "    train['polarization'].tolist(),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train['polarization'].tolist(),  # if labels are imbalanced\n",
        ")\n",
        "\n",
        "train_dataset = PolarizationDataset(texts_train, labels_train, tokenizer)\n",
        "val_dataset = PolarizationDataset(texts_val, labels_val, tokenizer)\n",
        "# test_dataset = PolarizationDataset(test['text'].tolist(), test['polarization'].tolist(), tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b13caa5c",
      "metadata": {
        "id": "b13caa5c"
      },
      "source": [
        "Next, we'll load the pre-trained `bert-base-uncased` model for sequence classification. Since this is a binary classification task (Polarized/Not Polarized), we set `num_labels=2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "7cd0411f",
      "metadata": {
        "id": "7cd0411f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b250d61e",
      "metadata": {
        "id": "b250d61e"
      },
      "source": [
        "Now, we'll define the training arguments and the evaluation metric. We'll use macro F1 score for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c97269",
      "metadata": {
        "id": "21c97269"
      },
      "outputs": [],
      "source": [
        "# Define metrics function\n",
        "# Primary Metric F1 MACRO SCORE\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return {\n",
        "        'f1_macro': f1_score(p.label_ids, preds, average='macro'),\n",
        "        'accuracy': accuracy_score(p.label_ids, preds),\n",
        "        'precision': precision_score(p.label_ids, preds, average='binary'),\n",
        "        'recall': recall_score(p.label_ids, preds, average='binary'),\n",
        "        'f1_binary': f1_score(p.label_ids, preds, average='binary'),\n",
        "        'f1_micro': f1_score(p.label_ids, preds, average='micro')\n",
        "    }\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "        output_dir=f\"./\",\n",
        "        num_train_epochs=3,\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=64,\n",
        "        per_device_eval_batch_size=8,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_steps=100,\n",
        "        disable_tqdm=False\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20167a2b",
      "metadata": {
        "id": "20167a2b"
      },
      "source": [
        "Finally, we'll initialize the `Trainer` and start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecd9f444",
      "metadata": {
        "id": "ecd9f444"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='102' max='102' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [102/102 01:05, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.492411</td>\n",
              "      <td>0.718954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.468928</td>\n",
              "      <td>0.744665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.439700</td>\n",
              "      <td>0.468923</td>\n",
              "      <td>0.738514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [67/67 00:01]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1 score on validation set: 0.7385141903793659\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        "    data_collator=DataCollatorWithPadding(tokenizer) # Data collator for dynamic padding\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Validation Results:\\nAccuracy: {eval_results['eval_accuracy']:.4f}\\nPrecision: {eval_results['eval_precision']:.4f}\\nRecall: {eval_results['eval_recall']:.4f}\\nF1 (binary): {eval_results['eval_f1_binary']:.4f}\\nF1 (macro): {eval_results['eval_f1_macro']:.4f}\\nF1 (micro): {eval_results['eval_f1_micro']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c7f8b1e5",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f48697428dc44cc8b60ab8395ee3d5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/133 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "God is with Ukraine and Zelensky\n",
            "4 Dems, 2 Republicans Luzerne County Council seatsDallas\n",
            "Abuse Survivor Recounts Her Struggles at YWCA Event\n",
            "After Rwanda, another deportation camp disaster\n",
            "Another plea in Trump election interference probe\n",
            "any number of southern red states tbh\n",
            "Breitbart is the new age grocery aisle tabloid\n",
            "Congressman talks border security, debit limit\n",
            "Cooke Co. GOP incumbents announce reelection runs\n",
            "Could one overwhelm the iron dome?\n",
            "Dan PatrickDade Phelan feud in Texas GOP threatens\n",
            "Democrats meet in Plymouth for moderated gubernatorial\n",
            "Election fraud did not go away, it is here. Every American must vote to overcome the election fraud. 2022 and 2024.\n",
            "Faculty , educate students on the IsraelHamas war\n",
            "GOP defense budgets abortion, diversity limits draw Biden\n",
            "GOP lawmakers ramp up pushback on Snake River dam\n",
            "Guilford County GOP Congratulates New School Board\n",
            "Hamas has nobody else to rescue them. Its over! Hamas says Gaza ceasefire deal closer than ever before Qatar, along with the UnitedStates and Egypt, has been involved in months of behindthescenes negotiations for a Gaza truce and hostage release f24.myAoqd.X\n",
            "Hamas indicates ceasefire deal is close, if Israel stops adding new conditions @URL\n",
            "Hamas struck first and is a terrorist group. Stop the use of human beings as human shields and then well talk.\n",
            "Harshbarger nominates VonCannon for GOP awardCitizen\n",
            "House GOP accuses President Biden of influence\n",
            "How Pam Bondi boosted Trumps election fraud claims in a key swing state, via @URL\n",
            "I wish she hmu like these early voting ppl is.\n",
            "In Gaza, a different view of the Hamas raid on IsraelThe Christian Science Monitor\n",
            "Is Biden in trouble with Democrats over Gaza?\n",
            "Israel imposes complete siege of Gaza Hamas threatens\n",
            "IsraelHamas temporary truce day 1 recap\n",
            "Israeli leader took the pants off U.S. president @URL\n",
            "Israeli strikes kill at least 37 Palestinians, most in tents\n",
            "Ken Paxton blasts fellow Republicans and floats Cornyn\n",
            "Lev Parnas says no Joe Biden fraud in Ukraine\n",
            "linguistics sociolinguist Paul Kerswill on The Cockney Yiddish Podcast on language and immigration\n",
            "National Enquirer tabloid that buried Donald Trump stories\n",
            "National Police Week: Union Deputy and New Albany Officers Honored\n",
            "Nebraska Gov. Pillen's Back-to-Office Order Raises Concerns\n",
            "New Spot Built with Focus on Training Service Dogs\n",
            "Nexus Services Inc. owners found in contempt as sanctions\n",
            "Northwestern students honor Israeli hostages on Deering\n",
            "Not all the Nazis were from Germany, either There were also Austrian Ukrainian nazis, for example\n",
            "Not really ironic considering Zelensky is proIsrael, but I see your point.\n",
            "Political ads on fentanyl and border security dont tell the whole story\n",
            "pro palestine march, media city, 2021 kodak gold instagram @URL savegaza palestine savepalestine propalestine photography shootfilm\n",
            "Putin makes Putin behave like this\n",
            "Quite a few since 24 Feb because they were Russian supporters of the Ukraine invasion.\n",
            "Raleigh residents push for ceasefire in Gaza\n",
            "Republicans celebrate local victories in Rockingham\n",
            "Say \"open borders\" thats all I need to hear.\n",
            "Shes been on Fox News, OAN, and Breitbart. Yeah, shes real...\n",
            "SO WHY IS THE US SENDING THEM SO MUCH MILITARY AID THEN\n",
            "Springfields Haitian community reacts to Trumps mass deportation threats @URL\n",
            "St. Johnsbury Hires New Police Chief\n",
            "stands up for parents, holding criminals accountable, border security and legal immigration\n",
            "Suspicions of voter fraud raised in Clerk of Court\n",
            "Texas AG Ken Paxton acquitted in impeachment trial\n",
            "Thanks to President Biden for obtaining 1.5 billion from Mexico for border security.\n",
            "There Are Voices To Be Heard Before the Vacated LSHA Position Filled\n",
            "This is a lie. Carter said no apartheid existed in Israel but existed in the West Bank. The West Bank isnt Israel\n",
            "This Israeli bourbon is made from Kansas corn mashed\n",
            "Who stopped the counting at 3 am in the swing states? Who ..?? You know..you absolutely know..\n",
            "Why does America still need the Electoral College?\n",
            "Will Kamala Harris bail him out?\n",
            "WIP US USA Trump Inauguration GOP\n",
            "Wisconsin Republicans float bill to designate state\n",
            "You mean the early voting locations?\n",
            "You think Trump is for open borders?\n",
            "Are u still working tirelessly for that ceasefire\n",
            "Boy CNN is the new FOX news\n",
            "Democrats are not liberals actually.\n",
            "Exactly. And on starlink service contracts. The add it to whiskey, and select products produced in red states.\n",
            "Great Barrier Reefs current suffering represents a place at Polling Places Highly In other assaults\n",
            "HelpRefugees_Indonesia It has been a decade that refugees are living in uncertainty. Please help Refugees.\n",
            "Is this Russian invasion or NATO expansion?\n",
            "Israeli PM meets ministers reax to possible ceasefire Israel\n",
            "Mike Pence is such a nerd\n",
            "More than 8,000 people have been arrested by federal immigration authorities since Trumps inauguration\n",
            "Oh right I forgot this movie had an illegal immigration subplot\n",
            "Other than patriotism and national identity, what are legitimate reasons why Canada should not be a part of the Genuinely curious.\n",
            "The US is accepting Ukrainian refugees\n",
            "The White House announces 800 M additional military aid to Ukraine, including 11 Mi17 helicopters.\n",
            "This from Mike Pence! I mean Im quoting Mike Pence!!\n",
            "im in my ceasefire era\n",
            "\"BREAKING The US is bombing civilians in Yemen as Israel commanded\" genocide Genocide Joe. Genocide Kamala. x.comPartisangirl...\n",
            "A Federal Investigation needs to be launched against TWITTER Fraud and Election Interference\n",
            "And Zionism is a genocidal psychopathic death cult.\n",
            "Biggs. Youre extreme right wing agenda is wrong for America.\n",
            "Black Men in U.S. Face Endless Police Horror Stories\n",
            "But \"they\" pushed \"defund\" the police?\n",
            "Do Your Job Kamala, Close The Wide Open Borders.\n",
            "Donald Trump is escalating his rhetoric as he runs\n",
            "Fukin cheaters...Trump was 600,000 in PA alone and all swing states he was up in by A LOT!\n",
            "Go on, read it. Show me the federal governments jurisdiction over state polling places.\n",
            "Good. Im tired of my taxes funding red states.\n",
            "I am getting my news from MSNBC and the Meidas Touch network. Believe me, I understand Project 2025.\n",
            "I dont remember voting to have open borders either.\n",
            "I guess Steve didnt get the memo that the red states historically take more handouts than the blue states.\n",
            "I have a weird point to mention but I always feel like when they say Christian Nationalism, it needs an additional word, White Christian Nationalism. Theres no place for brown people or black churches or Hispanic or liberal in the WCN movement.\n",
            "I imagine reasonable Germans in the 1940s who were not adherents to Nazism when Hitler started implementing his extreme policies felt about the same surreal feeling as Americans who are not adherents to \"Trumpism\" are feeling now.\n",
            "Leave occupied territories and stop recruiting young adults for your apartheid state\n",
            "Long live Mother Russia. Listen to my advice since youve already lost the war, Ukrainian Nazis, stop crying and focus on removing the tattoos from your wretched bodies before the Nazi hunters find you. And instead of donating to the Nazis, save your money for an emergency. Peace!!!\n",
            "Modern day genocide and ethnic cleansing with impunity\n",
            "NATO countries doesnt have balls to interfere They will only shout Sanctions Sanctions\n",
            "Netanyahu and the IDF are committing genocide\n",
            "No it cant. The radical left is a House of Cards.\n",
            "NO! Mail in ballots and early voting NEEDS to stop!\n",
            "Not all show. Rejected iron dome funding and pushed genocide blood libel, so shes your gal, I suppose.\n",
            "PRESIDENT TRUMP HAPPY THANKSGIVING TO ALL, Including To The Radical Left Lunatics Who Have Worked So Hard To Destroy Our Country, But Who Have Miserably Failed, And Will Always Fail, Because Their Ideas And Proud To Be An American!\n",
            "Say it LOUDER! Not enough fuckwits are naming this what it is the product of Christian White Nationalism, which has been brewing for decades in this country and finally manifested in this presidency!\n",
            "The real dangers of this bogus populism\n",
            "Then why did you withhold military aid to them?? We remember, Mike.\n",
            "This is a massive scandal. It is time for impeachment.\n",
            "This whole platform is communist propaganda\n",
            "Who gave the order to stop counting votes in the swing states on the night of November 34, 2020?\n",
            "Why is it immediately deportation instead of immigration reform, with this guy?\n",
            "Yes if we all post the Ukrainian flag on social media itll stop the Russian aggression.\n",
            "You bet. Time for the blue states to demand that the red states pony up. In some red states federal support is over 40 of the state budget.\n",
            "Zionism antisemitism Have you not researched the founders of Zionism? Its foundation is racialethnicreligious Supremacy.\n",
            "\"Mqundu we xenophobia\" you gotta love Xhosa women\n",
            "Every single article from MSNBC reads like they had no idea this would happen\n",
            "Fuck Putin All my homies hate Putin\n",
            "Fuck jd vance. pos traitor.\n",
            "If Zelensky doesnt get what Zelensky wants Zelensky drops dime on the Brandon crime family.\n",
            "Its called And a rigged election.\n",
            "Its still Free Palestine tho!\n",
            "Just remember that Democrata took better care of Ukrainian Nazis than their own citizens during a global pandemic.\n",
            "Mayorkas Secretly Met with SorosFunded Groups During Border Trip to Address Migrant Crisis\n",
            "Open borders and multiculturalism still working against British girls but still nothing gets done.\n",
            "Open borders, mass immigration Starmer continues on with the Tory experiment gone wrong.\n",
            "Should run for GOP press. LOL\n",
            "The shampoo will rinse down in the shower, and illegal immigration.\n",
            "Tomorrow Mike Pence is in love with bussy\n",
            "Unknown gunmen have shot and killed an Israeli guard at the entrance to the illegal Israeli settlement of Ariel in northcentral West Bank.\n",
            "we build a wall around the red states and celebrate 9 new provinces\n"
          ]
        }
      ],
      "source": [
        "test_dataset = pd.read_csv('./dev_phase/subtask1/dev/eng.csv')\n",
        "labels = []\n",
        "probs_list = []\n",
        "labels = []\n",
        "for text in tqdm(test_dataset['text']):\n",
        "    # Run the model\n",
        "    print(text)\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "        pred_label = logits.argmax(dim=1).cpu().numpy()[0]\n",
        "        labels.append(pred_label)\n",
        "        probs_list.append(probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "7b370d71",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eng_f66ca14d60851371f9720aaf4ccd9b58,0, [0.6541927 0.3458073]\n",
            "eng_3a489aa7fed9726aa8d3d4fe74c57efb,0, [0.9624602  0.03753977]\n",
            "eng_95770ff547ea5e48b0be00f385986483,0, [0.9794422  0.02055784]\n",
            "eng_2048ae6f9aa261c48e6d777bcc5b38bf,0, [0.9325723  0.06742771]\n",
            "eng_07781aa88e61e7c0a996abd1e5ea3a20,0, [0.9651683  0.03483172]\n",
            "eng_153d96f9dc27f0602c927223404d94b5,0, [0.9345434  0.06545668]\n",
            "eng_4ab5a4cc5c87d0af9cf4b80c301647bf,1, [0.27487347 0.7251265 ]\n",
            "eng_e75a95ba52930d6d72d503ab9469eb29,0, [0.9790981  0.02090194]\n",
            "eng_eb8fab668668f9959cafdecbfc0f081a,0, [0.9725691  0.02743092]\n",
            "eng_702724dc168d600e788d775c8e651f36,0, [0.68961114 0.31038886]\n",
            "eng_0efa1a3567443075db38c7ce2dcca571,0, [0.97684264 0.02315729]\n",
            "eng_d08d4243fd2786795df39c1a65dacac7,0, [0.98095924 0.01904074]\n",
            "eng_79fa99ba6989fb61ec127c6c99fc2343,1, [0.24789402 0.75210595]\n",
            "eng_30981038b71c210e97731d90e86038c5,0, [0.95542306 0.04457694]\n",
            "eng_b75e663a6fdc280171b6385b99306a3c,0, [0.97291416 0.0270858 ]\n",
            "eng_de2baffcfc59b672905e6f2694f672f6,0, [0.97957474 0.02042521]\n",
            "eng_d887794cce49564890a2552cdfb745d2,0, [0.97545415 0.02454589]\n",
            "eng_097b78cf6e209e6778e1fbda10d28b8d,0, [0.9145591  0.08544084]\n",
            "eng_6d29b7c72a091789d06d92157688e07f,0, [0.9777009  0.02229916]\n",
            "eng_00c797e70f1a2f50f1c59655f08581e1,1, [0.1518522  0.84814787]\n",
            "eng_f1e66eab0b9b2c4a83103eb65a67046e,0, [0.97887325 0.0211268 ]\n",
            "eng_4bf47d33b804477375ade2a151cb2614,0, [0.98324597 0.01675404]\n",
            "eng_6b4616355cbed93c122ca3e2369b3a0d,0, [0.94586384 0.0541362 ]\n",
            "eng_f011b534fb34efc8c574d2e16d3a95f5,0, [0.88857067 0.11142935]\n",
            "eng_8376c26da2f537abeada29ed927d3e01,0, [0.96907896 0.03092106]\n",
            "eng_af8597fa9be96fdfabb05c593476913c,0, [0.8942194  0.10578063]\n",
            "eng_e0f6e8dce6d6a6c13632b80100e5a6b1,0, [0.97667533 0.02332466]\n",
            "eng_48b992b30d2029785845b563a5ed5908,0, [0.97299486 0.02700519]\n",
            "eng_265277158900e90636bb6614c8f265b7,0, [0.9702837  0.02971631]\n",
            "eng_3c4dc44df877cfb232d222462dab6543,0, [0.93510437 0.06489564]\n",
            "eng_08a2c6cca0e7d33249339bbbef85c6c1,1, [0.49547923 0.5045208 ]\n",
            "eng_68280914d983fd99c5630ddd76e4bd95,0, [0.97573096 0.024269  ]\n",
            "eng_cd13f9dc863b830f0f1a123db729eaff,0, [0.88891566 0.11108439]\n",
            "eng_6f76d66a4bd34d5ce4a94ec943385197,0, [0.90486664 0.09513331]\n",
            "eng_12e097065c75824d4121c0ec670647c1,0, [0.9729504  0.02704958]\n",
            "eng_bbd31cdfc7077e4903c3204ef1b9175f,0, [0.9703601  0.02963983]\n",
            "eng_4b4f2e1f0e1255dccef1959d2b30165b,0, [0.9460858  0.05391416]\n",
            "eng_cae0921076de11e46ad10498cc7d5441,0, [0.94988215 0.05011779]\n",
            "eng_298c63907209feee5c7cfe0bba8cb7be,0, [0.9807724  0.01922762]\n",
            "eng_47c81418327ba69c71e62f93a060ed39,1, [0.20996413 0.79003584]\n",
            "eng_1d443006327009ce2aff905147b39692,0, [0.6582312 0.3417688]\n",
            "eng_71021b3579c72f916147f751bce10e0c,0, [0.7451783  0.25482175]\n",
            "eng_de9a2ae60667aaddf4c646338764b526,0, [0.9449171  0.05508297]\n",
            "eng_c07a5a7dabfdb3965ec98128f318175f,1, [0.2651713  0.73482865]\n",
            "eng_fbceb1ae34db8daf3cf672a3d4256ddf,1, [0.23624484 0.7637551 ]\n",
            "eng_3fee89034fbdfa73372d1c88eb0aea59,0, [0.9785881  0.02141188]\n",
            "eng_c532b3613bde52aa43a9475f1ea0b32d,0, [0.979518   0.02048199]\n",
            "eng_29ea84be308aaa614a463ddba1dfb36d,0, [0.7350015  0.26499853]\n",
            "eng_7b509629f338753f35fef4914bda9da6,0, [0.75989723 0.24010275]\n",
            "eng_3152400ae6bd362a4ae4405ea86070ec,0, [0.63449514 0.36550483]\n",
            "eng_c3a320d25b76f154caab9d9361b00907,0, [0.79882497 0.201175  ]\n",
            "eng_3235c4f9ae1a74593f5cc6cff9277a85,0, [0.9751561  0.02484387]\n",
            "eng_0077188f1a05dd1d68f8352a9b84ca79,0, [0.81783015 0.1821699 ]\n",
            "eng_a390951455e707af9520c71ffc9db2d9,0, [0.97450554 0.02549452]\n",
            "eng_2b75f86d237a8699a27582ad90e42919,0, [0.98202217 0.01797783]\n",
            "eng_d21174080515b0ad8dc1d00ee4368d4f,0, [0.95064443 0.04935555]\n",
            "eng_ef00c86f2c475df7cee4fd5dd25e2bc7,0, [0.9433931  0.05660686]\n",
            "eng_74a62e8e997bc736b2894d9bc4da7661,1, [0.18834381 0.8116562 ]\n",
            "eng_9aad387704111e1f051fce5968ef2232,0, [0.73763317 0.2623668 ]\n",
            "eng_db9761cf21a3abb48b2669423ff5788a,0, [0.56051403 0.43948603]\n",
            "eng_7811dd491f8437afd9689a75ccb1ce04,0, [0.8343574  0.16564266]\n",
            "eng_437f5f40d878166878c2d32b8e16af31,0, [0.8547088  0.14529118]\n",
            "eng_a8b55f8a70d1c34f93fbdefa0350e507,0, [0.9718777  0.02812224]\n",
            "eng_01057285508602421377273897c3c0e7,0, [0.981406 0.018594]\n",
            "eng_175c490fa4665823f1dc2fc44e4d98fb,0, [0.8109148  0.18908516]\n",
            "eng_1feb16d41ce65927a8153742d14b5b6b,0, [0.5505408  0.44945917]\n",
            "eng_8182654f9b6144da76e1cfcc985a4b3a,0, [0.7750129  0.22498704]\n",
            "eng_03a2aea654b7697fcd72acdbf7ecf944,0, [0.8672048  0.13279524]\n",
            "eng_a4a13cea5e6750286b14ae7a8d81bd28,1, [0.32345796 0.676542  ]\n",
            "eng_927ef1e092e0b61d9161dccb20b7d212,0, [0.6689519 0.3310481]\n",
            "eng_bab15926554f28dc36582b6e275b8805,0, [0.9742081  0.02579191]\n",
            "eng_938602684a67196e4bd95b313ad3919f,0, [0.643822   0.35617805]\n",
            "eng_d6d5259e0d04bf6fc543ba5baaf273f1,0, [0.8541787  0.14582126]\n",
            "eng_bf5e5633ac2fdca9164c02022e0c99fd,0, [0.9811918  0.01880817]\n",
            "eng_31268830d496fa2970b2ff9918b3b7ba,1, [0.31324148 0.6867585 ]\n",
            "eng_95d7415206b7898a7486b0c69197baa2,0, [0.9328675  0.06713241]\n",
            "eng_b91a56f542d0513d636a0a019b7726eb,0, [0.63369775 0.36630225]\n",
            "eng_eeaa3e10a86dec32fbc1b9f1d156d796,1, [0.47829673 0.5217033 ]\n",
            "eng_e2622eb5bd4d433e6138c58d943b4043,0, [0.93880683 0.06119315]\n",
            "eng_533142c1bdb17ab3ffdf43e6e25f1406,0, [0.9595178  0.04048223]\n",
            "eng_325cd4d0e08485ec5693fcf15b14ff1f,0, [0.6109876  0.38901243]\n",
            "eng_063b19c19c369b678bf3446054569fdf,0, [0.8536912  0.14630881]\n",
            "eng_ebe1ae54e0854b322ad3c9667a2a4802,1, [0.26244244 0.7375576 ]\n",
            "eng_f1a522278c7fff07d7d7f3d033b5fa36,0, [0.9052835 0.0947165]\n",
            "eng_50c78c3a83be7868fb1ce0d636911f63,1, [0.14474556 0.8552545 ]\n",
            "eng_0f6d980d360c0a6c8f1edfdf6a791fb8,1, [0.16223082 0.8377692 ]\n",
            "eng_5a19fecc98ef147b13b59bd0d8caf8d5,1, [0.41136602 0.588634  ]\n",
            "eng_3ad13d30d6003ac059e6c923a7a7eafb,1, [0.45250085 0.5474992 ]\n",
            "eng_74e531f9dcb74c5a7bfd9668012a8c74,0, [0.6649036 0.3350964]\n",
            "eng_b666fec715d97437ecb9c0c6a54378c4,0, [0.7236995  0.27630052]\n",
            "eng_5b51f6101221e28d6da47f2cb7214ee6,1, [0.18993172 0.8100683 ]\n",
            "eng_c12c886536597ecaddd1e94e922e8969,0, [0.75876856 0.24123149]\n",
            "eng_882dae250fd3467770c289b835a2aa83,0, [0.7060758  0.29392427]\n",
            "eng_b9cfff2304e5349d315bc474ce2899eb,0, [0.7603257  0.23967434]\n",
            "eng_3857e2c131a5b5fef5bbf2e9794bcd5e,0, [0.7738924  0.22610767]\n",
            "eng_2806bece99f0002047cc86a78a30a1d7,0, [0.68725675 0.31274325]\n",
            "eng_003fc3a198de8381e08ab3d85c7e40be,1, [0.17101574 0.82898426]\n",
            "eng_d74c7582012f631348296b2dbf10f4f6,1, [0.17906877 0.82093126]\n",
            "eng_0e62ae808071606db649622cb73dc2cb,1, [0.15702245 0.8429776 ]\n",
            "eng_8cef4402ae1b38e7c4593cc163bfe10c,1, [0.1800988 0.8199012]\n",
            "eng_310cb1f24f3545a53f33e005798ece95,1, [0.20926376 0.79073626]\n",
            "eng_5606f46a55984e9bf7db7034d451a1f6,0, [0.76850235 0.23149766]\n",
            "eng_ab5a1479644f5672c6337214087ecb4d,0, [0.5636382  0.43636176]\n",
            "eng_5e89647c49019ef6f4e3549bc5b41970,1, [0.24499784 0.75500214]\n",
            "eng_fd3ae133fa1ae5dac30d88c601d3171e,0, [0.86530703 0.13469294]\n",
            "eng_995661141a6abbbdef6770db6e1bd8f5,1, [0.18612535 0.8138746 ]\n",
            "eng_88e3a4bddcf38fe36666e6875399f6c3,0, [0.52538973 0.47461027]\n",
            "eng_5fbc07e0e76d061ad2496d55c93f4970,1, [0.15145102 0.84854895]\n",
            "eng_ef3116c56645f94bbe998051aaa49e40,1, [0.20946865 0.79053134]\n",
            "eng_4cd9e7e11035bcacb2814a1817238e75,0, [0.6300469  0.36995307]\n",
            "eng_ebd69a723309a37d9b5f384a3cd5c87c,1, [0.4262278 0.5737722]\n",
            "eng_d0b1c523b1cb02e41ca250d4d705efe6,1, [0.17967157 0.8203284 ]\n",
            "eng_5f408abc83c76617c0525e042a3ceb48,0, [0.94674516 0.0532548 ]\n",
            "eng_947ae20dbd1e2a3ba07bcdbd4b6a4eaa,0, [0.5126569 0.4873431]\n",
            "eng_3496f210f022027af26571fa2a2b6e30,1, [0.46465856 0.53534144]\n",
            "eng_4fca762d791268e973669733aa684e37,1, [0.29826763 0.7017324 ]\n",
            "eng_93a2492e7860be0d7ca445a97e245abe,1, [0.14339606 0.856604  ]\n",
            "eng_b2f95890baff716a2d871097a1c210fe,1, [0.2326062 0.7673938]\n",
            "eng_e5cfe9e96de0f4873a4a6dbfca573be2,0, [0.6004801  0.39951995]\n",
            "eng_897afb355e98b187b9f75478bbbf2c51,1, [0.17318448 0.8268155 ]\n",
            "eng_f0ae86891c2da536ebf24c0f3964dca8,1, [0.2046659 0.7953341]\n",
            "eng_e231e20dbb7d3d433637dbb3d3c946a0,1, [0.3565929 0.6434071]\n",
            "eng_8ee2b2e8b53c55407f30fbf1219b1588,1, [0.23010722 0.76989275]\n",
            "eng_0eb6247db86e3b42c8dc125317957580,1, [0.4223692 0.5776308]\n",
            "eng_185e4dabf037ec90771e1bd18e621e2a,1, [0.17394711 0.82605284]\n",
            "eng_dbadd716608d71fb92621f7f8259f4e4,0, [0.97618836 0.02381163]\n",
            "eng_ac3c36cc719bdce4cab6c919b9b2429e,1, [0.18728068 0.8127193 ]\n",
            "eng_5d8aa4863fe2f8c26f541937ff5a0368,1, [0.22033404 0.7796659 ]\n",
            "eng_2fd4484b6bab80971a96b2100e20966a,0, [0.97331953 0.0266805 ]\n",
            "eng_0e11358da0c0e0cd8e0fdedf05a0cbba,1, [0.20446399 0.795536  ]\n",
            "eng_0fb944d51bb376102a3ea6b65bafab6a,0, [0.598887   0.40111294]\n",
            "eng_d9253eaeb206934208a57786b688c316,0, [0.91383404 0.08616594]\n",
            "eng_d841e099c41eb0fdd803e7c0a6109933,0, [0.6153208  0.38467917]\n"
          ]
        }
      ],
      "source": [
        "# print the results row by row in csv format\n",
        "for i in range(len(labels)):\n",
        "    print(f\"{test_dataset['id'][i]},{labels[i]}, {probs_list[i]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Qi53eheGIbu",
      "metadata": {
        "id": "5Qi53eheGIbu"
      },
      "source": [
        "# Subtask 2: Polarization Type Classification\n",
        "Multi-label classification to identify the target of polarization as one of the following categories: Gender/Sexual, Political, Religious, Racial/Ethnic, or Other.\n",
        "For this task we will load the data for subtask 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "YaWIvnYv0rV2",
      "metadata": {
        "id": "YaWIvnYv0rV2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>political</th>\n",
              "      <th>racial/ethnic</th>\n",
              "      <th>religious</th>\n",
              "      <th>gender/sexual</th>\n",
              "      <th>other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>eng_973938b90b0ff5d87d35a582f83f5c89</td>\n",
              "      <td>is defending imperialism in the dnd chat</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eng_07dfd4600426caca6e2c5883fcbea9ea</td>\n",
              "      <td>Still playing with this. I am now following Ra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eng_f14519ff2302b6cd47712073f13bc461</td>\n",
              "      <td>.senate.gov Theres 3 groups out there Republic...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>eng_e48b7e7542faafa544ac57b64bc80daf</td>\n",
              "      <td>\"ABC MD, David Anderson, said the additional f...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>eng_7c581fb77bce8033aeba3d6dbd6273eb</td>\n",
              "      <td>\"bad people\" I have some conservative values s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     id  \\\n",
              "0  eng_973938b90b0ff5d87d35a582f83f5c89   \n",
              "1  eng_07dfd4600426caca6e2c5883fcbea9ea   \n",
              "2  eng_f14519ff2302b6cd47712073f13bc461   \n",
              "3  eng_e48b7e7542faafa544ac57b64bc80daf   \n",
              "4  eng_7c581fb77bce8033aeba3d6dbd6273eb   \n",
              "\n",
              "                                                text  political  \\\n",
              "0           is defending imperialism in the dnd chat          0   \n",
              "1  Still playing with this. I am now following Ra...          0   \n",
              "2  .senate.gov Theres 3 groups out there Republic...          0   \n",
              "3  \"ABC MD, David Anderson, said the additional f...          0   \n",
              "4  \"bad people\" I have some conservative values s...          0   \n",
              "\n",
              "   racial/ethnic  religious  gender/sexual  other  \n",
              "0              0          0              0      0  \n",
              "1              0          0              0      0  \n",
              "2              0          0              0      0  \n",
              "3              0          0              0      0  \n",
              "4              0          0              0      0  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train = pd.read_csv('./dev_phase/subtask2/train/eng.csv')\n",
        "val = pd.read_csv('./dev_phase/subtask2/train/eng.csv')\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "I6S2S6QBDKzw",
      "metadata": {
        "id": "I6S2S6QBDKzw"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length # Store max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, truncation=True, padding=False, max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        # Ensure consistent tensor conversion for all items\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        # CHANGE THIS LINE: Use torch.float instead of torch.long for multi-label classification\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "u1_KYsG68nxI",
      "metadata": {
        "id": "u1_KYsG68nxI"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Create train and Test dataset for multilabel\n",
        "train_dataset = PolarizationDataset(train['text'].tolist(), train[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n",
        "val_dataset = PolarizationDataset(val['text'].tolist(), val[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n",
        "dev_dataset = PolarizationDataset(val['text'].tolist(), val[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "cdiYJyr08bw2",
      "metadata": {
        "id": "cdiYJyr08bw2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5, problem_type=\"multi_label_classification\") # 5 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ArVWKwze2mtS",
      "metadata": {
        "id": "ArVWKwze2mtS"
      },
      "outputs": [],
      "source": [
        "# Define metrics function for multi-label classification\n",
        "def compute_metrics_multilabel(p):\n",
        "    # Sigmoid the predictions to get probabilities\n",
        "    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n",
        "    # Convert probabilities to predicted labels (0 or 1)\n",
        "    preds = (probs > 0.5).int().numpy()\n",
        "    # Compute macro F1 score\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./\",\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100,\n",
        "    disable_tqdm=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qd3QPyfc2RKE",
      "metadata": {
        "id": "Qd3QPyfc2RKE"
      },
      "outputs": [],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics_multilabel,  # Use the new metrics function\n",
        "    data_collator=DataCollatorWithPadding(tokenizer)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set for Subtask 2: {eval_results['eval_f1_macro']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UL1uE8llIgTQ",
      "metadata": {
        "id": "UL1uE8llIgTQ"
      },
      "source": [
        "# Subtask 3: Manifestation Identification\n",
        "Multi-label classification to classify how polarization is expressed, with multiple possible labels including Vilification, Extreme Language, Stereotype, Invalidation, Lack of Empathy, and Dehumanization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nCz20cgl-K3t",
      "metadata": {
        "id": "nCz20cgl-K3t"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv('subtask3/train/eng.csv')\n",
        "val = pd.read_csv('subtask3/train/eng.csv')\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qs-UjVYsInpD",
      "metadata": {
        "id": "Qs-UjVYsInpD"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length # Store max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, truncation=True, padding=False, max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        # Ensure consistent tensor conversion for all items\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        # CHANGE THIS LINE: Use torch.float instead of torch.long for multi-label classification\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-yxSaDCA9IMi",
      "metadata": {
        "id": "-yxSaDCA9IMi"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Create train and Test dataset for multilabel\n",
        "train_dataset = PolarizationDataset(train['text'].tolist(), train[['vilification','extreme_language','stereotype','invalidation','lack_of_empathy','dehumanization']].values.tolist(), tokenizer)\n",
        "val_dataset = PolarizationDataset(val['text'].tolist(), val[['vilification','extreme_language','stereotype','invalidation','lack_of_empathy','dehumanization']].values.tolist(), tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0VXqqqIH9A3M",
      "metadata": {
        "id": "0VXqqqIH9A3M"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6, problem_type=\"multi_label_classification\") # use 6 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QLubGtx988hm",
      "metadata": {
        "id": "QLubGtx988hm"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./\",\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100,\n",
        "    disable_tqdm=False\n",
        ")\n",
        "\n",
        "# Define metrics function for multi-label classification\n",
        "def compute_metrics_multilabel(p):\n",
        "    # Sigmoid the predictions to get probabilities\n",
        "    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n",
        "    # Convert probabilities to predicted labels (0 or 1)\n",
        "    preds = (probs > 0.5).int().numpy()\n",
        "    # Compute macro F1 score\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qEhm1TEv82mP",
      "metadata": {
        "id": "qEhm1TEv82mP"
      },
      "outputs": [],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics_multilabel,  # Use the new metrics function\n",
        "    data_collator=DataCollatorWithPadding(tokenizer)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set for Subtask 3: {eval_results['eval_f1_macro']}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
