{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81beb43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "student_lm_name = \"fireworks_ai/accounts/fireworks/models/glm-4p6\"\n",
    "teacher_lm_name = \"fireworks_ai/accounts/fireworks/models/glm-4p6\"\n",
    "\n",
    "student_lm = dspy.LM(student_lm_name)\n",
    "teacher_lm = dspy.LM(teacher_lm_name)\n",
    "\n",
    "dspy.configure(lm=student_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6c9db",
   "metadata": {},
   "source": [
    "# Prepare DSPY Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390a2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train val test split\n",
    "lang = \"eng\"\n",
    "# Load the training and validation data for subtask 1\n",
    "train_df = pd.read_csv(f'./dev_phase/subtask1/train/{lang}.csv')\n",
    "test_df = pd.read_csv(f'./dev_phase/subtask1/dev/{lang}.csv')\n",
    "# Split train into train and validation sets\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ccdaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the polarization numeric label to a string\n",
    "POLARIZATION_MAP = {1: \"polarization\", 0: \"no polarization\"}\n",
    "\n",
    "def make_dspy_examples(df, include_label: bool = True):\n",
    "    examples = []\n",
    "    for _, row in df.iterrows():\n",
    "        kwargs = dict(\n",
    "            sentence=row[\"text\"],\n",
    "        )\n",
    "        if include_label and \"polarization\" in row:\n",
    "            kwargs[\"polarization\"] = POLARIZATION_MAP[row[\"polarization\"]]\n",
    "        example = dspy.Example(**kwargs).with_inputs(\"sentence\")\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "# Create DSPY datasets\n",
    "raw_train = make_dspy_examples(train_df, include_label=True)\n",
    "raw_val = make_dspy_examples(val_df, include_label=True)\n",
    "raw_test = make_dspy_examples(test_df, include_label=False)\n",
    "\n",
    "\n",
    "# # For now take only 10% of each \n",
    "raw_train = raw_train[:int(len(raw_train) * 0.2)]\n",
    "raw_val = raw_val[:int(len(raw_val) * 0.3)]\n",
    "raw_test = raw_test[:int(len(raw_test) * 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6ebcb",
   "metadata": {},
   "source": [
    "# Define Signature (Subtask 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "012b53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Polarization(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Polarization denotes stereotyping, vilification, dehumanization, deindividuation, or intolerance of other people’s views, beliefs, and identities. In this study, speeches and articles that are shared on social media that incite division, groupism, hatred, conflict, and intolerance are classified as containing polarization.\n",
    "    Given this sentence, classify it as containing polarization or not.\"\"\"\n",
    "\n",
    "    sentence: str = dspy.InputField()\n",
    "    polarization: Literal[\"polarization\", \"no polarization\"] = dspy.OutputField(\n",
    "        desc='Return \"polarization\" or \"no polarization\".',\n",
    "        choices=[\"polarization\", \"no polarization\"],\n",
    "    )\n",
    "classify = dspy.Predict(Polarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9272d5",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a87480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "POLARIZATION_MAP = {1: \"polarization\", 0: \"no polarization\"}\n",
    "\n",
    "def label2id(label: str) -> int:\n",
    "    return {v: k for k, v in POLARIZATION_MAP.items()}[label]\n",
    "\n",
    "def id2label(i: int) -> str:\n",
    "    return POLARIZATION_MAP[i]\n",
    "\n",
    "def accuracy_metric(example, pred, trace=None):\n",
    "    gold = example.polarization          # from your Examples\n",
    "    guess = pred.polarization         # from Signature output\n",
    "    return int(gold == guess)         # 1 = correct, 0 = incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c6ed1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 62.00 / 73 (84.9%):  36%|███▌      | 73/202 [05:01<07:37,  3.55s/it] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 17:37:29 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=None. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently None)  if the reason for truncation is repetition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 165.00 / 202 (81.7%): 100%|██████████| 202/202 [12:46<00:00,  3.79s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/04 17:45:07 INFO dspy.evaluate.evaluate: Average Metric: 165 / 202 (81.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>example_polarization</th>\n",
       "      <th>pred_polarization</th>\n",
       "      <th>accuracy_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>لطيفة فنانة كبيرة ومحترمة وهي مدرسة متجددة وراقية وجديرة التعليم</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بعد بيتي يا الكدعان ، اوف اوف لو مكسرينها ، ما قصرتو اسباع \\nالعراقي</td>\n",
       "      <td>polarization</td>\n",
       "      <td>polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ما افتهمت الكويت تقول كاظم الساهر انطلق من الكويت واحد يقول انطلق ...</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>من  البيضة مهيوب الحر … \\nمن لعب لاندية عالمية مثل برايتون و مالمو...</td>\n",
       "      <td>polarization</td>\n",
       "      <td>None</td>\n",
       "      <td>✔️ [0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>الاحتيال المالي يتفاقم.. هل تستطيع البنوك الصمود بمفردها؟</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>علم الطاقة \\nالابراج \\nالتاروت\\nالاستبصار\\nحرااااااااااام وشرك ولا...</td>\n",
       "      <td>polarization</td>\n",
       "      <td>polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>فيديو .. وليد الفراج يعلق على خلع حسن معاذ للشورت شاهد على :</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>الجيش الإسرائيلي يصدر بيانا حول جثث الرهائن الأربعة</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>لطيفة اكبر منافقة  تغني لمصر وتتودد للمصريين ايه النفاق ده يا لطيفة</td>\n",
       "      <td>polarization</td>\n",
       "      <td>polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>كل ما اشوفها احسها ذكر متحول استغفر الله العظيم</td>\n",
       "      <td>polarization</td>\n",
       "      <td>polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  sentence  \\\n",
       "0         لطيفة فنانة كبيرة ومحترمة وهي مدرسة متجددة وراقية وجديرة التعليم   \n",
       "1     بعد بيتي يا الكدعان ، اوف اوف لو مكسرينها ، ما قصرتو اسباع \\nالعراقي   \n",
       "2    ما افتهمت الكويت تقول كاظم الساهر انطلق من الكويت واحد يقول انطلق ...   \n",
       "3    من  البيضة مهيوب الحر … \\nمن لعب لاندية عالمية مثل برايتون و مالمو...   \n",
       "4                الاحتيال المالي يتفاقم.. هل تستطيع البنوك الصمود بمفردها؟   \n",
       "..                                                                     ...   \n",
       "197  علم الطاقة \\nالابراج \\nالتاروت\\nالاستبصار\\nحرااااااااااام وشرك ولا...   \n",
       "198         فيديو .. وليد الفراج يعلق على خلع حسن معاذ للشورت شاهد على :     \n",
       "199                    الجيش الإسرائيلي يصدر بيانا حول جثث الرهائن الأربعة   \n",
       "200    لطيفة اكبر منافقة  تغني لمصر وتتودد للمصريين ايه النفاق ده يا لطيفة   \n",
       "201                        كل ما اشوفها احسها ذكر متحول استغفر الله العظيم   \n",
       "\n",
       "    example_polarization pred_polarization accuracy_metric  \n",
       "0        no polarization   no polarization          ✔️ [1]  \n",
       "1           polarization      polarization          ✔️ [1]  \n",
       "2        no polarization   no polarization          ✔️ [1]  \n",
       "3           polarization              None          ✔️ [0]  \n",
       "4        no polarization   no polarization          ✔️ [1]  \n",
       "..                   ...               ...             ...  \n",
       "197         polarization      polarization          ✔️ [1]  \n",
       "198      no polarization   no polarization          ✔️ [1]  \n",
       "199      no polarization   no polarization          ✔️ [1]  \n",
       "200         polarization      polarization          ✔️ [1]  \n",
       "201         polarization      polarization          ✔️ [1]  \n",
       "\n",
       "[202 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy average accuracy metric: 81.68\n"
     ]
    }
   ],
   "source": [
    "evaluate = dspy.Evaluate(\n",
    "    devset=raw_val,\n",
    "    metric=accuracy_metric,\n",
    "    display_progress=True,\n",
    "    display_table=True,   # nice overview\n",
    ")\n",
    "eval_result = evaluate(classify)\n",
    "print(\"DSPy average accuracy metric:\", eval_result.score)  # percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe38184",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics_on_dataset(program, dataset):\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for ex in dataset:\n",
    "        gold = ex.polarization\n",
    "        pred = program(sentence=ex.sentence).polarization\n",
    "        if pred is None:\n",
    "            pred = \"no polarization\"\n",
    "        y_true.append(label2id(gold))\n",
    "        y_pred.append(label2id(pred))\n",
    "\n",
    "    return {\n",
    "        'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='binary'),\n",
    "        'recall': recall_score(y_true, y_pred, average='binary'),\n",
    "        'f1_binary': f1_score(y_true, y_pred, average='binary'),\n",
    "        'f1_micro': f1_score(y_true, y_pred, average='micro'),\n",
    "    }\n",
    "\n",
    "# metrics_val = eval_metrics_on_dataset(classify, raw_val)\n",
    "# print(\"Validation metrics:\", metrics_val)\n",
    "\n",
    "# metrics_test = eval_metrics_on_dataset(classify, raw_test)\n",
    "# print(\"Test metrics:\", metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcd78bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba9213f1f3e4277ba4048375c693d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id  polarization\n",
      "0  arb_67be47e5216d7bee41e17484e619f4e6             1\n",
      "1  arb_272322e5b265e177613d685e5619e402             1\n",
      "2  arb_d1ec38dd0ec5d7a4fe28ef8317fc96c1             0\n",
      "3  arb_fad75310b17c124d98ebc514189ec033             1\n",
      "4  arb_95caf70cec5bf00c94c35cf7af2a0ab5             1\n"
     ]
    }
   ],
   "source": [
    "ids = test_df[\"id\"]\n",
    "def predict_dataset(program, dataset):\n",
    "    rows = []\n",
    "    for i, ex in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        out = program(sentence=ex.sentence)\n",
    "        label = out.polarization\n",
    "        rows.append({\n",
    "            \"id\": test_df.iloc[i][\"id\"],\n",
    "            \"polarization\": label2id(label),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "# after you choose which model to use (classify, optimized_classify, etc.)\n",
    "test_preds_df = predict_dataset(classify, raw_test)\n",
    "\n",
    "print(test_preds_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26672f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_df.to_csv(f\"subtask1_{lang}_dspy_{student_lm_name.split(\"/\")[-1]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c4e788",
   "metadata": {},
   "source": [
    "# Using MIPROv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4f4f8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:24:26 WARNING dspy.teleprompt.mipro_optimizer_v2: 'requires_permission_to_run' is deprecated and will be removed in a future version.\n",
      "2025/12/05 11:24:26 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 10\n",
      "minibatch: True\n",
      "num_fewshot_candidates: 6\n",
      "num_instruct_candidates: 3\n",
      "valset size: 100\n",
      "\n",
      "2025/12/05 11:24:26 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/12/05 11:24:26 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/12/05 11:24:26 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/6\n",
      "Bootstrapping set 2/6\n",
      "Bootstrapping set 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/428 [00:34<48:09,  6.83s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/428 [00:11<1:19:45, 11.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/428 [00:29<52:43,  7.46s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Bootstrapping set 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/428 [00:01<08:40,  1.22s/it]\n",
      "2025/12/05 11:25:43 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/12/05 11:25:43 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:26:02 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=None. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently None)  if the reason for truncation is repetition.\n",
      "2025/12/05 11:26:33 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=3 instructions...\n",
      "\n",
      "2025/12/05 11:27:11 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=None. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 1.0)  if the reason for truncation is repetition.\n",
      "2025/12/05 11:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/12/05 11:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Polarization denotes stereotyping, vilification, dehumanization, deindividuation, or intolerance of other people’s views, beliefs, and identities. In this study, speeches and articles that are shared on social media that incite division, groupism, hatred, conflict, and intolerance are classified as containing polarization.\n",
      "Given this sentence, classify it as containing polarization or not.\n",
      "\n",
      "2025/12/05 11:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Your task is to classify a given sentence as either 'polarization' or 'no polarization'. A sentence is considered polarizing if it uses language to intentionally create, reinforce, or exacerbate divisions between different social or political groups.\n",
      "\n",
      "Identify polarizing language by looking for these key indicators:\n",
      "*   **Loaded or Derogatory Labels:** Using charged terms to describe a group of people (e.g., \"radical left,\" \"extremist right,\" \"apartheid state\").\n",
      "*   **\"Us vs. Them\" Framing:** Pitting one group against another, creating a clear in-group/out-group dynamic.\n",
      "*   **Sweeping Generalizations:** Making overly broad, negative, and unsubstantiated claims about a group.\n",
      "*   **Vilification or Dehumanization:** Portraying a group as evil, morally corrupt, or less than human.\n",
      "\n",
      "A sentence should be classified as 'no polarization' if it is neutral, presents a fact without divisive rhetoric, or poses a genuine question without an accusatory or manipulative tone.\n",
      "\n",
      "Based on these criteria, classify the provided sentence.\n",
      "\n",
      "2025/12/05 11:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are an analyst specializing in political communication and biased language. Your task is to analyze a given sentence and determine if it contains polarizing language. Polarizing language is used to create or highlight sharp divisions between opposing groups, often through the use of accusatory language, \"us vs. them\" framing, derogatory labels, or rhetoric intended to foster animosity and conflict. Look for signs of:\n",
      "\n",
      "*   **Accusatory or vilifying language:** Referring to an entire group with terms like \"evil,\" \"radical,\" or other derogatory labels.\n",
      "*   **\"Us vs. them\" framing:** Creating a stark distinction between in-groups and out-groups.\n",
      "*   **Stereotyping and generalization:** Making broad, negative claims about an entire group of people.\n",
      "*   **Dehumanization:** Portraying a group as less than human.\n",
      "\n",
      "Review the sentence below and classify it. Respond with only the label 'polarization' or 'no polarization'. Do not provide any explanation.\n",
      "\n",
      "Sentence: {sentence}\n",
      "Polarization:\n",
      "\n",
      "2025/12/05 11:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/12/05 11:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/12/05 11:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/12/05 11:28:53 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 13 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 84.00 / 100 (84.0%): 100%|██████████| 100/100 [02:34<00:00,  1.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:31:28 INFO dspy.evaluate.evaluate: Average Metric: 84 / 100 (84.0%)\n",
      "2025/12/05 11:31:28 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 84.0\n",
      "\n",
      "/Users/0ssamaak0/miniconda3/envs/nlp/lib/python3.13/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/12/05 11:31:28 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.00 / 35 (85.7%): 100%|██████████| 35/35 [00:30<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:31:59 INFO dspy.evaluate.evaluate: Average Metric: 30 / 35 (85.7%)\n",
      "2025/12/05 11:31:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 85.71 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/12/05 11:31:59 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [85.71]\n",
      "2025/12/05 11:31:59 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0]\n",
      "2025/12/05 11:31:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 84.0\n",
      "2025/12/05 11:31:59 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/05 11:31:59 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.00 / 35 (80.0%): 100%|██████████| 35/35 [00:44<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:32:43 INFO dspy.evaluate.evaluate: Average Metric: 28 / 35 (80.0%)\n",
      "2025/12/05 11:32:43 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 80.0 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/12/05 11:32:43 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [85.71, 80.0]\n",
      "2025/12/05 11:32:43 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0]\n",
      "2025/12/05 11:32:43 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 84.0\n",
      "2025/12/05 11:32:43 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/05 11:32:43 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.00 / 35 (82.9%): 100%|██████████| 35/35 [00:28<00:00,  1.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:33:11 INFO dspy.evaluate.evaluate: Average Metric: 29 / 35 (82.9%)\n",
      "2025/12/05 11:33:11 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 82.86 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/12/05 11:33:11 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [85.71, 80.0, 82.86]\n",
      "2025/12/05 11:33:11 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0]\n",
      "2025/12/05 11:33:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 84.0\n",
      "2025/12/05 11:33:11 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/05 11:33:11 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 32.00 / 35 (91.4%): 100%|██████████| 35/35 [00:30<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:33:42 INFO dspy.evaluate.evaluate: Average Metric: 32 / 35 (91.4%)\n",
      "2025/12/05 11:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 91.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/12/05 11:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [85.71, 80.0, 82.86, 91.43]\n",
      "2025/12/05 11:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0]\n",
      "2025/12/05 11:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 84.0\n",
      "2025/12/05 11:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/05 11:33:42 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.00 / 35 (85.7%): 100%|██████████| 35/35 [00:28<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:34:10 INFO dspy.evaluate.evaluate: Average Metric: 30 / 35 (85.7%)\n",
      "2025/12/05 11:34:10 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 85.71 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/12/05 11:34:10 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [85.71, 80.0, 82.86, 91.43, 85.71]\n",
      "2025/12/05 11:34:10 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0]\n",
      "2025/12/05 11:34:10 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 84.0\n",
      "2025/12/05 11:34:10 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/05 11:34:10 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 13 - Full Evaluation =====\n",
      "2025/12/05 11:34:10 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 91.43) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 86.00 / 100 (86.0%): 100%|██████████| 100/100 [01:00<00:00,  1.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:35:11 INFO dspy.evaluate.evaluate: Average Metric: 86 / 100 (86.0%)\n",
      "2025/12/05 11:35:11 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 86.0\n",
      "2025/12/05 11:35:11 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0, 86.0]\n",
      "2025/12/05 11:35:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
      "2025/12/05 11:35:11 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/12/05 11:35:11 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/12/05 11:35:11 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 8 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.00 / 35 (82.9%): 100%|██████████| 35/35 [00:30<00:00,  1.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:35:41 INFO dspy.evaluate.evaluate: Average Metric: 29 / 35 (82.9%)\n",
      "2025/12/05 11:35:41 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 82.86 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/12/05 11:35:41 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [85.71, 80.0, 82.86, 91.43, 85.71, 82.86]\n",
      "2025/12/05 11:35:41 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0, 86.0]\n",
      "2025/12/05 11:35:41 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
      "2025/12/05 11:35:41 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/05 11:35:41 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 9 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 30.00 / 35 (85.7%): 100%|██████████| 35/35 [00:23<00:00,  1.52it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:36:04 INFO dspy.evaluate.evaluate: Average Metric: 30 / 35 (85.7%)\n",
      "2025/12/05 11:36:04 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 85.71 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/12/05 11:36:04 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [85.71, 80.0, 82.86, 91.43, 85.71, 82.86, 85.71]\n",
      "2025/12/05 11:36:04 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0, 86.0]\n",
      "2025/12/05 11:36:04 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
      "2025/12/05 11:36:04 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/05 11:36:04 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 10 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.00 / 35 (74.3%): 100%|██████████| 35/35 [00:25<00:00,  1.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:36:30 INFO dspy.evaluate.evaluate: Average Metric: 26 / 35 (74.3%)\n",
      "2025/12/05 11:36:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.29 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/12/05 11:36:30 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [85.71, 80.0, 82.86, 91.43, 85.71, 82.86, 85.71, 74.29]\n",
      "2025/12/05 11:36:30 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0, 86.0]\n",
      "2025/12/05 11:36:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
      "2025/12/05 11:36:30 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/12/05 11:36:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 11 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.00 / 35 (82.9%): 100%|██████████| 35/35 [00:29<00:00,  1.19it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:36:59 INFO dspy.evaluate.evaluate: Average Metric: 29 / 35 (82.9%)\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 82.86 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [85.71, 80.0, 82.86, 91.43, 85.71, 82.86, 85.71, 74.29, 82.86]\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0, 86.0]\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 12 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 29.00 / 35 (82.9%): 100%|██████████| 35/35 [00:00<00:00, 3912.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:36:59 INFO dspy.evaluate.evaluate: Average Metric: 29 / 35 (82.9%)\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 82.86 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [85.71, 80.0, 82.86, 91.43, 85.71, 82.86, 85.71, 74.29, 82.86, 82.86]\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0, 86.0]\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 13 - Full Evaluation =====\n",
      "2025/12/05 11:36:59 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 85.71) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 83.00 / 100 (83.0%): 100%|██████████| 100/100 [01:02<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/05 11:38:02 INFO dspy.evaluate.evaluate: Average Metric: 83 / 100 (83.0%)\n",
      "2025/12/05 11:38:02 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [84.0, 86.0, 83.0]\n",
      "2025/12/05 11:38:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 86.0\n",
      "2025/12/05 11:38:02 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/12/05 11:38:02 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/12/05 11:38:02 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 86.0!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'eval_metrics_on_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     10\u001b[39m optimized_prog = mipro.compile(\n\u001b[32m     11\u001b[39m     student=dspy.Predict(Polarization),\n\u001b[32m     12\u001b[39m     trainset=raw_train,\n\u001b[32m     13\u001b[39m     valset=raw_val,\n\u001b[32m     14\u001b[39m     requires_permission_to_run=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# After optimization, compute your full metrics dict\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m metrics_val_opt = \u001b[43meval_metrics_on_dataset\u001b[49m(optimized_prog, raw_val)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mOptimized validation metrics:\u001b[39m\u001b[33m\"\u001b[39m, metrics_val_opt)\n",
      "\u001b[31mNameError\u001b[39m: name 'eval_metrics_on_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "mipro = MIPROv2(\n",
    "    metric=accuracy_metric,\n",
    "    auto=\"light\",\n",
    "    teacher_settings=dict(lm=teacher_lm),\n",
    "    prompt_model=student_lm\n",
    ")\n",
    "\n",
    "optimized_prog = mipro.compile(\n",
    "    student=dspy.Predict(Polarization),\n",
    "    trainset=raw_train,\n",
    "    valset=raw_val,\n",
    "    requires_permission_to_run=False,\n",
    ")\n",
    "\n",
    "# After optimization, compute your full metrics dict\n",
    "metrics_val_opt = eval_metrics_on_dataset(optimized_prog, raw_val)\n",
    "\n",
    "print(\"Optimized validation metrics:\", metrics_val_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26a3e2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-12-05T11:37:56.280923]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `sentence` (str):\n",
      "Your output fields are:\n",
      "1. `polarization` (Literal['polarization', 'no polarization']): Return \"polarization\" or \"no polarization\".\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "{sentence}\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "{polarization}        # note: the value you produce must exactly match (no extra characters) one of: polarization; no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Your task is to classify a given sentence as either 'polarization' or 'no polarization'. A sentence is considered polarizing if it uses language to intentionally create, reinforce, or exacerbate divisions between different social or political groups.\n",
      "        \n",
      "        Identify polarizing language by looking for these key indicators:\n",
      "        *   **Loaded or Derogatory Labels:** Using charged terms to describe a group of people (e.g., \"radical left,\" \"extremist right,\" \"apartheid state\").\n",
      "        *   **\"Us vs. Them\" Framing:** Pitting one group against another, creating a clear in-group/out-group dynamic.\n",
      "        *   **Sweeping Generalizations:** Making overly broad, negative, and unsubstantiated claims about a group.\n",
      "        *   **Vilification or Dehumanization:** Portraying a group as evil, morally corrupt, or less than human.\n",
      "        \n",
      "        A sentence should be classified as 'no polarization' if it is neutral, presents a fact without divisive rhetoric, or poses a genuine question without an accusatory or manipulative tone.\n",
      "        \n",
      "        Based on these criteria, classify the provided sentence.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Refugees ofc being an exception here.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Ukraine war Russia Sanctions Taiwan War China Sanctions New World Reserve Currency\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Mike Pence has some tough words for GOP\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Crean fake news sobre muerte de Jennifer\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Were talking about asylum seekers here Einstein\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## polarization ## ]]` (must be formatted as a valid Python Literal['polarization', 'no polarization']), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## polarization ## ]]\n",
      "polarization\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-12-05T11:37:59.789277]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `sentence` (str):\n",
      "Your output fields are:\n",
      "1. `polarization` (Literal['polarization', 'no polarization']): Return \"polarization\" or \"no polarization\".\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "{sentence}\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "{polarization}        # note: the value you produce must exactly match (no extra characters) one of: polarization; no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Your task is to classify a given sentence as either 'polarization' or 'no polarization'. A sentence is considered polarizing if it uses language to intentionally create, reinforce, or exacerbate divisions between different social or political groups.\n",
      "        \n",
      "        Identify polarizing language by looking for these key indicators:\n",
      "        *   **Loaded or Derogatory Labels:** Using charged terms to describe a group of people (e.g., \"radical left,\" \"extremist right,\" \"apartheid state\").\n",
      "        *   **\"Us vs. Them\" Framing:** Pitting one group against another, creating a clear in-group/out-group dynamic.\n",
      "        *   **Sweeping Generalizations:** Making overly broad, negative, and unsubstantiated claims about a group.\n",
      "        *   **Vilification or Dehumanization:** Portraying a group as evil, morally corrupt, or less than human.\n",
      "        \n",
      "        A sentence should be classified as 'no polarization' if it is neutral, presents a fact without divisive rhetoric, or poses a genuine question without an accusatory or manipulative tone.\n",
      "        \n",
      "        Based on these criteria, classify the provided sentence.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Refugees ofc being an exception here.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Ukraine war Russia Sanctions Taiwan War China Sanctions New World Reserve Currency\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Mike Pence has some tough words for GOP\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Crean fake news sobre muerte de Jennifer\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Jews need atheistic multiculturalism in order to hide.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## polarization ## ]]` (must be formatted as a valid Python Literal['polarization', 'no polarization']), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## polarization ## ]]\n",
      "polarization\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-12-05T11:38:02.438598]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `sentence` (str):\n",
      "Your output fields are:\n",
      "1. `polarization` (Literal['polarization', 'no polarization']): Return \"polarization\" or \"no polarization\".\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "{sentence}\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "{polarization}        # note: the value you produce must exactly match (no extra characters) one of: polarization; no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Your task is to classify a given sentence as either 'polarization' or 'no polarization'. A sentence is considered polarizing if it uses language to intentionally create, reinforce, or exacerbate divisions between different social or political groups.\n",
      "        \n",
      "        Identify polarizing language by looking for these key indicators:\n",
      "        *   **Loaded or Derogatory Labels:** Using charged terms to describe a group of people (e.g., \"radical left,\" \"extremist right,\" \"apartheid state\").\n",
      "        *   **\"Us vs. Them\" Framing:** Pitting one group against another, creating a clear in-group/out-group dynamic.\n",
      "        *   **Sweeping Generalizations:** Making overly broad, negative, and unsubstantiated claims about a group.\n",
      "        *   **Vilification or Dehumanization:** Portraying a group as evil, morally corrupt, or less than human.\n",
      "        \n",
      "        A sentence should be classified as 'no polarization' if it is neutral, presents a fact without divisive rhetoric, or poses a genuine question without an accusatory or manipulative tone.\n",
      "        \n",
      "        Based on these criteria, classify the provided sentence.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Refugees ofc being an exception here.\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Ukraine war Russia Sanctions Taiwan War China Sanctions New World Reserve Currency\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Mike Pence has some tough words for GOP\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Crean fake news sobre muerte de Jennifer\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## sentence ## ]]\n",
      "Evanston equity panel pulls Gaza ceasefire resolutionThe Daily Northwestern\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## polarization ## ]]` (must be formatted as a valid Python Literal['polarization', 'no polarization']), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## polarization ## ]]\n",
      "no polarization\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dec8970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95965cf5b7fd4bc2843bceb08913d8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id  polarization\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58             0\n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb             0\n",
      "2  eng_95770ff547ea5e48b0be00f385986483             0\n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf             1\n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20             0\n"
     ]
    }
   ],
   "source": [
    "ids = test_df[\"id\"]\n",
    "def predict_dataset(program, dataset):\n",
    "    rows = []\n",
    "    for i, ex in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        out = program(sentence=ex.sentence)\n",
    "        label = out.polarization\n",
    "        rows.append({\n",
    "            \"id\": test_df.iloc[i][\"id\"],\n",
    "            \"polarization\": label2id(label),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# after you choose which model to use (classify, optimized_classify, etc.)\n",
    "test_preds_df = predict_dataset(optimized_prog, raw_test)\n",
    "\n",
    "print(test_preds_df.head())\n",
    "test_preds_df.to_csv(f\"subtask1_{lang}_dspy_miprov2_student{student_lm_name.split('/')[-1]}_teacher{teacher_lm_name.split('/')[-1]}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ede3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save optimize program for future use\n",
    "optimized_prog.save(f\"optimized_subtask1_{lang}_dspy_miprov2_student{student_lm_name.split('/')[-1]}_teacher{teacher_lm_name.split('/')[-1]}.json\")\n",
    "\n",
    "# load the optimized program\n",
    "save_path = f\"optimized_subtask1_{lang}_dspy_miprov2_student{student_lm_name.split('/')[-1]}_teacher{teacher_lm_name.split('/')[-1]}.json\"\n",
    "optimized_prog_loaded = dspy.Predict(Polarization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
