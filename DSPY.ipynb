{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81beb43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "student_lm_name = \"fireworks_ai/accounts/fireworks/models/gpt-oss-20b\"\n",
    "teacher_lm_name = \"openai/gpt-5.1-2025-11-13\"\n",
    "\n",
    "if \"ollama_chat\" in student_lm_name:\n",
    "    student_lm = dspy.LM(student_lm_name, api_base='http://localhost:11434', api_key='')\n",
    "else:\n",
    "    student_lm = dspy.LM(student_lm_name)\n",
    "teacher_lm = dspy.LM(teacher_lm_name)\n",
    "\n",
    "dspy.configure(lm=student_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef6c9db",
   "metadata": {},
   "source": [
    "# Prepare DSPY Dataset (Subtask 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "390a2d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_id = \"DSP0002S\"\n",
    "# Train val test split\n",
    "lang = \"eng\"\n",
    "# Load the training and validation data for subtask 1\n",
    "train_df = pd.read_csv(f'./dev_phase/subtask1/train/{lang}.csv')\n",
    "test_df = pd.read_csv(f'./dev_phase/subtask1/dev/{lang}.csv')\n",
    "# Split train into train and validation sets\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36ccdaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the polarization numeric label to a string\n",
    "POLARIZATION_MAP = {1: \"polarization\", 0: \"no polarization\"}\n",
    "\n",
    "def make_dspy_examples(df, include_label: bool = True):\n",
    "    examples = []\n",
    "    for _, row in df.iterrows():\n",
    "        kwargs = dict(\n",
    "            sentence=row[\"text\"],\n",
    "        )\n",
    "        if include_label and \"polarization\" in row:\n",
    "            kwargs[\"polarization\"] = POLARIZATION_MAP[row[\"polarization\"]]\n",
    "        example = dspy.Example(**kwargs).with_inputs(\"sentence\")\n",
    "        examples.append(example)\n",
    "    return examples\n",
    "\n",
    "# Create DSPY datasets\n",
    "raw_train = make_dspy_examples(train_df, include_label=True)\n",
    "raw_val = make_dspy_examples(val_df, include_label=True)\n",
    "raw_test = make_dspy_examples(test_df, include_label=False)\n",
    "\n",
    "\n",
    "# # For now take only 10% of each \n",
    "raw_train = raw_train[:int(len(raw_train) * 0.2)]\n",
    "raw_val = raw_val[:int(len(raw_val) * 0.3)]\n",
    "raw_test = raw_test[:int(len(raw_test) * 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6ebcb",
   "metadata": {},
   "source": [
    "# Define Signature (Subtask 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "012b53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Polarization(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Polarization denotes stereotyping, vilification, dehumanization, deindividuation, or intolerance of other people’s views, beliefs, and identities. In this study, speeches and articles that are shared on social media that incite division, groupism, hatred, conflict, and intolerance are classified as containing polarization.\n",
    "    Given this sentence, classify it as containing polarization or not.\"\"\"\n",
    "\n",
    "    sentence: str = dspy.InputField()\n",
    "    polarization: Literal[\"polarization\", \"no polarization\"] = dspy.OutputField(\n",
    "        desc='Return \"polarization\" or \"no polarization\".',\n",
    "        choices=[\"polarization\", \"no polarization\"],\n",
    "    )\n",
    "classify = dspy.Predict(Polarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9272d5",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a87480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "POLARIZATION_MAP = {1: \"polarization\", 0: \"no polarization\"}\n",
    "\n",
    "def label2id(label: str) -> int:\n",
    "    return {v: k for k, v in POLARIZATION_MAP.items()}[label]\n",
    "\n",
    "def id2label(i: int) -> str:\n",
    "    return POLARIZATION_MAP[i]\n",
    "\n",
    "def accuracy_metric(example, pred, trace=None):\n",
    "    gold = example.polarization          # from your Examples\n",
    "    guess = pred.polarization         # from Signature output\n",
    "    return int(gold == guess)         # 1 = correct, 0 = incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7c6ed1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 41.00 / 50 (82.0%):  25%|██▌       | 49/193 [00:00<00:00, 215.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 164.00 / 193 (85.0%): 100%|██████████| 193/193 [00:01<00:00, 171.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:18 INFO dspy.evaluate.evaluate: Average Metric: 164 / 193 (85.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>example_polarization</th>\n",
       "      <th>pred_polarization</th>\n",
       "      <th>accuracy_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump relies on First Amendment</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House GOP in no rush to give more Ukraine aid after 6</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Israeli adviser to meet with US officials on war</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so russia commits war crimes, how does that justify ukraine also c...</td>\n",
       "      <td>polarization</td>\n",
       "      <td>polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cant wait to watch this episode of Border Security</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Wow, thats awesome. It reminds me of the crazy things the Tamir in...</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>How long will it be until human rights are stripped away? oligarch...</td>\n",
       "      <td>polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>There are no open borders here in Texas.</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Ottawa to unveil economic update detailing deficit, new border sec...</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>The White House or the asylum seekers?</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>polarization</td>\n",
       "      <td>✔️ [0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  sentence  \\\n",
       "0                                   Donald Trump relies on First Amendment   \n",
       "1                    House GOP in no rush to give more Ukraine aid after 6   \n",
       "2                         Israeli adviser to meet with US officials on war   \n",
       "3    so russia commits war crimes, how does that justify ukraine also c...   \n",
       "4                       Cant wait to watch this episode of Border Security   \n",
       "..                                                                     ...   \n",
       "188  Wow, thats awesome. It reminds me of the crazy things the Tamir in...   \n",
       "189  How long will it be until human rights are stripped away? oligarch...   \n",
       "190                               There are no open borders here in Texas.   \n",
       "191  Ottawa to unveil economic update detailing deficit, new border sec...   \n",
       "192                                 The White House or the asylum seekers?   \n",
       "\n",
       "    example_polarization pred_polarization accuracy_metric  \n",
       "0        no polarization   no polarization          ✔️ [1]  \n",
       "1        no polarization   no polarization          ✔️ [1]  \n",
       "2        no polarization   no polarization          ✔️ [1]  \n",
       "3           polarization      polarization          ✔️ [1]  \n",
       "4        no polarization   no polarization          ✔️ [1]  \n",
       "..                   ...               ...             ...  \n",
       "188      no polarization   no polarization          ✔️ [1]  \n",
       "189         polarization   no polarization          ✔️ [0]  \n",
       "190      no polarization   no polarization          ✔️ [1]  \n",
       "191      no polarization   no polarization          ✔️ [1]  \n",
       "192      no polarization      polarization          ✔️ [0]  \n",
       "\n",
       "[193 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy average accuracy metric: 84.97\n"
     ]
    }
   ],
   "source": [
    "evaluate = dspy.Evaluate(\n",
    "    devset=raw_val,\n",
    "    metric=accuracy_metric,\n",
    "    display_progress=True,\n",
    "    display_table=True,   # nice overview\n",
    ")\n",
    "eval_result = evaluate(classify)\n",
    "print(\"DSPy average accuracy metric:\", eval_result.score)  # percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fe38184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'f1_macro': 0.8166420966420966, 'accuracy': 0.8497409326424871, 'precision': 0.7192982456140351, 'recall': 0.7592592592592593, 'f1_binary': 0.7387387387387387, 'f1_micro': 0.8497409326424871}\n"
     ]
    }
   ],
   "source": [
    "def eval_metrics_on_dataset(program, dataset):\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for ex in dataset:\n",
    "        gold = ex.polarization\n",
    "        pred = program(sentence=ex.sentence).polarization\n",
    "        if pred is None:\n",
    "            pred = \"no polarization\"\n",
    "        y_true.append(label2id(gold))\n",
    "        y_pred.append(label2id(pred))\n",
    "\n",
    "    return {\n",
    "        'f1_macro': f1_score(y_true, y_pred, average='macro'),\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred, average='binary'),\n",
    "        'recall': recall_score(y_true, y_pred, average='binary'),\n",
    "        'f1_binary': f1_score(y_true, y_pred, average='binary'),\n",
    "        'f1_micro': f1_score(y_true, y_pred, average='micro'),\n",
    "    }\n",
    "\n",
    "metrics_val = eval_metrics_on_dataset(classify, raw_val)\n",
    "print(\"Validation metrics:\", metrics_val)\n",
    "\n",
    "# metrics_test = eval_metrics_on_dataset(classify, raw_test)\n",
    "# print(\"Test metrics:\", metrics_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cfe4025",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_f1_macro = metrics_val[\"f1_macro\"]\n",
    "import json\n",
    "\n",
    "# Build current language entry for subtask_1\n",
    "lang_entry = {\n",
    "    \"eval_results\": {\n",
    "        \"eval_f1_macro\": student_f1_macro\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load previous trials from logs.json if it exists, else create new list\n",
    "log_path = \"logs.json\"\n",
    "try:\n",
    "    with open(log_path, \"r\") as f:\n",
    "        trials = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    trials = []\n",
    "\n",
    "# Look for existing trial by trial_id\n",
    "found = False\n",
    "for trial in trials:\n",
    "    if trial.get(\"trial_id\") == trial_id:\n",
    "        # Insert or update lang in subtask_1\n",
    "        if \"subtask_1\" not in trial:\n",
    "            trial[\"subtask_1\"] = {\"score\": None}\n",
    "        if \"score\" not in trial[\"subtask_1\"]:\n",
    "            trial[\"subtask_1\"][\"score\"] = None\n",
    "        trial[\"subtask_1\"][lang] = lang_entry\n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    # Build new trial dict if trial_id not found\n",
    "    current_trial = {\n",
    "        \"trial_id\": trial_id,\n",
    "        \"metadata\": {\n",
    "            \"approach\": \"dspy basic\",\n",
    "            \"model\": student_lm_name\n",
    "        },\n",
    "        \"subtask_1\": {\n",
    "            \"score\": None,\n",
    "            lang: lang_entry\n",
    "        }\n",
    "    }\n",
    "    trials.append(current_trial)\n",
    "\n",
    "# Save back to logs.json\n",
    "with open(log_path, \"w\") as f:\n",
    "    json.dump(trials, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adcd78bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32b9fd46a8c46b2896c9ccaa7992f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id  polarization\n",
      "0  eng_f66ca14d60851371f9720aaf4ccd9b58             0\n",
      "1  eng_3a489aa7fed9726aa8d3d4fe74c57efb             0\n",
      "2  eng_95770ff547ea5e48b0be00f385986483             0\n",
      "3  eng_2048ae6f9aa261c48e6d777bcc5b38bf             0\n",
      "4  eng_07781aa88e61e7c0a996abd1e5ea3a20             0\n"
     ]
    }
   ],
   "source": [
    "ids = test_df[\"id\"]\n",
    "def predict_dataset(program, dataset):\n",
    "    rows = []\n",
    "    for i, ex in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        out = program(sentence=ex.sentence)\n",
    "        label = out.polarization\n",
    "        rows.append({\n",
    "            \"id\": test_df.iloc[i][\"id\"],\n",
    "            \"polarization\": label2id(label),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "# after you choose which model to use (classify, optimized_classify, etc.)\n",
    "test_preds_df = predict_dataset(classify, raw_test)\n",
    "\n",
    "print(test_preds_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51c330cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in results create dir with trial_id and create subtask_1 inside it, then save the csv as \"pred_lang.csv\" inside it\n",
    "import os\n",
    "os.makedirs(f\"results/{trial_id}/subtask_1\", exist_ok=True)\n",
    "test_preds_df.to_csv(f\"results/{trial_id}/subtask_1/pred_{lang}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c4e788",
   "metadata": {},
   "source": [
    "# Using MIPROv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4f4f8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:29 WARNING dspy.teleprompt.mipro_optimizer_v2: 'requires_permission_to_run' is deprecated and will be removed in a future version.\n",
      "2025/12/07 14:38:29 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING LIGHT AUTO RUN SETTINGS:\n",
      "num_trials: 10\n",
      "minibatch: True\n",
      "num_fewshot_candidates: 6\n",
      "num_instruct_candidates: 3\n",
      "valset size: 100\n",
      "\n",
      "2025/12/07 14:38:29 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/12/07 14:38:29 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/12/07 14:38:29 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=6 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/6\n",
      "Bootstrapping set 2/6\n",
      "Bootstrapping set 3/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/515 [00:00<00:14, 34.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 4/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/515 [00:00<00:13, 37.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 5/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/515 [00:00<00:15, 33.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 6/6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/515 [00:00<00:12, 41.29it/s]\n",
      "2025/12/07 14:38:29 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/12/07 14:38:29 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:29 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=3 instructions...\n",
      "\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Polarization denotes stereotyping, vilification, dehumanization, deindividuation, or intolerance of other people’s views, beliefs, and identities. In this study, speeches and articles that are shared on social media that incite division, groupism, hatred, conflict, and intolerance are classified as containing polarization.\n",
      "Given this sentence, classify it as containing polarization or not.\n",
      "\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Classify the following sentence as containing polarization or not.  \n",
      "Output exactly one of the two labels:  \n",
      "\n",
      "* **polarity** – if the sentence includes political/ideological slurs, dehumanizing or vilifying language, direct second‑person address, profanity, overt partisan framing, or has a strong negative sentiment (typically < –0.3).  \n",
      "* **no_polarity** – if the sentence is longer, fact‑laden, neutral or mildly positive, and lacks the linguistic cues above.\n",
      "\n",
      "Return only the label, no other text.  \n",
      "\n",
      "Example format:  \n",
      "\n",
      "**Input:** Lazy woke excuse to justify sjw practices  \n",
      "**Output:** polarization\n",
      "\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You will be given a single sentence. Classify whether it expresses polarized language based on the following criteria: presence of direct second‑person address (e.g., \"you\"), profanity or ideological slurs, aggressive or hostile tone, strong negative sentiment, or explicit political/ideological framing. Return a **JSON** object with the single field `label` whose value is either \"polarization\" or \"no polarization\". Do not output any other text or explanation.\n",
      "\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 13 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 80.00 / 100 (80.0%): 100%|██████████| 100/100 [00:00<00:00, 1406.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:30 INFO dspy.evaluate.evaluate: Average Metric: 80 / 100 (80.0%)\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 80.0\n",
      "\n",
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 28.00 / 35 (80.0%): 100%|██████████| 35/35 [00:00<00:00, 229.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:30 INFO dspy.evaluate.evaluate: Average Metric: 28 / 35 (80.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 80.0 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.0]\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0]\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 22.00 / 35 (62.9%): 100%|██████████| 35/35 [00:00<00:00, 222.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:30 INFO dspy.evaluate.evaluate: Average Metric: 22 / 35 (62.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.86 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.0, 62.86]\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0]\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 35 (71.4%): 100%|██████████| 35/35 [00:00<00:00, 223.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:30 INFO dspy.evaluate.evaluate: Average Metric: 25 / 35 (71.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 71.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/12/07 14:38:30 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.0, 62.86, 71.43]\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0]\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 25.00 / 35 (71.4%): 100%|██████████| 35/35 [00:00<00:00, 220.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:31 INFO dspy.evaluate.evaluate: Average Metric: 25 / 35 (71.4%)\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 71.43 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.0, 62.86, 71.43, 71.43]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0]\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 28.00 / 35 (80.0%): 100%|██████████| 35/35 [00:00<00:00, 217.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:31 INFO dspy.evaluate.evaluate: Average Metric: 28 / 35 (80.0%)\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 80.0 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 5'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.0, 62.86, 71.43, 71.43, 80.0]\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0]\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 13 - Full Evaluation =====\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 80.0) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 79.00 / 100 (79.0%): 100%|██████████| 100/100 [00:00<00:00, 238.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:31 INFO dspy.evaluate.evaluate: Average Metric: 79 / 100 (79.0%)\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0, 79.0]\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/12/07 14:38:31 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 8 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 20.00 / 35 (57.1%): 100%|██████████| 35/35 [00:00<00:00, 234.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:32 INFO dspy.evaluate.evaluate: Average Metric: 20 / 35 (57.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 57.14 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.0, 62.86, 71.43, 71.43, 80.0, 57.14]\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0, 79.0]\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 9 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.00 / 35 (60.0%): 100%|██████████| 35/35 [00:00<00:00, 209.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:32 INFO dspy.evaluate.evaluate: Average Metric: 21 / 35 (60.0%)\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 60.0 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.0, 62.86, 71.43, 71.43, 80.0, 57.14, 60.0]\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0, 79.0]\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 10 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 24.00 / 35 (68.6%): 100%|██████████| 35/35 [00:00<00:00, 204.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:32 INFO dspy.evaluate.evaluate: Average Metric: 24 / 35 (68.6%)\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 68.57 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.0, 62.86, 71.43, 71.43, 80.0, 57.14, 60.0, 68.57]\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0, 79.0]\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 11 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 26.00 / 35 (74.3%): 100%|██████████| 35/35 [00:00<00:00, 1126.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:32 INFO dspy.evaluate.evaluate: Average Metric: 26 / 35 (74.3%)\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 74.29 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 0'].\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.0, 62.86, 71.43, 71.43, 80.0, 57.14, 60.0, 68.57, 74.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0, 79.0]\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 12 / 13 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 27.00 / 35 (77.1%): 100%|██████████| 35/35 [00:00<00:00, 1270.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:32 INFO dspy.evaluate.evaluate: Average Metric: 27 / 35 (77.1%)\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 77.14 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [80.0, 62.86, 71.43, 71.43, 80.0, 57.14, 60.0, 68.57, 74.29, 77.14]\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0, 79.0]\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 13 - Full Evaluation =====\n",
      "2025/12/07 14:38:32 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 80.0) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 80.00 / 100 (80.0%): 100%|██████████| 100/100 [00:00<00:00, 253.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:33 INFO dspy.evaluate.evaluate: Average Metric: 80 / 100 (80.0%)\n",
      "2025/12/07 14:38:33 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [80.0, 79.0, 80.0]\n",
      "2025/12/07 14:38:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 80.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:33 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/12/07 14:38:33 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/12/07 14:38:33 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 80.0!\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import MIPROv2\n",
    "\n",
    "mipro = MIPROv2(\n",
    "    metric=accuracy_metric,\n",
    "    auto=\"light\",\n",
    "    teacher_settings=dict(lm=teacher_lm),\n",
    "    prompt_model=student_lm,\n",
    ")\n",
    "\n",
    "optimized_prog = mipro.compile(\n",
    "    student=dspy.Predict(Polarization),\n",
    "    trainset=raw_train,\n",
    "    valset=raw_val,\n",
    "    requires_permission_to_run=False,\n",
    ")\n",
    "\n",
    "# # After optimization, compute your full metrics dict\n",
    "# metrics_val_opt = eval_metrics_on_dataset(optimized_prog, raw_val)\n",
    "\n",
    "# print(\"Optimized validation metrics:\", metrics_val_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5280ad23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 3.00 / 5 (60.0%):   2%|▏         | 4/193 [00:00<00:01, 103.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 164.00 / 193 (85.0%): 100%|██████████| 193/193 [00:00<00:00, 854.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/07 14:38:33 INFO dspy.evaluate.evaluate: Average Metric: 164 / 193 (85.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>example_polarization</th>\n",
       "      <th>pred_polarization</th>\n",
       "      <th>accuracy_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump relies on First Amendment</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>House GOP in no rush to give more Ukraine aid after 6</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Israeli adviser to meet with US officials on war</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>so russia commits war crimes, how does that justify ukraine also c...</td>\n",
       "      <td>polarization</td>\n",
       "      <td>polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cant wait to watch this episode of Border Security</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Wow, thats awesome. It reminds me of the crazy things the Tamir in...</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>How long will it be until human rights are stripped away? oligarch...</td>\n",
       "      <td>polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>There are no open borders here in Texas.</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Ottawa to unveil economic update detailing deficit, new border sec...</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>✔️ [1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>The White House or the asylum seekers?</td>\n",
       "      <td>no polarization</td>\n",
       "      <td>polarization</td>\n",
       "      <td>✔️ [0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  sentence  \\\n",
       "0                                   Donald Trump relies on First Amendment   \n",
       "1                    House GOP in no rush to give more Ukraine aid after 6   \n",
       "2                         Israeli adviser to meet with US officials on war   \n",
       "3    so russia commits war crimes, how does that justify ukraine also c...   \n",
       "4                       Cant wait to watch this episode of Border Security   \n",
       "..                                                                     ...   \n",
       "188  Wow, thats awesome. It reminds me of the crazy things the Tamir in...   \n",
       "189  How long will it be until human rights are stripped away? oligarch...   \n",
       "190                               There are no open borders here in Texas.   \n",
       "191  Ottawa to unveil economic update detailing deficit, new border sec...   \n",
       "192                                 The White House or the asylum seekers?   \n",
       "\n",
       "    example_polarization pred_polarization accuracy_metric  \n",
       "0        no polarization   no polarization          ✔️ [1]  \n",
       "1        no polarization   no polarization          ✔️ [1]  \n",
       "2        no polarization   no polarization          ✔️ [1]  \n",
       "3           polarization      polarization          ✔️ [1]  \n",
       "4        no polarization   no polarization          ✔️ [1]  \n",
       "..                   ...               ...             ...  \n",
       "188      no polarization   no polarization          ✔️ [1]  \n",
       "189         polarization   no polarization          ✔️ [0]  \n",
       "190      no polarization   no polarization          ✔️ [1]  \n",
       "191      no polarization   no polarization          ✔️ [1]  \n",
       "192      no polarization      polarization          ✔️ [0]  \n",
       "\n",
       "[193 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSPy average accuracy metric: 84.97\n"
     ]
    }
   ],
   "source": [
    "evaluate = dspy.Evaluate(\n",
    "    devset=raw_val,\n",
    "    metric=accuracy_metric,\n",
    "    display_progress=True,\n",
    "    display_table=True,   # nice overview\n",
    ")\n",
    "eval_result = evaluate(optimized_prog)\n",
    "print(\"DSPy average accuracy metric:\", eval_result.score)  # percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "796ef6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'f1_macro': 0.8166420966420966, 'accuracy': 0.8497409326424871, 'precision': 0.7192982456140351, 'recall': 0.7592592592592593, 'f1_binary': 0.7387387387387387, 'f1_micro': 0.8497409326424871}\n"
     ]
    }
   ],
   "source": [
    "metrics_val = eval_metrics_on_dataset(optimized_prog, raw_val)\n",
    "print(\"Validation metrics:\", metrics_val)\n",
    "mipro_f1_macro = metrics_val[\"f1_macro\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5dec8970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1691084731d04133a6ac95330a693b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ids = test_df[\"id\"]\n",
    "def predict_dataset(program, dataset):\n",
    "    rows = []\n",
    "    for i, ex in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "        out = program(sentence=ex.sentence)\n",
    "        label = out.polarization\n",
    "        if label is None:\n",
    "            label = \"no polarization\"\n",
    "        rows.append({\n",
    "            \"id\": test_df.iloc[i][\"id\"],\n",
    "            \"polarization\": label2id(label),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# after you choose which model to use (classify, optimized_classify, etc.)\n",
    "test_preds_df = predict_dataset(optimized_prog, raw_test)\n",
    "\n",
    "trial_id = \"MIPRO\" + trial_id\n",
    "os.makedirs(f\"results/{trial_id}/subtask_1\", exist_ok=True)\n",
    "test_preds_df.to_csv(f\"results/{trial_id}/subtask_1/pred_{lang}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34f12229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "log_path = \"logs.json\"\n",
    "\n",
    "# Load previous trials from logs.json if it exists, else create new list\n",
    "try:\n",
    "    with open(log_path, \"r\") as f:\n",
    "        trials = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    trials = []\n",
    "\n",
    "# Try to find an existing trial with the same trial_id\n",
    "found = False\n",
    "for trial in trials:\n",
    "    if trial.get(\"trial_id\") == trial_id:\n",
    "        # Add or update the language entry under subtask_1\n",
    "        if \"subtask_1\" not in trial:\n",
    "            trial[\"subtask_1\"] = {\"score\": None}\n",
    "        if \"score\" not in trial[\"subtask_1\"]:\n",
    "            trial[\"subtask_1\"][\"score\"] = None\n",
    "        # Insert/update this language result\n",
    "        trial[\"subtask_1\"][lang] = {\n",
    "            \"eval_results\": {\n",
    "                \"eval_f1_macro\": mipro_f1_macro\n",
    "            }\n",
    "        }\n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if not found:\n",
    "    # Build current trial result dict and append if no matching trial_id found\n",
    "    current_trial = {\n",
    "        \"trial_id\": trial_id,\n",
    "        \"metadata\": {\n",
    "            \"approach\": \"dspy MIPROv2\",\n",
    "            \"student_model\": student_lm_name,\n",
    "            \"teacher_model\": teacher_lm_name\n",
    "        },\n",
    "        \"subtask_1\": {\n",
    "            \"score\": None,\n",
    "            lang: {\n",
    "                \"eval_results\": {\n",
    "                    \"eval_f1_macro\": mipro_f1_macro\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    trials.append(current_trial)\n",
    "\n",
    "# Save back to logs.json\n",
    "with open(log_path, \"w\") as f:\n",
    "    json.dump(trials, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4e3ebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the optimized program\n",
    "# Create dspy_cache dir if it doesn't exist\n",
    "os.makedirs(\"dspy_cache\", exist_ok=True)\n",
    "optimized_prog.save(f\"dspy_cache/optimized_subtask1_{lang}_dspy_miprov2_student{student_lm_name.split('/')[-1]}_teacher{teacher_lm_name.split('/')[-1]}_{trial_id}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe247b",
   "metadata": {},
   "source": [
    "# GEPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b16b093c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dspy import GPEA\n",
    "# gepa = GPEA(metric=accuracy_metric,\n",
    "#                  auto=\"light\",\n",
    "#                  reflection_lm=teacher_lm)\n",
    "\n",
    "# gepa_program = gepa.compile(student=optimized_prog,\n",
    "#                             trainset=raw_train,\n",
    "#                             valset=raw_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
