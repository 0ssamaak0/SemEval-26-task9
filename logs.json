[
    {
        "trial_id": "B000000",
        "metadata": {
            "approach": "bert",
            "model_eng": "bert-base-uncased",
            "model_arb": "bert-base-uncased",
            "learning_rate": 2e-05,
            "num_train_epochs": 3,
            "id_on_site": 447161
        },
        "subtask_1": {
            "score": 0.68,
            "eng": {
                "eval_results": {
                    "eval_f1_macro": 0.756
                }
            },
            "arb": {
                "eval_results": {
                    "eval_f1_macro": 0.65
                }
            }
        },
        "subtask_2": {
            "score": 0.03,
            "eng": {
                "score": 0.187,
                "eval_results": {
                    "eval_f1_macro": 0.268
                }
            },
            "arb": {
                "score": 0.0324,
                "eval_results": {
                    "eval_f1_macro": 0.045
                }
            }
        },
        "subtask_3": {
            "score": 0.21,
            "eng": {
                "score": 0.3161,
                "eval_results": {
                    "eval_f1_macro": 0.317
                }
            },
            "arb": {
                "score": 0.2119,
                "eval_results": {
                    "eval_f1_macro": 0.287
                }
            }
        }
    },
    {
        "trial_id": "B000001",
        "metadata": {
            "approach": "bert",
            "model_eng": "microsoft/deberta-v3-base",
            "model_arb": "UBC-NLP/MARBERTv2",
            "learning_rate": 2e-05,
            "num_train_epochs": 3,
            "id_on_site": 447912
        },
        "subtask_1": {
            "score": 0.68,
            "eng": {
                "score": 0.74,
                "eval_results": {
                    "eval_f1_macro": 0.756
                }
            },
            "arb": {
                "score": 0.5963,
                "eval_results": {
                    "eval_f1_macro": 0.8
                }
            }
        },
        "subtask_2": {
            "score": 0.03,
            "eng": {
                "score": 0.187,
                "eval_results": {
                    "eval_f1_macro": 0.268
                }
            },
            "arb": {
                "score": 0.0324,
                "eval_results": {
                    "eval_f1_macro": 0.61
                }
            }
        },
        "subtask_3": {
            "score": 0.4,
            "eng": {
                "score": 0.2344,
                "eval_results": {
                    "eval_f1_macro": 0.317
                }
            },
            "arb": {
                "score": 0.4016,
                "eval_results": {
                    "eval_f1_macro": 0.486
                }
            }
        }
    },
    {
        "trial_id": "GT000001",
        "metadata": {
            "approach": "MTL_Gated",
            "model_eng": "bert-base-uncased",
            "learning_rate": 2e-05,
            "num_train_epochs": 10,
            "per_device_train_batch_size": 64,
            "per_device_eval_batch_size": 8,
            "num_types": 5,
            "num_manifestations": 6,
            "datasets_merge": true,
            "model_arb": "bert-base-uncased",
            "id_on_site": 447014
        },
        "subtask_1": {
            "score": 0.66,
            "eng": {
                "score": 0.7718,
                "eval_results": {
                    "eval_f1_macro": 0.74693544282321
                }
            },
            "arb": {
                "score": 0.6597,
                "eval_results": {
                    "eval_f1_macro": 0.7106716973180833
                }
            }
        },
        "subtask_2": {
            "score": 0.06,
            "eng": {
                "score": 0.1612,
                "eval_results": {
                    "eval_f1_macro": 0.1649313318428617
                }
            },
            "arb": {
                "score": 0.0646,
                "eval_results": {
                    "eval_f1_macro": 0.1143635724331927
                }
            }
        },
        "subtask_3": {
            "score": 0.26,
            "eng": {
                "score": 0.2978,
                "eval_results": {
                    "eval_f1_macro": 0.2938462815302812
                }
            },
            "arb": {
                "score": 0.2553,
                "eval_results": {
                    "eval_f1_macro": 0.3068775328177798
                }
            }
        }
    },
    {
        "trial_id": "GT000002",
        "metadata": {
            "model_arb": "UBC-NLP/MARBERTv2",
            "approach": "MTL_Gated",
            "learning_rate": 2e-05,
            "num_train_epochs": 10,
            "per_device_train_batch_size": 64,
            "per_device_eval_batch_size": 8,
            "num_types": 5,
            "num_manifestations": 6,
            "datasets_merge": true,
            "model_eng": "microsoft/deberta-v3-base",
            "id_on_site": 447043
        },
        "subtask_1": {
            "arb": {
                "eval_results": {
                    "eval_f1_macro": 0.8090775936998496
                }
            },
            "eng": {
                "eval_results": {
                    "eval_f1_macro": 0.7538329933539514
                }
            }
        },
        "subtask_2": {
            "score": 0.38,
            "arb": {
                "score": 0.3843,
                "eval_results": {
                    "eval_f1_macro": 0.5169923091301157
                }
            },
            "eng": {
                "score": 0.1426,
                "eval_results": {
                    "eval_f1_macro": 0.14004294801669298
                }
            }
        },
        "subtask_3": {
            "score": 0.37,
            "arb": {
                "score": 0.3697,
                "eval_results": {
                    "eval_f1_macro": 0.432488336994267
                }
            },
            "eng": {
                "score": 0.367,
                "eval_results": {
                    "eval_f1_macro": 0.3542418115939625
                }
            }
        }
    },
    {
        "trial_id": "DSP0001S",
        "metadata": {
            "approach": "dspy basic",
            "model": "ollama_chat/gemma3:12b"
        },
        "subtask_1": {
            "score": null,
            "eng": {
                "eval_results": {
                    "eval_f1_macro": 0.7735584489912719
                }
            }
        }
    },
    {
        "trial_id": "0000NG1",
        "subtask_1": {
            "arb": {
                "eval_results": {
                    "eval_f1_macro": 0.8222222222222222
                }
            },
            "eng": {
                "eval_results": {
                    "eval_f1_macro": 0.7916488358673776
                }
            }
        },
        "metadata": {
            "model_arb": "UBC-NLP/MARBERTv2",
            "approach": "MTL_no_gate",
            "learning_rate": 2e-05,
            "num_train_epochs": 15,
            "per_device_train_batch_size": 32,
            "per_device_eval_batch_size": 16,
            "num_types": 5,
            "num_manifestations": 6,
            "datasets_merge": true,
            "model_eng": "microsoft/deberta-v3-base"
        },
        "subtask_2": {
            "arb": {
                "eval_results": {
                    "eval_f1_macro": 0.3943146759286401
                }
            },
            "eng": {
                "eval_results": {
                    "eval_f1_macro": 0.1407035175879397
                }
            }
        },
        "subtask_3": {
            "arb": {
                "eval_results": {
                    "eval_f1_macro": 0.38416407256783786
                }
            },
            "eng": {
                "eval_results": {
                    "eval_f1_macro": 0.1922514619883041
                }
            }
        }
    },
    {
        "trial_id": "MIPRODSP0001S",
        "metadata": {
            "approach": "dspy MIPROv2",
            "student_model": "ollama_chat/gemma3:12b",
            "teacher_model": "openai/gpt-5.1-2025-11-13"
        },
        "subtask_1": {
            "score": null,
            "eng": {
                "eval_results": {
                    "eval_f1_macro": 0.7784664830119375
                }
            }
        }
    }
]