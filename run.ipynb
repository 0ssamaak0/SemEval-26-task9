{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(mode=\"disabled\")\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, Trainer\n",
    "from src.config import NUM_TYPES, NUM_MANIFESTATIONS, MODEL_NAMES\n",
    "from src.data import load_data, prepare_datasets\n",
    "from src.model import SharedMTLModel\n",
    "from src.metrics import compute_metrics\n",
    "from src.training import compute_pos_weights, get_training_args, get_early_stopping_callback\n",
    "from src.predict import predict_dev_set\n",
    "from src.logging_utils import log_experiment_results\n",
    "\n",
    "lang = \"eng\"\n",
    "trial_id = \"MTL_10epochs_full_soft_gating\"\n",
    "model_name = MODEL_NAMES[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1, train_2, train_3 = load_data(lang)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, force_download=True)\n",
    "train_dataset, val_dataset = prepare_datasets(train_1, train_2, train_3, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight_2 = compute_pos_weights(train_2, train_2.columns[2:])\n",
    "pos_weight_3 = compute_pos_weights(train_3, train_3.columns[2:])\n",
    "model = SharedMTLModel(model_name, NUM_TYPES, NUM_MANIFESTATIONS, pos_weight_2, pos_weight_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = get_training_args(trial_id)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer),\n",
    "    callbacks=[get_early_stopping_callback()]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(\n",
    "    \"Validation Results:\",\n",
    "    f\"\\nsubtask_1 f1_macro: {eval_results['eval_subtask_1/f1_macro']:.4f}\",\n",
    "    f\"\\nsubtask_2 f1_macro: {eval_results['eval_subtask_2/f1_macro']:.4f}\",\n",
    "    f\"\\nsubtask_3 f1_macro: {eval_results['eval_subtask_3/f1_macro']:.4f}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_experiment_results(\n",
    "    eval_results,\n",
    "    trial_id,\n",
    "    lang,\n",
    "    model_name,\n",
    "    training_args,\n",
    "    NUM_TYPES,\n",
    "    NUM_MANIFESTATIONS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_1, output_2, output_3 = predict_dev_set(trainer, tokenizer, lang, trial_id)\n",
    "print(\"Predictions saved for all 3 dev sets with Logical Gating applied.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
