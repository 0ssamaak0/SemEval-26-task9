{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "78d203c2-4edd-41ed-a45d-dc1fc92fa697",
      "metadata": {
        "id": "78d203c2-4edd-41ed-a45d-dc1fc92fa697"
      },
      "source": [
        "# Bert baseline for POLAR"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea01ed9f-399e-4b8a-b46f-49369a33ee31",
      "metadata": {
        "id": "ea01ed9f-399e-4b8a-b46f-49369a33ee31"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this part of the starter notebook, we will take you through the process of all three Subtasks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aIt64l96d4TR",
      "metadata": {
        "id": "aIt64l96d4TR"
      },
      "source": [
        "## Subtask 1 - Polarization detection\n",
        "\n",
        "This is a binary classification to determine whether a post contains polarized content (Polarized or Not Polarized)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e5w0WSE89hdW",
      "metadata": {
        "id": "e5w0WSE89hdW"
      },
      "outputs": [],
      "source": [
        "# !unzip dev_phase.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "843cbd77-1b7f-41df-aec8-1d53fe1199c2",
      "metadata": {
        "id": "843cbd77-1b7f-41df-aec8-1d53fe1199c2"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5b8e9d6e-9342-43fd-9a0a-1330caf4e23a",
      "metadata": {
        "id": "5b8e9d6e-9342-43fd-9a0a-1330caf4e23a"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "UkC2r47nManC",
      "metadata": {
        "id": "UkC2r47nManC"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/ynd1ykmo?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x795c69909550>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "# Disable wandb logging for this script\n",
        "wandb.init(mode=\"disabled\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dac92ad-3fac-4aa1-aae6-1fe3ad14b1c0",
      "metadata": {
        "id": "4dac92ad-3fac-4aa1-aae6-1fe3ad14b1c0"
      },
      "source": [
        "## Data Import\n",
        "\n",
        "The training data consists of a short text and binary labels\n",
        "\n",
        "The data is structured as a CSV file with the following fields:\n",
        "- id: a unique identifier for the sample\n",
        "- text: a sentence or short text\n",
        "- polarization:  1 text is polarized, 0 text is not polarized\n",
        "\n",
        "The data is in all three subtask folders the same but only containing the labels for the specific task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e4fe8cc2-ba47-4240-bdd2-b1d3ea323134",
      "metadata": {
        "id": "e4fe8cc2-ba47-4240-bdd2-b1d3ea323134"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>polarization</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>eng_f308ca27dccc22549e50f1042ceb1df8</td>\n",
              "      <td>And where did I say h8 or xenophobia?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2605</th>\n",
              "      <td>eng_b1d3f6b9a86d738b0dbe5a5d891f79ef</td>\n",
              "      <td>WOW bad will the RedWAVE bloodbath be for the ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1754</th>\n",
              "      <td>eng_5836d1c4db446e1a501fe30fb1b2615c</td>\n",
              "      <td>Breitbart is racist trash, for revealing Racis...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>634</th>\n",
              "      <td>eng_789191ae3e9c3a9c6de6565559820379</td>\n",
              "      <td>Israeli Bedouins, lacking government protectio...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2700</th>\n",
              "      <td>eng_737e402f83d6f36f2023195aecac92df</td>\n",
              "      <td>As Joe Biden leaves the White House today, I r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        id  \\\n",
              "1350  eng_f308ca27dccc22549e50f1042ceb1df8   \n",
              "2605  eng_b1d3f6b9a86d738b0dbe5a5d891f79ef   \n",
              "1754  eng_5836d1c4db446e1a501fe30fb1b2615c   \n",
              "634   eng_789191ae3e9c3a9c6de6565559820379   \n",
              "2700  eng_737e402f83d6f36f2023195aecac92df   \n",
              "\n",
              "                                                   text  polarization  \n",
              "1350              And where did I say h8 or xenophobia?             0  \n",
              "2605  WOW bad will the RedWAVE bloodbath be for the ...             1  \n",
              "1754  Breitbart is racist trash, for revealing Racis...             1  \n",
              "634   Israeli Bedouins, lacking government protectio...             0  \n",
              "2700  As Joe Biden leaves the White House today, I r...             0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the training and validation data for subtask 1\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('./dev_phase/subtask1/train/eng.csv')\n",
        "\n",
        "# Split into train (80%) and val (20%), stratify if possible\n",
        "train, val = train_test_split(\n",
        "    data,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=data[\"polarization\"] if \"polarization\" in data.columns else None\n",
        ")\n",
        "\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eQWDFio83z9g",
      "metadata": {
        "id": "eQWDFio83z9g"
      },
      "source": [
        "# Dataset\n",
        "-  Create a pytorch class for handling data\n",
        "-  Wrapping the raw texts and labels into a format that Huggingfaceâ€™s Trainer can use for training and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "8e749d08",
      "metadata": {
        "id": "8e749d08"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,texts,labels,tokenizer,max_length =128):\n",
        "    self.texts=texts\n",
        "    self.labels=labels\n",
        "    self.tokenizer= tokenizer\n",
        "    self.max_length = max_length # Store max_length\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    text=self.texts[idx]\n",
        "    label=self.labels[idx]\n",
        "    encoding=self.tokenizer(text,truncation=True,padding=False,max_length=self.max_length,return_tensors='pt')\n",
        "\n",
        "    # Ensure consistent tensor conversion for all items\n",
        "    item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "    item['labels'] = torch.tensor(label, dtype=torch.long)\n",
        "    return item"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adfb74a3",
      "metadata": {
        "id": "adfb74a3"
      },
      "source": [
        "Now, we'll tokenize the text data and create the datasets using `bert-base-uncased` as the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c2e6215b",
      "metadata": {
        "id": "c2e6215b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = PolarizationDataset(train['text'].tolist(), train['polarization'].tolist(), tokenizer)\n",
        "val_dataset = PolarizationDataset(val['text'].tolist(), val['polarization'].tolist(), tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b13caa5c",
      "metadata": {
        "id": "b13caa5c"
      },
      "source": [
        "Next, we'll load the pre-trained `bert-base-uncased` model for sequence classification. Since this is a binary classification task (Polarized/Not Polarized), we set `num_labels=2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7cd0411f",
      "metadata": {
        "id": "7cd0411f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b250d61e",
      "metadata": {
        "id": "b250d61e"
      },
      "source": [
        "Now, we'll define the training arguments and the evaluation metric. We'll use macro F1 score for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "21c97269",
      "metadata": {
        "id": "21c97269"
      },
      "outputs": [],
      "source": [
        "# Define metrics function\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "        output_dir=f\"./\",\n",
        "        num_train_epochs=3,\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=64,\n",
        "        per_device_eval_batch_size=8,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_steps=100,\n",
        "        disable_tqdm=False\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20167a2b",
      "metadata": {
        "id": "20167a2b"
      },
      "source": [
        "Finally, we'll initialize the `Trainer` and start training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ecd9f444",
      "metadata": {
        "id": "ecd9f444"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [123/123 00:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.471600</td>\n",
              "      <td>0.777037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.422740</td>\n",
              "      <td>0.795289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.462100</td>\n",
              "      <td>0.428515</td>\n",
              "      <td>0.801731</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [81/81 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1 score on validation set: 0.801730707135938\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset,            # evaluation dataset\n",
        "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
        "    data_collator=DataCollatorWithPadding(tokenizer) # Data collator for dynamic padding\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set: {eval_results['eval_f1_macro']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "eea47953",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "20eb4a7a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/160 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:04<00:00, 38.98it/s]\n"
          ]
        }
      ],
      "source": [
        "test_dataset = pd.read_csv('./dev_phase/subtask1/dev/eng.csv')\n",
        "labels = []\n",
        "probs_list = []\n",
        "labels = []\n",
        "for text in tqdm(test_dataset['text']):\n",
        "    # Run the model\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
        "        pred_label = logits.argmax(dim=1).cpu().numpy()[0]\n",
        "        labels.append(pred_label)\n",
        "        probs_list.append(probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8cb65325",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eng_f66ca14d60851371f9720aaf4ccd9b58,0\n",
            "eng_3a489aa7fed9726aa8d3d4fe74c57efb,0\n",
            "eng_95770ff547ea5e48b0be00f385986483,0\n",
            "eng_2048ae6f9aa261c48e6d777bcc5b38bf,0\n",
            "eng_07781aa88e61e7c0a996abd1e5ea3a20,0\n",
            "eng_153d96f9dc27f0602c927223404d94b5,1\n",
            "eng_4ab5a4cc5c87d0af9cf4b80c301647bf,0\n",
            "eng_e75a95ba52930d6d72d503ab9469eb29,0\n",
            "eng_eb8fab668668f9959cafdecbfc0f081a,0\n",
            "eng_702724dc168d600e788d775c8e651f36,0\n",
            "eng_0efa1a3567443075db38c7ce2dcca571,0\n",
            "eng_d08d4243fd2786795df39c1a65dacac7,0\n",
            "eng_79fa99ba6989fb61ec127c6c99fc2343,1\n",
            "eng_30981038b71c210e97731d90e86038c5,0\n",
            "eng_b75e663a6fdc280171b6385b99306a3c,0\n",
            "eng_de2baffcfc59b672905e6f2694f672f6,0\n",
            "eng_d887794cce49564890a2552cdfb745d2,0\n",
            "eng_097b78cf6e209e6778e1fbda10d28b8d,0\n",
            "eng_6d29b7c72a091789d06d92157688e07f,0\n",
            "eng_00c797e70f1a2f50f1c59655f08581e1,1\n",
            "eng_f1e66eab0b9b2c4a83103eb65a67046e,0\n",
            "eng_4bf47d33b804477375ade2a151cb2614,0\n",
            "eng_6b4616355cbed93c122ca3e2369b3a0d,0\n",
            "eng_f011b534fb34efc8c574d2e16d3a95f5,0\n",
            "eng_8376c26da2f537abeada29ed927d3e01,0\n",
            "eng_af8597fa9be96fdfabb05c593476913c,0\n",
            "eng_e0f6e8dce6d6a6c13632b80100e5a6b1,0\n",
            "eng_48b992b30d2029785845b563a5ed5908,0\n",
            "eng_265277158900e90636bb6614c8f265b7,0\n",
            "eng_3c4dc44df877cfb232d222462dab6543,0\n",
            "eng_08a2c6cca0e7d33249339bbbef85c6c1,0\n",
            "eng_68280914d983fd99c5630ddd76e4bd95,0\n",
            "eng_cd13f9dc863b830f0f1a123db729eaff,0\n",
            "eng_6f76d66a4bd34d5ce4a94ec943385197,0\n",
            "eng_12e097065c75824d4121c0ec670647c1,0\n",
            "eng_bbd31cdfc7077e4903c3204ef1b9175f,0\n",
            "eng_4b4f2e1f0e1255dccef1959d2b30165b,0\n",
            "eng_cae0921076de11e46ad10498cc7d5441,0\n",
            "eng_298c63907209feee5c7cfe0bba8cb7be,0\n",
            "eng_47c81418327ba69c71e62f93a060ed39,0\n",
            "eng_1d443006327009ce2aff905147b39692,0\n",
            "eng_71021b3579c72f916147f751bce10e0c,0\n",
            "eng_de9a2ae60667aaddf4c646338764b526,0\n",
            "eng_c07a5a7dabfdb3965ec98128f318175f,0\n",
            "eng_fbceb1ae34db8daf3cf672a3d4256ddf,1\n",
            "eng_3fee89034fbdfa73372d1c88eb0aea59,0\n",
            "eng_c532b3613bde52aa43a9475f1ea0b32d,0\n",
            "eng_29ea84be308aaa614a463ddba1dfb36d,0\n",
            "eng_7b509629f338753f35fef4914bda9da6,0\n",
            "eng_3152400ae6bd362a4ae4405ea86070ec,0\n",
            "eng_c3a320d25b76f154caab9d9361b00907,0\n",
            "eng_3235c4f9ae1a74593f5cc6cff9277a85,0\n",
            "eng_0077188f1a05dd1d68f8352a9b84ca79,0\n",
            "eng_a390951455e707af9520c71ffc9db2d9,0\n",
            "eng_2b75f86d237a8699a27582ad90e42919,0\n",
            "eng_d21174080515b0ad8dc1d00ee4368d4f,0\n",
            "eng_ef00c86f2c475df7cee4fd5dd25e2bc7,0\n",
            "eng_74a62e8e997bc736b2894d9bc4da7661,1\n",
            "eng_9aad387704111e1f051fce5968ef2232,0\n",
            "eng_db9761cf21a3abb48b2669423ff5788a,0\n",
            "eng_7811dd491f8437afd9689a75ccb1ce04,0\n",
            "eng_437f5f40d878166878c2d32b8e16af31,0\n",
            "eng_a8b55f8a70d1c34f93fbdefa0350e507,0\n",
            "eng_01057285508602421377273897c3c0e7,0\n",
            "eng_175c490fa4665823f1dc2fc44e4d98fb,0\n",
            "eng_1feb16d41ce65927a8153742d14b5b6b,0\n",
            "eng_8182654f9b6144da76e1cfcc985a4b3a,0\n",
            "eng_03a2aea654b7697fcd72acdbf7ecf944,0\n",
            "eng_a4a13cea5e6750286b14ae7a8d81bd28,1\n",
            "eng_927ef1e092e0b61d9161dccb20b7d212,0\n",
            "eng_bab15926554f28dc36582b6e275b8805,0\n",
            "eng_938602684a67196e4bd95b313ad3919f,0\n",
            "eng_d6d5259e0d04bf6fc543ba5baaf273f1,0\n",
            "eng_bf5e5633ac2fdca9164c02022e0c99fd,0\n",
            "eng_31268830d496fa2970b2ff9918b3b7ba,1\n",
            "eng_95d7415206b7898a7486b0c69197baa2,0\n",
            "eng_b91a56f542d0513d636a0a019b7726eb,0\n",
            "eng_eeaa3e10a86dec32fbc1b9f1d156d796,0\n",
            "eng_e2622eb5bd4d433e6138c58d943b4043,0\n",
            "eng_533142c1bdb17ab3ffdf43e6e25f1406,0\n",
            "eng_325cd4d0e08485ec5693fcf15b14ff1f,0\n",
            "eng_063b19c19c369b678bf3446054569fdf,0\n",
            "eng_ebe1ae54e0854b322ad3c9667a2a4802,1\n",
            "eng_f1a522278c7fff07d7d7f3d033b5fa36,0\n",
            "eng_50c78c3a83be7868fb1ce0d636911f63,1\n",
            "eng_0f6d980d360c0a6c8f1edfdf6a791fb8,1\n",
            "eng_5a19fecc98ef147b13b59bd0d8caf8d5,0\n",
            "eng_3ad13d30d6003ac059e6c923a7a7eafb,1\n",
            "eng_74e531f9dcb74c5a7bfd9668012a8c74,1\n",
            "eng_b666fec715d97437ecb9c0c6a54378c4,0\n",
            "eng_5b51f6101221e28d6da47f2cb7214ee6,1\n",
            "eng_c12c886536597ecaddd1e94e922e8969,0\n",
            "eng_882dae250fd3467770c289b835a2aa83,1\n",
            "eng_b9cfff2304e5349d315bc474ce2899eb,0\n",
            "eng_3857e2c131a5b5fef5bbf2e9794bcd5e,0\n",
            "eng_2806bece99f0002047cc86a78a30a1d7,1\n",
            "eng_003fc3a198de8381e08ab3d85c7e40be,0\n",
            "eng_d74c7582012f631348296b2dbf10f4f6,1\n",
            "eng_0e62ae808071606db649622cb73dc2cb,1\n",
            "eng_8cef4402ae1b38e7c4593cc163bfe10c,1\n",
            "eng_310cb1f24f3545a53f33e005798ece95,1\n",
            "eng_5606f46a55984e9bf7db7034d451a1f6,1\n",
            "eng_ab5a1479644f5672c6337214087ecb4d,1\n",
            "eng_5e89647c49019ef6f4e3549bc5b41970,1\n",
            "eng_fd3ae133fa1ae5dac30d88c601d3171e,0\n",
            "eng_995661141a6abbbdef6770db6e1bd8f5,1\n",
            "eng_88e3a4bddcf38fe36666e6875399f6c3,1\n",
            "eng_5fbc07e0e76d061ad2496d55c93f4970,1\n",
            "eng_ef3116c56645f94bbe998051aaa49e40,1\n",
            "eng_4cd9e7e11035bcacb2814a1817238e75,0\n",
            "eng_ebd69a723309a37d9b5f384a3cd5c87c,1\n",
            "eng_d0b1c523b1cb02e41ca250d4d705efe6,1\n",
            "eng_5f408abc83c76617c0525e042a3ceb48,0\n",
            "eng_947ae20dbd1e2a3ba07bcdbd4b6a4eaa,1\n",
            "eng_3496f210f022027af26571fa2a2b6e30,0\n",
            "eng_4fca762d791268e973669733aa684e37,0\n",
            "eng_93a2492e7860be0d7ca445a97e245abe,1\n",
            "eng_b2f95890baff716a2d871097a1c210fe,0\n",
            "eng_e5cfe9e96de0f4873a4a6dbfca573be2,1\n",
            "eng_897afb355e98b187b9f75478bbbf2c51,1\n",
            "eng_f0ae86891c2da536ebf24c0f3964dca8,1\n",
            "eng_e231e20dbb7d3d433637dbb3d3c946a0,1\n",
            "eng_8ee2b2e8b53c55407f30fbf1219b1588,1\n",
            "eng_0eb6247db86e3b42c8dc125317957580,0\n",
            "eng_185e4dabf037ec90771e1bd18e621e2a,1\n",
            "eng_dbadd716608d71fb92621f7f8259f4e4,0\n",
            "eng_ac3c36cc719bdce4cab6c919b9b2429e,1\n",
            "eng_5d8aa4863fe2f8c26f541937ff5a0368,1\n",
            "eng_2fd4484b6bab80971a96b2100e20966a,0\n",
            "eng_0e11358da0c0e0cd8e0fdedf05a0cbba,0\n",
            "eng_0fb944d51bb376102a3ea6b65bafab6a,1\n",
            "eng_d9253eaeb206934208a57786b688c316,0\n",
            "eng_d841e099c41eb0fdd803e7c0a6109933,0\n",
            "eng_f6fc63a70cfafa2144d88c503cd4687b,1\n",
            "eng_2712f15ca491022233712e630d64d73d,1\n",
            "eng_d62d432eec0c12d2dc3b023edf67eac0,0\n",
            "eng_5ee585bf8f98b28a7e65035db0204410,0\n",
            "eng_07745499010cafb2d59ff898c49cf615,0\n",
            "eng_ec325c11de1d6163d8feb749d6457c20,0\n",
            "eng_4d616a82cd313bdd0dfdcf47b5f26795,0\n",
            "eng_268c8ff24dbb29bfa42a252ad198fe29,0\n",
            "eng_d9a5c1cc8ce24ec15a6b432204a34a9d,1\n",
            "eng_e71b8aa8338a1deaae7328a73a122cca,1\n",
            "eng_8c2492d1274d3693cb98ee3e700baba7,0\n",
            "eng_d7edf2c962f46f62f1140787e871c4a2,0\n",
            "eng_4c2694e3632178ffb50db62f48e1d75e,0\n",
            "eng_e343d9522d1ea4ab6d50998b81ad36b3,1\n",
            "eng_c15194e3c8b4bba93b3d652340460ffd,1\n",
            "eng_04eae1abe60bbb1373b9bb0f77a12e6b,1\n",
            "eng_12b06c46b376b4425fe6ffbcee59276c,1\n",
            "eng_13f40590af8d17dc49cbd80dd34e6be8,0\n",
            "eng_66f612addfe5a96a4a1a84342d86bdc4,1\n",
            "eng_ac17e23b4789ee87ade59dca086adf5c,0\n",
            "eng_a0a03d5390346e771751b3d0890224c1,0\n",
            "eng_b01fd24fbfb6630edba40768157dbed3,1\n",
            "eng_9f170d76134d91a9aae08ec49a0eb1b1,0\n",
            "eng_3caf621f17c15e73ad88d1d58ace76e1,1\n",
            "eng_d735bda395a80ff9861c0ab78c5fb9a3,1\n",
            "eng_576cca5b3a10908cc024bc4c4c6e61b3,0\n",
            "eng_e729b733cd4c356edea50e29301a8162,0\n"
          ]
        }
      ],
      "source": [
        "# print the results row by row in csv format\n",
        "for i in range(len(labels)):\n",
        "    print(f\"{test_dataset['id'][i]},{labels[i]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Qi53eheGIbu",
      "metadata": {
        "id": "5Qi53eheGIbu"
      },
      "source": [
        "# Subtask 2: Polarization Type Classification\n",
        "Multi-label classification to identify the target of polarization as one of the following categories: Gender/Sexual, Political, Religious, Racial/Ethnic, or Other.\n",
        "For this task we will load the data for subtask 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "YaWIvnYv0rV2",
      "metadata": {
        "id": "YaWIvnYv0rV2"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('./dev_phase/subtask2/train/eng.csv')\n",
        "\n",
        "# Split into train (80%) and val (20%), stratify if possible\n",
        "train, val = train_test_split(\n",
        "    data,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "I6S2S6QBDKzw",
      "metadata": {
        "id": "I6S2S6QBDKzw"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length # Store max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, truncation=True, padding=False, max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        # Ensure consistent tensor conversion for all items\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        # CHANGE THIS LINE: Use torch.float instead of torch.long for multi-label classification\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
        "        return item\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "u1_KYsG68nxI",
      "metadata": {
        "id": "u1_KYsG68nxI"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "\n",
        "# Create train and Test dataset for multilabel\n",
        "train_dataset = PolarizationDataset(train['text'].tolist(), train[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n",
        "val_dataset = PolarizationDataset(val['text'].tolist(), val[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n",
        "dev_dataset = PolarizationDataset(val['text'].tolist(), val[['gender/sexual','political','religious','racial/ethnic','other']].values.tolist(), tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cdiYJyr08bw2",
      "metadata": {
        "id": "cdiYJyr08bw2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=5, problem_type=\"multi_label_classification\") # 5 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ArVWKwze2mtS",
      "metadata": {
        "id": "ArVWKwze2mtS"
      },
      "outputs": [],
      "source": [
        "# Define metrics function for multi-label classification\n",
        "def compute_metrics_multilabel(p):\n",
        "    # Sigmoid the predictions to get probabilities\n",
        "    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n",
        "    # Convert probabilities to predicted labels (0 or 1)\n",
        "    preds = (probs > 0.5).int().numpy()\n",
        "    # Compute macro F1 score\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./\",\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100,\n",
        "    disable_tqdm=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "Qd3QPyfc2RKE",
      "metadata": {
        "id": "Qd3QPyfc2RKE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='969' max='969' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [969/969 01:49, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.229600</td>\n",
              "      <td>0.220426</td>\n",
              "      <td>0.132258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.185100</td>\n",
              "      <td>0.201620</td>\n",
              "      <td>0.138462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.154500</td>\n",
              "      <td>0.217973</td>\n",
              "      <td>0.192754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [81/81 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1 score on validation set for Subtask 2: 0.19275362318840578\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics_multilabel,  # Use the new metrics function\n",
        "    data_collator=DataCollatorWithPadding(tokenizer)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set for Subtask 2: {eval_results['eval_f1_macro']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8536deba",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/160 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:04<00:00, 38.86it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "test_dataset = pd.read_csv('./dev_phase/subtask2/dev/eng.csv')\n",
        "labels = []\n",
        "probs_list = []\n",
        "labels = []\n",
        "for text in tqdm(test_dataset['text']):\n",
        "    # Run the model\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "        pred_label = (probabilities > 0.5).astype(int)\n",
        "        labels.append(pred_label)\n",
        "        probs_list.append(probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c951d74e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eng_f66ca14d60851371f9720aaf4ccd9b58,0,0,0,0,0\n",
            "eng_3a489aa7fed9726aa8d3d4fe74c57efb,0,0,0,0,0\n",
            "eng_95770ff547ea5e48b0be00f385986483,0,0,0,0,0\n",
            "eng_2048ae6f9aa261c48e6d777bcc5b38bf,0,0,0,0,0\n",
            "eng_07781aa88e61e7c0a996abd1e5ea3a20,0,0,0,0,0\n",
            "eng_153d96f9dc27f0602c927223404d94b5,0,0,0,0,0\n",
            "eng_4ab5a4cc5c87d0af9cf4b80c301647bf,0,0,0,0,0\n",
            "eng_e75a95ba52930d6d72d503ab9469eb29,0,0,0,0,0\n",
            "eng_eb8fab668668f9959cafdecbfc0f081a,0,0,0,0,0\n",
            "eng_702724dc168d600e788d775c8e651f36,0,0,0,0,0\n",
            "eng_0efa1a3567443075db38c7ce2dcca571,0,0,0,0,0\n",
            "eng_d08d4243fd2786795df39c1a65dacac7,0,0,0,0,0\n",
            "eng_79fa99ba6989fb61ec127c6c99fc2343,0,1,0,0,0\n",
            "eng_30981038b71c210e97731d90e86038c5,0,0,0,0,0\n",
            "eng_b75e663a6fdc280171b6385b99306a3c,0,0,0,0,0\n",
            "eng_de2baffcfc59b672905e6f2694f672f6,0,0,0,0,0\n",
            "eng_d887794cce49564890a2552cdfb745d2,0,0,0,0,0\n",
            "eng_097b78cf6e209e6778e1fbda10d28b8d,0,0,0,0,0\n",
            "eng_6d29b7c72a091789d06d92157688e07f,0,0,0,0,0\n",
            "eng_00c797e70f1a2f50f1c59655f08581e1,0,1,0,1,0\n",
            "eng_f1e66eab0b9b2c4a83103eb65a67046e,0,0,0,0,0\n",
            "eng_4bf47d33b804477375ade2a151cb2614,0,0,0,0,0\n",
            "eng_6b4616355cbed93c122ca3e2369b3a0d,0,0,0,0,0\n",
            "eng_f011b534fb34efc8c574d2e16d3a95f5,0,0,0,0,0\n",
            "eng_8376c26da2f537abeada29ed927d3e01,0,0,0,0,0\n",
            "eng_af8597fa9be96fdfabb05c593476913c,0,0,0,0,0\n",
            "eng_e0f6e8dce6d6a6c13632b80100e5a6b1,0,0,0,0,0\n",
            "eng_48b992b30d2029785845b563a5ed5908,0,0,0,0,0\n",
            "eng_265277158900e90636bb6614c8f265b7,0,0,0,0,0\n",
            "eng_3c4dc44df877cfb232d222462dab6543,0,0,0,0,0\n",
            "eng_08a2c6cca0e7d33249339bbbef85c6c1,0,0,0,0,0\n",
            "eng_68280914d983fd99c5630ddd76e4bd95,0,0,0,0,0\n",
            "eng_cd13f9dc863b830f0f1a123db729eaff,0,0,0,0,0\n",
            "eng_6f76d66a4bd34d5ce4a94ec943385197,0,0,0,0,0\n",
            "eng_12e097065c75824d4121c0ec670647c1,0,0,0,0,0\n",
            "eng_bbd31cdfc7077e4903c3204ef1b9175f,0,0,0,0,0\n",
            "eng_4b4f2e1f0e1255dccef1959d2b30165b,0,0,0,0,0\n",
            "eng_cae0921076de11e46ad10498cc7d5441,0,0,0,0,0\n",
            "eng_298c63907209feee5c7cfe0bba8cb7be,0,0,0,0,0\n",
            "eng_47c81418327ba69c71e62f93a060ed39,0,1,0,0,0\n",
            "eng_1d443006327009ce2aff905147b39692,0,0,0,0,0\n",
            "eng_71021b3579c72f916147f751bce10e0c,0,0,0,0,0\n",
            "eng_de9a2ae60667aaddf4c646338764b526,0,0,0,0,0\n",
            "eng_c07a5a7dabfdb3965ec98128f318175f,0,1,0,0,0\n",
            "eng_fbceb1ae34db8daf3cf672a3d4256ddf,0,0,0,0,0\n",
            "eng_3fee89034fbdfa73372d1c88eb0aea59,0,0,0,0,0\n",
            "eng_c532b3613bde52aa43a9475f1ea0b32d,0,0,0,0,0\n",
            "eng_29ea84be308aaa614a463ddba1dfb36d,0,0,0,0,0\n",
            "eng_7b509629f338753f35fef4914bda9da6,0,0,0,0,0\n",
            "eng_3152400ae6bd362a4ae4405ea86070ec,0,0,0,0,0\n",
            "eng_c3a320d25b76f154caab9d9361b00907,0,0,0,0,0\n",
            "eng_3235c4f9ae1a74593f5cc6cff9277a85,0,0,0,0,0\n",
            "eng_0077188f1a05dd1d68f8352a9b84ca79,0,0,0,0,0\n",
            "eng_a390951455e707af9520c71ffc9db2d9,0,0,0,0,0\n",
            "eng_2b75f86d237a8699a27582ad90e42919,0,0,0,0,0\n",
            "eng_d21174080515b0ad8dc1d00ee4368d4f,0,0,0,0,0\n",
            "eng_ef00c86f2c475df7cee4fd5dd25e2bc7,0,0,0,0,0\n",
            "eng_74a62e8e997bc736b2894d9bc4da7661,0,1,0,0,0\n",
            "eng_9aad387704111e1f051fce5968ef2232,0,0,0,0,0\n",
            "eng_db9761cf21a3abb48b2669423ff5788a,0,0,0,0,0\n",
            "eng_7811dd491f8437afd9689a75ccb1ce04,0,0,0,0,0\n",
            "eng_437f5f40d878166878c2d32b8e16af31,0,0,0,0,0\n",
            "eng_a8b55f8a70d1c34f93fbdefa0350e507,0,0,0,0,0\n",
            "eng_01057285508602421377273897c3c0e7,0,0,0,0,0\n",
            "eng_175c490fa4665823f1dc2fc44e4d98fb,0,0,0,0,0\n",
            "eng_1feb16d41ce65927a8153742d14b5b6b,0,0,0,0,0\n",
            "eng_8182654f9b6144da76e1cfcc985a4b3a,0,0,0,0,0\n",
            "eng_03a2aea654b7697fcd72acdbf7ecf944,0,0,0,0,0\n",
            "eng_a4a13cea5e6750286b14ae7a8d81bd28,0,1,0,0,0\n",
            "eng_927ef1e092e0b61d9161dccb20b7d212,0,1,0,0,0\n",
            "eng_bab15926554f28dc36582b6e275b8805,0,0,0,0,0\n",
            "eng_938602684a67196e4bd95b313ad3919f,0,0,0,0,0\n",
            "eng_d6d5259e0d04bf6fc543ba5baaf273f1,0,0,0,0,0\n",
            "eng_bf5e5633ac2fdca9164c02022e0c99fd,0,0,0,0,0\n",
            "eng_31268830d496fa2970b2ff9918b3b7ba,0,1,0,0,0\n",
            "eng_95d7415206b7898a7486b0c69197baa2,0,0,0,0,0\n",
            "eng_b91a56f542d0513d636a0a019b7726eb,0,0,0,0,0\n",
            "eng_eeaa3e10a86dec32fbc1b9f1d156d796,0,0,0,0,0\n",
            "eng_e2622eb5bd4d433e6138c58d943b4043,0,0,0,0,0\n",
            "eng_533142c1bdb17ab3ffdf43e6e25f1406,0,0,0,0,0\n",
            "eng_325cd4d0e08485ec5693fcf15b14ff1f,0,0,0,0,0\n",
            "eng_063b19c19c369b678bf3446054569fdf,0,0,0,0,0\n",
            "eng_ebe1ae54e0854b322ad3c9667a2a4802,0,1,0,0,0\n",
            "eng_f1a522278c7fff07d7d7f3d033b5fa36,0,0,0,0,0\n",
            "eng_50c78c3a83be7868fb1ce0d636911f63,0,1,0,1,0\n",
            "eng_0f6d980d360c0a6c8f1edfdf6a791fb8,0,1,0,0,0\n",
            "eng_5a19fecc98ef147b13b59bd0d8caf8d5,0,1,0,0,0\n",
            "eng_3ad13d30d6003ac059e6c923a7a7eafb,0,1,0,0,0\n",
            "eng_74e531f9dcb74c5a7bfd9668012a8c74,0,1,0,0,0\n",
            "eng_b666fec715d97437ecb9c0c6a54378c4,0,0,0,0,0\n",
            "eng_5b51f6101221e28d6da47f2cb7214ee6,0,1,0,0,0\n",
            "eng_c12c886536597ecaddd1e94e922e8969,0,0,0,0,0\n",
            "eng_882dae250fd3467770c289b835a2aa83,0,1,0,0,0\n",
            "eng_b9cfff2304e5349d315bc474ce2899eb,0,0,0,0,0\n",
            "eng_3857e2c131a5b5fef5bbf2e9794bcd5e,0,0,0,0,0\n",
            "eng_2806bece99f0002047cc86a78a30a1d7,0,0,0,0,0\n",
            "eng_003fc3a198de8381e08ab3d85c7e40be,0,1,0,0,0\n",
            "eng_d74c7582012f631348296b2dbf10f4f6,0,0,0,0,0\n",
            "eng_0e62ae808071606db649622cb73dc2cb,0,1,0,1,0\n",
            "eng_8cef4402ae1b38e7c4593cc163bfe10c,0,1,0,0,0\n",
            "eng_310cb1f24f3545a53f33e005798ece95,0,1,0,0,0\n",
            "eng_5606f46a55984e9bf7db7034d451a1f6,0,1,0,0,0\n",
            "eng_ab5a1479644f5672c6337214087ecb4d,0,1,0,0,0\n",
            "eng_5e89647c49019ef6f4e3549bc5b41970,0,1,0,0,0\n",
            "eng_fd3ae133fa1ae5dac30d88c601d3171e,0,0,0,0,0\n",
            "eng_995661141a6abbbdef6770db6e1bd8f5,0,1,0,0,0\n",
            "eng_88e3a4bddcf38fe36666e6875399f6c3,0,1,0,0,0\n",
            "eng_5fbc07e0e76d061ad2496d55c93f4970,0,1,0,0,0\n",
            "eng_ef3116c56645f94bbe998051aaa49e40,0,0,0,0,0\n",
            "eng_4cd9e7e11035bcacb2814a1817238e75,0,0,0,0,0\n",
            "eng_ebd69a723309a37d9b5f384a3cd5c87c,0,0,0,0,0\n",
            "eng_d0b1c523b1cb02e41ca250d4d705efe6,0,1,0,0,0\n",
            "eng_5f408abc83c76617c0525e042a3ceb48,0,0,0,0,0\n",
            "eng_947ae20dbd1e2a3ba07bcdbd4b6a4eaa,0,1,0,0,0\n",
            "eng_3496f210f022027af26571fa2a2b6e30,0,0,0,0,0\n",
            "eng_4fca762d791268e973669733aa684e37,0,0,0,0,0\n",
            "eng_93a2492e7860be0d7ca445a97e245abe,0,1,0,1,0\n",
            "eng_b2f95890baff716a2d871097a1c210fe,0,1,0,0,0\n",
            "eng_e5cfe9e96de0f4873a4a6dbfca573be2,0,0,0,0,0\n",
            "eng_897afb355e98b187b9f75478bbbf2c51,0,1,0,0,0\n",
            "eng_f0ae86891c2da536ebf24c0f3964dca8,0,1,0,0,0\n",
            "eng_e231e20dbb7d3d433637dbb3d3c946a0,0,1,0,0,0\n",
            "eng_8ee2b2e8b53c55407f30fbf1219b1588,0,1,0,0,0\n",
            "eng_0eb6247db86e3b42c8dc125317957580,0,0,0,0,0\n",
            "eng_185e4dabf037ec90771e1bd18e621e2a,0,1,0,1,0\n",
            "eng_dbadd716608d71fb92621f7f8259f4e4,0,0,0,0,0\n",
            "eng_ac3c36cc719bdce4cab6c919b9b2429e,0,1,0,0,0\n",
            "eng_5d8aa4863fe2f8c26f541937ff5a0368,0,1,0,0,0\n",
            "eng_2fd4484b6bab80971a96b2100e20966a,0,0,0,0,0\n",
            "eng_0e11358da0c0e0cd8e0fdedf05a0cbba,0,1,0,0,0\n",
            "eng_0fb944d51bb376102a3ea6b65bafab6a,0,0,0,0,0\n",
            "eng_d9253eaeb206934208a57786b688c316,0,0,0,0,0\n",
            "eng_d841e099c41eb0fdd803e7c0a6109933,0,1,0,0,0\n",
            "eng_f6fc63a70cfafa2144d88c503cd4687b,0,1,0,0,0\n",
            "eng_2712f15ca491022233712e630d64d73d,0,1,0,0,0\n",
            "eng_d62d432eec0c12d2dc3b023edf67eac0,0,0,0,0,0\n",
            "eng_5ee585bf8f98b28a7e65035db0204410,0,0,0,0,0\n",
            "eng_07745499010cafb2d59ff898c49cf615,0,0,0,0,0\n",
            "eng_ec325c11de1d6163d8feb749d6457c20,0,0,0,0,0\n",
            "eng_4d616a82cd313bdd0dfdcf47b5f26795,0,0,0,0,0\n",
            "eng_268c8ff24dbb29bfa42a252ad198fe29,0,0,0,0,0\n",
            "eng_d9a5c1cc8ce24ec15a6b432204a34a9d,0,0,0,0,0\n",
            "eng_e71b8aa8338a1deaae7328a73a122cca,0,1,0,0,0\n",
            "eng_8c2492d1274d3693cb98ee3e700baba7,0,0,0,0,0\n",
            "eng_d7edf2c962f46f62f1140787e871c4a2,0,0,0,0,0\n",
            "eng_4c2694e3632178ffb50db62f48e1d75e,0,0,0,0,0\n",
            "eng_e343d9522d1ea4ab6d50998b81ad36b3,0,1,0,0,0\n",
            "eng_c15194e3c8b4bba93b3d652340460ffd,0,1,0,0,0\n",
            "eng_04eae1abe60bbb1373b9bb0f77a12e6b,0,1,0,0,0\n",
            "eng_12b06c46b376b4425fe6ffbcee59276c,0,1,0,0,0\n",
            "eng_13f40590af8d17dc49cbd80dd34e6be8,0,0,0,0,0\n",
            "eng_66f612addfe5a96a4a1a84342d86bdc4,0,0,0,0,0\n",
            "eng_ac17e23b4789ee87ade59dca086adf5c,0,0,0,0,0\n",
            "eng_a0a03d5390346e771751b3d0890224c1,0,0,0,0,0\n",
            "eng_b01fd24fbfb6630edba40768157dbed3,0,1,0,0,0\n",
            "eng_9f170d76134d91a9aae08ec49a0eb1b1,0,0,0,0,0\n",
            "eng_3caf621f17c15e73ad88d1d58ace76e1,0,1,0,0,0\n",
            "eng_d735bda395a80ff9861c0ab78c5fb9a3,0,1,0,0,0\n",
            "eng_576cca5b3a10908cc024bc4c4c6e61b3,0,1,0,0,0\n",
            "eng_e729b733cd4c356edea50e29301a8162,0,0,0,0,0\n"
          ]
        }
      ],
      "source": [
        "# print the results row by row in csv format\n",
        "for i in range(len(labels)):\n",
        "    print(f\"{test_dataset['id'][i]},\" + \",\".join(str(x) for x in labels[i]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UL1uE8llIgTQ",
      "metadata": {
        "id": "UL1uE8llIgTQ"
      },
      "source": [
        "# Subtask 3: Manifestation Identification\n",
        "Multi-label classification to classify how polarization is expressed, with multiple possible labels including Vilification, Extreme Language, Stereotype, Invalidation, Lack of Empathy, and Dehumanization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "nCz20cgl-K3t",
      "metadata": {
        "id": "nCz20cgl-K3t"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "data = pd.read_csv('./dev_phase/subtask3/train/eng.csv')\n",
        "\n",
        "# Split into train (80%) and val (20%), stratify if possible\n",
        "train, val = train_test_split(\n",
        "    data,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "Qs-UjVYsInpD",
      "metadata": {
        "id": "Qs-UjVYsInpD"
      },
      "outputs": [],
      "source": [
        "# Fix the dataset class by inheriting from torch.utils.data.Dataset\n",
        "class PolarizationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length # Store max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(text, truncation=True, padding=False, max_length=self.max_length, return_tensors='pt')\n",
        "\n",
        "        # Ensure consistent tensor conversion for all items\n",
        "        item = {key: encoding[key].squeeze() for key in encoding.keys()}\n",
        "        # CHANGE THIS LINE: Use torch.float instead of torch.long for multi-label classification\n",
        "        item['labels'] = torch.tensor(label, dtype=torch.float)\n",
        "        return item"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "-yxSaDCA9IMi",
      "metadata": {
        "id": "-yxSaDCA9IMi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:566: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "\n",
        "# Create train and Test dataset for multilabel\n",
        "train_dataset = PolarizationDataset(train['text'].tolist(), train[['vilification','extreme_language','stereotype','invalidation','lack_of_empathy','dehumanization']].values.tolist(), tokenizer)\n",
        "val_dataset = PolarizationDataset(val['text'].tolist(), val[['vilification','extreme_language','stereotype','invalidation','lack_of_empathy','dehumanization']].values.tolist(), tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "0VXqqqIH9A3M",
      "metadata": {
        "id": "0VXqqqIH9A3M"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=6, problem_type=\"multi_label_classification\") # use 6 labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "QLubGtx988hm",
      "metadata": {
        "id": "QLubGtx988hm"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./\",\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_steps=100,\n",
        "    disable_tqdm=False\n",
        ")\n",
        "\n",
        "# Define metrics function for multi-label classification\n",
        "def compute_metrics_multilabel(p):\n",
        "    # Sigmoid the predictions to get probabilities\n",
        "    probs = torch.sigmoid(torch.from_numpy(p.predictions))\n",
        "    # Convert probabilities to predicted labels (0 or 1)\n",
        "    preds = (probs > 0.5).int().numpy()\n",
        "    # Compute macro F1 score\n",
        "    return {'f1_macro': f1_score(p.label_ids, preds, average='macro')}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "qEhm1TEv82mP",
      "metadata": {
        "id": "qEhm1TEv82mP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "A ConfigError was raised whilst setting the number of model parameters in Weights & Biases config.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='969' max='969' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [969/969 01:48, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1 Macro</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.376900</td>\n",
              "      <td>0.380339</td>\n",
              "      <td>0.064461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.335700</td>\n",
              "      <td>0.328302</td>\n",
              "      <td>0.219581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.306700</td>\n",
              "      <td>0.345058</td>\n",
              "      <td>0.311165</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='81' max='81' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [81/81 00:02]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Macro F1 score on validation set for Subtask 3: 0.3111648990997745\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics_multilabel,  # Use the new metrics function\n",
        "    data_collator=DataCollatorWithPadding(tokenizer)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Macro F1 score on validation set for Subtask 3: {eval_results['eval_f1_macro']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "023e38ba",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a3881bc1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/160 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160/160 [00:04<00:00, 38.67it/s]\n"
          ]
        }
      ],
      "source": [
        "test_dataset = pd.read_csv('./dev_phase/subtask3/dev/eng.csv')\n",
        "labels = []\n",
        "probs_list = []\n",
        "labels = []\n",
        "for text in tqdm(test_dataset['text']):\n",
        "    # Run the model\n",
        "    inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(model.device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.sigmoid(logits).cpu().numpy()[0]\n",
        "        pred_label = (probabilities > 0.5).astype(int)\n",
        "        labels.append(pred_label)\n",
        "        probs_list.append(probabilities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "1dd5235f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eng_f66ca14d60851371f9720aaf4ccd9b58,0,0,0,0,0,0\n",
            "eng_3a489aa7fed9726aa8d3d4fe74c57efb,0,0,0,0,0,0\n",
            "eng_95770ff547ea5e48b0be00f385986483,0,0,0,0,0,0\n",
            "eng_2048ae6f9aa261c48e6d777bcc5b38bf,0,0,0,0,0,0\n",
            "eng_07781aa88e61e7c0a996abd1e5ea3a20,0,0,0,0,0,0\n",
            "eng_153d96f9dc27f0602c927223404d94b5,0,0,0,0,0,0\n",
            "eng_4ab5a4cc5c87d0af9cf4b80c301647bf,0,0,0,0,0,0\n",
            "eng_e75a95ba52930d6d72d503ab9469eb29,0,0,0,0,0,0\n",
            "eng_eb8fab668668f9959cafdecbfc0f081a,0,0,0,0,0,0\n",
            "eng_702724dc168d600e788d775c8e651f36,0,0,0,0,0,0\n",
            "eng_0efa1a3567443075db38c7ce2dcca571,0,0,0,0,0,0\n",
            "eng_d08d4243fd2786795df39c1a65dacac7,0,0,0,0,0,0\n",
            "eng_79fa99ba6989fb61ec127c6c99fc2343,1,0,0,0,0,0\n",
            "eng_30981038b71c210e97731d90e86038c5,0,0,0,0,0,0\n",
            "eng_b75e663a6fdc280171b6385b99306a3c,0,0,0,0,0,0\n",
            "eng_de2baffcfc59b672905e6f2694f672f6,0,0,0,0,0,0\n",
            "eng_d887794cce49564890a2552cdfb745d2,0,0,0,0,0,0\n",
            "eng_097b78cf6e209e6778e1fbda10d28b8d,0,0,0,0,0,0\n",
            "eng_6d29b7c72a091789d06d92157688e07f,0,0,0,0,0,0\n",
            "eng_00c797e70f1a2f50f1c59655f08581e1,1,1,0,0,0,0\n",
            "eng_f1e66eab0b9b2c4a83103eb65a67046e,0,0,0,0,0,0\n",
            "eng_4bf47d33b804477375ade2a151cb2614,0,0,0,0,0,0\n",
            "eng_6b4616355cbed93c122ca3e2369b3a0d,0,0,0,0,0,0\n",
            "eng_f011b534fb34efc8c574d2e16d3a95f5,0,0,0,0,0,0\n",
            "eng_8376c26da2f537abeada29ed927d3e01,0,0,0,0,0,0\n",
            "eng_af8597fa9be96fdfabb05c593476913c,0,0,0,0,0,0\n",
            "eng_e0f6e8dce6d6a6c13632b80100e5a6b1,0,0,0,0,0,0\n",
            "eng_48b992b30d2029785845b563a5ed5908,0,0,0,0,0,0\n",
            "eng_265277158900e90636bb6614c8f265b7,0,0,0,0,0,0\n",
            "eng_3c4dc44df877cfb232d222462dab6543,0,0,0,0,0,0\n",
            "eng_08a2c6cca0e7d33249339bbbef85c6c1,0,0,0,0,0,0\n",
            "eng_68280914d983fd99c5630ddd76e4bd95,0,0,0,0,0,0\n",
            "eng_cd13f9dc863b830f0f1a123db729eaff,0,0,0,0,0,0\n",
            "eng_6f76d66a4bd34d5ce4a94ec943385197,0,0,0,0,0,0\n",
            "eng_12e097065c75824d4121c0ec670647c1,0,0,0,0,0,0\n",
            "eng_bbd31cdfc7077e4903c3204ef1b9175f,0,0,0,0,0,0\n",
            "eng_4b4f2e1f0e1255dccef1959d2b30165b,0,0,0,0,0,0\n",
            "eng_cae0921076de11e46ad10498cc7d5441,0,0,0,0,0,0\n",
            "eng_298c63907209feee5c7cfe0bba8cb7be,0,0,0,0,0,0\n",
            "eng_47c81418327ba69c71e62f93a060ed39,0,0,0,0,0,0\n",
            "eng_1d443006327009ce2aff905147b39692,0,0,0,0,0,0\n",
            "eng_71021b3579c72f916147f751bce10e0c,0,0,0,0,0,0\n",
            "eng_de9a2ae60667aaddf4c646338764b526,0,0,0,0,0,0\n",
            "eng_c07a5a7dabfdb3965ec98128f318175f,0,0,0,0,0,0\n",
            "eng_fbceb1ae34db8daf3cf672a3d4256ddf,0,0,0,0,0,0\n",
            "eng_3fee89034fbdfa73372d1c88eb0aea59,0,0,0,0,0,0\n",
            "eng_c532b3613bde52aa43a9475f1ea0b32d,0,0,0,0,0,0\n",
            "eng_29ea84be308aaa614a463ddba1dfb36d,0,0,0,0,0,0\n",
            "eng_7b509629f338753f35fef4914bda9da6,0,0,0,0,0,0\n",
            "eng_3152400ae6bd362a4ae4405ea86070ec,0,0,0,0,0,0\n",
            "eng_c3a320d25b76f154caab9d9361b00907,0,0,0,0,0,0\n",
            "eng_3235c4f9ae1a74593f5cc6cff9277a85,0,0,0,0,0,0\n",
            "eng_0077188f1a05dd1d68f8352a9b84ca79,0,0,0,0,0,0\n",
            "eng_a390951455e707af9520c71ffc9db2d9,0,0,0,0,0,0\n",
            "eng_2b75f86d237a8699a27582ad90e42919,0,0,0,0,0,0\n",
            "eng_d21174080515b0ad8dc1d00ee4368d4f,0,0,0,0,0,0\n",
            "eng_ef00c86f2c475df7cee4fd5dd25e2bc7,0,0,0,0,0,0\n",
            "eng_74a62e8e997bc736b2894d9bc4da7661,0,0,0,0,0,0\n",
            "eng_9aad387704111e1f051fce5968ef2232,0,0,0,0,0,0\n",
            "eng_db9761cf21a3abb48b2669423ff5788a,0,0,0,0,0,0\n",
            "eng_7811dd491f8437afd9689a75ccb1ce04,0,0,0,0,0,0\n",
            "eng_437f5f40d878166878c2d32b8e16af31,0,0,0,0,0,0\n",
            "eng_a8b55f8a70d1c34f93fbdefa0350e507,0,0,0,0,0,0\n",
            "eng_01057285508602421377273897c3c0e7,0,0,0,0,0,0\n",
            "eng_175c490fa4665823f1dc2fc44e4d98fb,0,0,0,0,0,0\n",
            "eng_1feb16d41ce65927a8153742d14b5b6b,0,0,0,0,0,0\n",
            "eng_8182654f9b6144da76e1cfcc985a4b3a,0,0,0,0,0,0\n",
            "eng_03a2aea654b7697fcd72acdbf7ecf944,0,0,0,0,0,0\n",
            "eng_a4a13cea5e6750286b14ae7a8d81bd28,0,0,0,0,0,0\n",
            "eng_927ef1e092e0b61d9161dccb20b7d212,1,1,0,0,0,0\n",
            "eng_bab15926554f28dc36582b6e275b8805,0,0,0,0,0,0\n",
            "eng_938602684a67196e4bd95b313ad3919f,0,0,0,0,0,0\n",
            "eng_d6d5259e0d04bf6fc543ba5baaf273f1,0,0,0,0,0,0\n",
            "eng_bf5e5633ac2fdca9164c02022e0c99fd,0,0,0,0,0,0\n",
            "eng_31268830d496fa2970b2ff9918b3b7ba,1,1,0,0,0,0\n",
            "eng_95d7415206b7898a7486b0c69197baa2,0,0,0,0,0,0\n",
            "eng_b91a56f542d0513d636a0a019b7726eb,0,0,0,0,0,0\n",
            "eng_eeaa3e10a86dec32fbc1b9f1d156d796,0,0,0,0,0,0\n",
            "eng_e2622eb5bd4d433e6138c58d943b4043,0,0,0,0,0,0\n",
            "eng_533142c1bdb17ab3ffdf43e6e25f1406,0,0,0,0,0,0\n",
            "eng_325cd4d0e08485ec5693fcf15b14ff1f,0,0,0,0,0,0\n",
            "eng_063b19c19c369b678bf3446054569fdf,0,0,0,0,0,0\n",
            "eng_ebe1ae54e0854b322ad3c9667a2a4802,1,1,0,0,0,0\n",
            "eng_f1a522278c7fff07d7d7f3d033b5fa36,0,0,0,0,0,0\n",
            "eng_50c78c3a83be7868fb1ce0d636911f63,1,1,1,0,0,1\n",
            "eng_0f6d980d360c0a6c8f1edfdf6a791fb8,1,1,1,0,0,0\n",
            "eng_5a19fecc98ef147b13b59bd0d8caf8d5,0,0,0,0,0,0\n",
            "eng_3ad13d30d6003ac059e6c923a7a7eafb,1,1,0,0,0,0\n",
            "eng_74e531f9dcb74c5a7bfd9668012a8c74,1,1,0,0,0,0\n",
            "eng_b666fec715d97437ecb9c0c6a54378c4,0,0,0,0,0,0\n",
            "eng_5b51f6101221e28d6da47f2cb7214ee6,1,1,0,0,0,0\n",
            "eng_c12c886536597ecaddd1e94e922e8969,0,0,0,0,0,0\n",
            "eng_882dae250fd3467770c289b835a2aa83,1,1,0,0,0,0\n",
            "eng_b9cfff2304e5349d315bc474ce2899eb,0,0,0,0,0,0\n",
            "eng_3857e2c131a5b5fef5bbf2e9794bcd5e,0,0,0,0,0,0\n",
            "eng_2806bece99f0002047cc86a78a30a1d7,1,1,0,0,0,0\n",
            "eng_003fc3a198de8381e08ab3d85c7e40be,0,0,0,0,0,0\n",
            "eng_d74c7582012f631348296b2dbf10f4f6,0,0,0,0,0,0\n",
            "eng_0e62ae808071606db649622cb73dc2cb,1,1,1,0,0,1\n",
            "eng_8cef4402ae1b38e7c4593cc163bfe10c,1,1,0,0,0,0\n",
            "eng_310cb1f24f3545a53f33e005798ece95,1,1,0,0,0,0\n",
            "eng_5606f46a55984e9bf7db7034d451a1f6,1,1,1,0,0,0\n",
            "eng_ab5a1479644f5672c6337214087ecb4d,1,1,1,0,0,0\n",
            "eng_5e89647c49019ef6f4e3549bc5b41970,1,1,1,1,0,0\n",
            "eng_fd3ae133fa1ae5dac30d88c601d3171e,0,0,0,0,0,0\n",
            "eng_995661141a6abbbdef6770db6e1bd8f5,1,1,0,0,0,0\n",
            "eng_88e3a4bddcf38fe36666e6875399f6c3,1,1,1,0,0,1\n",
            "eng_5fbc07e0e76d061ad2496d55c93f4970,1,1,1,0,0,0\n",
            "eng_ef3116c56645f94bbe998051aaa49e40,0,0,0,0,0,0\n",
            "eng_4cd9e7e11035bcacb2814a1817238e75,0,0,0,0,0,0\n",
            "eng_ebd69a723309a37d9b5f384a3cd5c87c,0,0,0,0,0,0\n",
            "eng_d0b1c523b1cb02e41ca250d4d705efe6,1,1,0,0,0,0\n",
            "eng_5f408abc83c76617c0525e042a3ceb48,0,0,0,0,0,0\n",
            "eng_947ae20dbd1e2a3ba07bcdbd4b6a4eaa,0,0,0,0,0,0\n",
            "eng_3496f210f022027af26571fa2a2b6e30,0,0,0,0,0,0\n",
            "eng_4fca762d791268e973669733aa684e37,0,0,0,0,0,0\n",
            "eng_93a2492e7860be0d7ca445a97e245abe,1,1,0,0,0,0\n",
            "eng_b2f95890baff716a2d871097a1c210fe,0,0,0,0,0,0\n",
            "eng_e5cfe9e96de0f4873a4a6dbfca573be2,0,0,0,0,0,0\n",
            "eng_897afb355e98b187b9f75478bbbf2c51,1,1,0,0,0,0\n",
            "eng_f0ae86891c2da536ebf24c0f3964dca8,1,1,1,0,0,0\n",
            "eng_e231e20dbb7d3d433637dbb3d3c946a0,1,1,0,0,0,0\n",
            "eng_8ee2b2e8b53c55407f30fbf1219b1588,1,1,0,0,0,0\n",
            "eng_0eb6247db86e3b42c8dc125317957580,0,0,0,0,0,0\n",
            "eng_185e4dabf037ec90771e1bd18e621e2a,1,1,1,0,0,1\n",
            "eng_dbadd716608d71fb92621f7f8259f4e4,0,0,0,0,0,0\n",
            "eng_ac3c36cc719bdce4cab6c919b9b2429e,1,1,0,0,0,0\n",
            "eng_5d8aa4863fe2f8c26f541937ff5a0368,1,1,0,0,0,0\n",
            "eng_2fd4484b6bab80971a96b2100e20966a,0,0,0,0,0,0\n",
            "eng_0e11358da0c0e0cd8e0fdedf05a0cbba,1,1,0,0,0,0\n",
            "eng_0fb944d51bb376102a3ea6b65bafab6a,0,0,0,0,0,0\n",
            "eng_d9253eaeb206934208a57786b688c316,0,0,0,0,0,0\n",
            "eng_d841e099c41eb0fdd803e7c0a6109933,0,0,0,0,0,0\n",
            "eng_f6fc63a70cfafa2144d88c503cd4687b,0,0,0,0,0,0\n",
            "eng_2712f15ca491022233712e630d64d73d,0,0,0,0,0,0\n",
            "eng_d62d432eec0c12d2dc3b023edf67eac0,0,0,0,0,0,0\n",
            "eng_5ee585bf8f98b28a7e65035db0204410,0,0,0,0,0,0\n",
            "eng_07745499010cafb2d59ff898c49cf615,0,0,0,0,0,0\n",
            "eng_ec325c11de1d6163d8feb749d6457c20,0,0,0,0,0,0\n",
            "eng_4d616a82cd313bdd0dfdcf47b5f26795,0,0,0,0,0,0\n",
            "eng_268c8ff24dbb29bfa42a252ad198fe29,0,0,0,0,0,0\n",
            "eng_d9a5c1cc8ce24ec15a6b432204a34a9d,0,0,0,0,0,0\n",
            "eng_e71b8aa8338a1deaae7328a73a122cca,1,1,0,0,0,0\n",
            "eng_8c2492d1274d3693cb98ee3e700baba7,0,0,0,0,0,0\n",
            "eng_d7edf2c962f46f62f1140787e871c4a2,0,0,0,0,0,0\n",
            "eng_4c2694e3632178ffb50db62f48e1d75e,0,0,0,0,0,0\n",
            "eng_e343d9522d1ea4ab6d50998b81ad36b3,1,1,0,0,0,0\n",
            "eng_c15194e3c8b4bba93b3d652340460ffd,1,0,0,0,0,0\n",
            "eng_04eae1abe60bbb1373b9bb0f77a12e6b,1,1,1,0,0,0\n",
            "eng_12b06c46b376b4425fe6ffbcee59276c,1,1,1,0,0,0\n",
            "eng_13f40590af8d17dc49cbd80dd34e6be8,0,0,0,0,0,0\n",
            "eng_66f612addfe5a96a4a1a84342d86bdc4,0,0,0,0,0,0\n",
            "eng_ac17e23b4789ee87ade59dca086adf5c,0,0,0,0,0,0\n",
            "eng_a0a03d5390346e771751b3d0890224c1,0,0,0,0,0,0\n",
            "eng_b01fd24fbfb6630edba40768157dbed3,1,1,0,0,0,0\n",
            "eng_9f170d76134d91a9aae08ec49a0eb1b1,0,0,0,0,0,0\n",
            "eng_3caf621f17c15e73ad88d1d58ace76e1,1,1,0,0,0,0\n",
            "eng_d735bda395a80ff9861c0ab78c5fb9a3,1,1,0,0,0,0\n",
            "eng_576cca5b3a10908cc024bc4c4c6e61b3,0,0,0,0,0,0\n",
            "eng_e729b733cd4c356edea50e29301a8162,0,0,0,0,0,0\n"
          ]
        }
      ],
      "source": [
        "# print the results row by row in csv format\n",
        "for i in range(len(labels)):\n",
        "    print(f\"{test_dataset['id'][i]},\" + \",\".join(str(x) for x in labels[i]))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cloudspace",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
